[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math 300Z",
    "section": "",
    "text": "Math 300Z is a proposed revision to Math 300 that will be taught for the first time in Spring 2023. The revisions apply only to Lessons 19 and up; the first 18 lessons will come from Math 300."
  },
  {
    "objectID": "index.html#course-textbooks",
    "href": "index.html#course-textbooks",
    "title": "Math 300Z",
    "section": "Course textbooks",
    "text": "Course textbooks\nBoth Math 300 and Math 300Z will start with Chapters 1 through 6 of Statistical Inference via Data Science.\nFor the second half of the semester, Math 300Z continues with Lessons in Statistical Thinking. Math 300, continues with Chapter 7 through 11 of Statistical Inference via Data Science\n | | \nBoth textbooks are available free online."
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Math 300Z",
    "section": "Software",
    "text": "Software\ninstall.packages(c(\"mosaic\", \"ggplot\", \"dplyr\", \"openintro\", \"moderndive\", \"nycflights13\", \"knitr\"))\n# addition package for Math 300Z\nremotes::install_github(\"dtkaplan/math300\")"
  },
  {
    "objectID": "index.html#day-by-day-schedule",
    "href": "index.html#day-by-day-schedule",
    "title": "Math 300Z",
    "section": "Day-by-day schedule",
    "text": "Day-by-day schedule\nData, graphics, wrangling\nReading: SIDS Chapters 1 through 4\n\nData with R\nScatterplots\nLinegraphs, histograms, facets\nBoxplots and barcharts\nfilter and summarize\ngroup_by, mutate, arrange\njoin, select, rename, & top n\nImporting data\nCase study/review\nGR1 (chapters 1-4)\n\nRegression\nReadings 11. SLR: Continuous x 12. SLR: Discrete x 13. SLR: Related topics 14. Multiple regression: Numerical & discrete 15. Multiple regression: Two numerical 16. Multiple regression: Related topics 17. Multiple regression: Conclusion/review 18. GR 2 (chapters 5-6)"
  },
  {
    "objectID": "index.html#math-300z-continues-with",
    "href": "index.html#math-300z-continues-with",
    "title": "Math 300Z",
    "section": "Math 300Z continues with",
    "text": "Math 300Z continues with\n\nA note on computing summaries of data\n\nVariation\n\nStatistical thinking Reading : Student notes\nSimulating variation Reading : Student notes\nSignal and noise Reading : Student notes\nSampling variation Reading : Student notes\nConfidence intervals from a single sample Reading : Student notes\nEffect size Reading : Student notes\nMechanics of prediction Reading : Student notes\nConstructing a prediction interval Reading : Student notes\nGR 3 (Lessons 19-26)\n\nInference\n\nCovariates Reading : Student notes\nCovariates eat variance Reading : Student notes\nConfounding Reading : Student notes\nSpurious correlation Reading : Student notes\nExperiment and random assignment Reading : Student notes\nMeasuring and accumulating risk Reading : Student notes\nConstructing a classifier Reading : Student notes\nAccounting for prevalence Reading : Student notes\nHypothesis testing Reading : Student notes\nCalculating a p-value Reading : Student notes\nFalse discovery with hypothesis testing Reading : Student notes\nGR 4 (lessons 28-38)\nReview"
  },
  {
    "objectID": "objective-list.html",
    "href": "objective-list.html",
    "title": "List of objectives",
    "section": "",
    "text": "This list is assembled from the individual-lesson files in the Objectives/ directory. Make any changes in that directory.\n\n19.1 Use the response vs. explanatory (RESPEX) format for data graphics, employing jittering as appropriate. Display density distributions using a violin graphic.\n19.2 Use the variance to measure the amount of variation in a quantitative variable. a. Convert a variance into the corresponding standard deviation. b. Properly display a standard deviation on a RESPEX-format graph.\n19.3 Compute, interpret, and display the fitted model values and the residuals.\n\n\n\n\n\n\nIn DRAFT: “Fitted model values”\n\n\n\nMake sure this appears in the text. Also, RESPEX.\n\n\n19.4 Generate graphics and models using zero-one encoding of a categorical response variable. Interpret the output of such models.\n\n20.1 Construct sampling trials from a data frame or a simulation.\n20.2 Replicate sampling trials and calculate the amount of sampling variability.\n20.3 Recognize properties of directed, acyclic graphs (DAGs).\n\n21.1 Use model training to separate signal from noise in a response variable.\n21.2 Recognize that the same training data will show a different signal depending on what model specification is used.\n\n22.1 Describe the logical origin of sampling variation as the variation between multiple samples from the same source.\n22.2 Recognize the several formats in which we describe sampling variation—sampling variance, standard error, margin of error, confidence interval—and show how they are related.\n22.3 Identify how sampling variance scales with sample size \\(n\\) and use this to estimate—given a single sample—how large the sampling variation would be in a sample of a different size.\n\n23.1 Construct and interpret confidence intervals on model coefficients and relate the intervals to the sampling distribution.\n23.2 Recognize that confidence intervals are only about sampling variation. They do not measure or summarize bias.\n\n24.1 Calculate the effect size with respect to a specified variable from regression models of one and multiple variables.\n24.2 State the units of an effect size given the units of the input and output of the model.\n24.3 Be able to hold a covariate “constant” in the calculation of effect size.\n\n25.1 Given a data frame, construct a predictor function for a specified response variable.\n25.2 Use the predictor function to estimate prediction error and summarize with root mean square (RMS) error. Relate this to a prediction interval.\n25.3 Distinguish between in-sample and out-of-sample prediction estimates of prediction error.\n25.4 Distinguish between the two settings for decision-making:\na. **Prediction**: predict an outcome for an individual\nb. **Relationship**: characterize a relationship with an eye toward intervention or a better understanding of how a mechanism works.\n\nGiven a research question, identify whether it corresponds to a prediction setting or a relationship setting.\n\n26.1 In evaluating a model function, generate a prediction interval.\n26.2 Interpret prediction bands as a series of intervals, one for each value of the model input.\n26.3 Identify the two components that make up a prediction error, one that scales with \\(n\\) and the other that doesn’t.\n\nThis is a QR day.\n\n28.1 Read a DAG to determine which covariates to include in a model to reduce (out-of-sample) prediction error.\n\n29.1 Correctly define “covariate”.\n29.2 Understand why including covariates—even spurious ones—always improves the appearance of model performance in in-sample testing.\n29.3 Read a DAG to anticipate when using spurious covariates will improve or will worsen model performance on out-of-sample prediction.\n29.4 Calculate amount of in-sample mean square error reduction to be expected with a useless (random) covariate. (Residual sum of squares divided by residual degrees of freedom.)\n\n30.1 Identify confounding in a DAG\n30.2 Choose whether to include covariate depending on form of DAG\n\n31.1 Distinguish “common cause” and “collider” forms of DAG.\n31.2 Construct appropriate DAG to match a narrative hypothesis.\n\n32.1 Properly use nomenclature of experiment.\n32.2 Correctly re-draw DAG for an ideal experimental intervention.\n32.3 Use blocking to set assignment to treatment or control.\n\n33.1. Distinguish between absolute and relative risk and identify when a change in risk is being presented as absolute or relative.\n33.2. Calculate and correctly interpret other presentations of differences in risk: population attributable fraction, NTT, odds ratio.\n33.3. Interpret effect size as stated in log odds.\n\n34.1. Build a classifier from case-control data.\n34.2. Cross-tabulate classifier results versus true state. Evaluate false-positive rate, false-negative rate, accuracy.\n34.3. Calculate different forms of conditional probability: p(A|B) versus p(B|A) and identify which form of conditional probability is useful for prediction of an individual’s outcome.\n\n35.1 Explain why case-control data may not give an proper measure of “prevalence.”\n35.2 Understand sensitivity and specificity as conditional probabilities.\n35.3 Calculate false-positive and false-negative rates for a given prevalence.\n\n36.1 Understand and use properly hypothesis testing nomenclature: test statistic, sampling distribution under the null, Type-1 and Type-2 error, rejection threshold, p-value\n36.2 Contrast hypothesis testing versus Bayesian framework.\n\n37.1 The permutation test\n37.2 Interpret correctly from regression/ANOVA reports\n37.3 Traditional names for hypothesis tests in different “textbook” settings.\n37.4. Distinguish between p-value and effect size, that is, “significance” and “substance.”\n\n38.1 Identify signs of false discovery in a research paper.\n38.2 Estimate how overall p-value should change when study is replicated."
  },
  {
    "objectID": "lessons.html",
    "href": "lessons.html",
    "title": "Math 300R day-by-day Lessons",
    "section": "",
    "text": "See Fall 2022 repository.\nData, graphics, wrangling\n\nData with R\nScatterplots\nLinegraphs, histograms, facets\nBoxplots and barcharts\nfilter and summarize\ngroup_by, mutate, arrange\njoin, select, rename, & top n\nImporting data\nCase study/review\nGR1 (chapters 1-4)\n\nRegression\n\nSLR: Continuous x\nSLR: Discrete x\nSLR: Related topics\nMultiple regression: Numerical & discrete\nMultiple regression: Two numerical\nMultiple regression: Related topics\nMultiple regression: Conclusion/review\nGR 2 (chapters 5-6)\n\nThere are already learning checks associated with these first 18 chapters. Some additional ideas for learning checks are in this document."
  },
  {
    "objectID": "lessons.html#new-lessons",
    "href": "lessons.html#new-lessons",
    "title": "Math 300R day-by-day Lessons",
    "section": "New lessons",
    "text": "New lessons\n\nA note on computing summaries of data\n\nVariation\n\nStatistical thinking NTI : Objectives : LC : Reading : Student notes\nSimulating variation NTI : Objectives : LC : Reading : Student notes\nSignal and noise NTI : Objectives : LC : Reading : Student notes\nSampling variation NTI : Objectives : LC : Reading : Student notes\nConfidence intervals from a single sample NTI : Objectives : LC : Reading : Student notes\nEffect size NTI : Objectives : LC : Reading : Student notes\nMechanics of prediction NTI : Objectives : LC : Reading : Student notes\nConstructing a prediction interval NTI : Objectives : LC : Reading : Student notes\nGR 3 (Lessons 19-26)\n\nInference\n\nCovariates NTI : Objectives : LC : Reading : Student notes\nCovariates eat variance NTI : Objectives : LC : Reading : Student notes\nConfounding NTI : Objectives : LC : Reading : Student notes\nSpurious correlation NTI : Objectives : LC : Reading : Student notes\nExperiment and random assignment NTI : Objectives : LC : Reading : Student notes\nMeasuring and accumulating risk NTI : Objectives : LC : Reading : Student notes\nConstructing a classifier NTI : Objectives : LC : Reading : Student notes\nAccounting for prevalence NTI : Objectives : LC : Reading : Student notes\nHypothesis testing NTI : Objectives : LC : Reading : Student notes\nCalculating a p-value NTI : Objectives : LC : Reading : Student notes\nFalse discovery with hypothesis testing NTI : Objectives : LC : Reading : Student notes\nGR 4 (lessons 28-38)\nReview"
  },
  {
    "objectID": "layout.html",
    "href": "layout.html",
    "title": "Layout of this site",
    "section": "",
    "text": "This is the proposal/layout site for the Spring 2023 revisions to Math 300, which we’re calling “Math 300R” to distinguish it from the Fall 2022 version of the course. The site contains notes and other materials for each of the (revised) lessons in Math 300R.\nAs of October 2022, the revisions are for lessons 19-37. Revisions, if any, to earlier lessons may be added. Eventually, the revised lessons and the unrevised lessons should be consolidated into a single site. This might occur in December 2022.\nThere are four main directories. In each directory, the contents are split up on a lesson-by-lesson basis.\n\nObjectives: Student-facing learning goals that make explicit the skills and understandings that students are expected to develop in the course of each lesson. These files are formatted in a specific manner that provides an ID to each objective. Software reads the files so that each objective can be referred to in any document without duplication. That is, the files in this Objectives directory are the source of truth for the objectives for each of the revised lessons. Any edits or additions to the objectives must be performed in the files in this directory.\nNTI: Lesson-by-lesson “Notes To Instructors.” These are intended to guide instructors through each lesson. They usually contain references to the objectives stored in the Objectives directory. In draft form, the NTIs typically contain notes that are to be moved eventually to the “Reading notes.”\nLC: Like Objectives, this directory contains lesson-by-lesson exercises, styled “learning checks” in the style of the Statistical Inference via Data Science textbook. Not all the learning checks need to be assigned. Which ones are assigned for each lesson will be noted in the NTIs.\nReading-notes: Textbook-like readings, also organized lesson-by-lesson (as opposed to the chapter organization typically found in textbooks.) Often, several lessons in sequence refer to the same statistical topic. Nonetheless, the reading notes are divided on a lesson basis. It is anticipated that these will be provided to students in an on-line format.\nStudent-notes: “Student notes” refers to a set of student-facing Rmd files, one for each Lesson. They are usually based on the Learning Challenges Students are expected to work through the notes, answering the questions by completing code chunks and writing short free response answers. A good daily assignment would be complete the notes and compile them to PDF format."
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "Up through Spring 2022, Math 300 was organized around the Moore and Notz textbook: Statistics: Concepts and controversies 10/e. This book was designed for a non-technical audience of “consumers of statistics” but is dramatically outdated. For instance, it has no data science content and introduces only primitive statistical methods. A course with such shortcomings seems inappropriate for cadets going on to be officers who will inevitably have to work with modern data and methods.\nIn Fall 2022, Math 300 switched to a very different book, Ismay and Kim, Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. The ModernDive book introduces computing on data in an accessible but modern way. It is the only well-known statistics text based on a data-science perspective. Nonetheless, the statistical inference portions of the book regress to the same sort of primitive statistical methods from Concepts and Controversies.\nTo support the Fall 2022 course using ModernDive, a complete set of roughly 35 Notes to Instructors (NTI) was written by Prof. Bradley Warner along with problem sets and other needed materials and deployed for the course.\nThis proposal is for additional improvements to Math 300, building on the Fall 2022 course but replacing the statistical inference portions of the course with more contemporary and general-purpose inference techniques and support for concepts and methods relevant to decision-making.\nIn the following, I refer to three different versions of Math 300:\n\nThe Fall 2022 version of the course, using the ModernDive book, will be called Math 300.\nThe previous version of the course, as taught for several years before Fall 2022, will be called 300CC, which refers to the textbook then used, Concepts & Controversies.\nThe course proposed in this document, a revision of part of Math 300, will be called Math 300R. The R stands for “revised.”"
  },
  {
    "objectID": "proposal.html#overall-goals-of-math-300r",
    "href": "proposal.html#overall-goals-of-math-300r",
    "title": "Proposal",
    "section": "Overall goals of Math 300R",
    "text": "Overall goals of Math 300R\nThe design of a course revision needs to take into account several factors:\n\nThe target audience’s anticipated technical ability and motivation and, therefore, the appropriate pedagogy and the balance between theory and practice to use in the course.\nInstitutional goals that inform the prioritization of the topics included in the course.\nConstraints of class time and internal coherence of the course, that is, using later topics to reinforce student learning of the earlier topics.\n\nLater, in the rationale section section of this document, I describe how I came to the following conclusions, but for now, a simple statement will suffice.\n\nThe target audience is humanities and social science majors, many of whom will not be confident in the use of calculus but all of whom have had previous exposure to R in the core calculus course.\nInstitutional goals (as revealed by discussions with humanities and social science departments and the wording of the catalog description of Math 300) include a substantial emphasis on data science techniques (data wrangling and visualization) and the use of statistical concepts and methods to support decision-making."
  },
  {
    "objectID": "proposal.html#statistical-topics-and-framework",
    "href": "proposal.html#statistical-topics-and-framework",
    "title": "Proposal",
    "section": "Statistical topics and framework",
    "text": "Statistical topics and framework\nTransitioning from Math 300CC to Math 300 has already accomplished many data science goals. This proposal centers on the statistical topics/methods to be covered and the path through them.\nThe class-time demands of the new emphasis on data science techniques in Math 300 (and retained in Math 300R) dictate that the statistical concepts and methods be taught more compactly than in Math 300CC. Low-priority, legacy topics from Math 300CC should be dropped. (The GAISE report provides some guidance here.) We can use to advantage that students in Math 300 already see many modeling-related topics in Math 141Z/142Z. Since students already have a background in model-building and computing, we can choose statistical topics that relate well to decision-making.\nA traditional path for statistical methods starts with descriptive statistics (e.g., standard deviation) and then presents “1-sample” statistics (e.g., mean, proportion) and inferential techniques (confidence interval, hypothesis test) in that context. Next comes the inferential techniques for the analogous “2-sample” statistics (difference in mean, difference in proportion), followed by inference techniques for regression.\nThis path is unnecessarily long for our students since regression encompasses all the traditional methods.1 Framing statistical inference in the context of regression avoids the need to teach method-specific calculations or cover the variety of formats for non-regression test results. Regression is part of the data scientist’s standard toolbox and relates well to more advanced data techniques such as machine learning. The ModernDive textbook uses regression as the segue from the first block (about data wrangling and visualization) to the third block (about inference).\nAdditional streamlining comes from motivating statistical inference using a simulation approach. Simulation draws on two conceptually simple data operations: resampling and permutation (shuffling). This approach is well established in the statistics community and is considered by many (including the ModernDive authors) to be a better pedagogy than the traditional formula-and-distribution presentation of statistical methods. Since Math 300 (and 300R) students will already have worked with wrangling and visualization, they will be well prepared to work with the data generated by repeated simulation trials.\nThe focus on decision-making in 300R appears in the addition of new concepts and techniques treated minimally in traditional statistics courses. These include risk, prediction (and its close cousin classification), causality, and confounding. Introductory epidemiology courses provide a model for teaching about risk, causation, and confounding. The pedagogy for these topics in Math 300R comes from the epidemiology course I introduced at Macalester. In addition, Math 300R draws on my decade of experience teaching causality as part of an introductory statistics course. (See the causation chapter of my Statistical Modeling text.)\nThe Statistical Modeling pedagogy for causality uses directed acyclic graphs (DAGs) and causal simulations based on them. Unlike resampling and permutation, which re-arrange existing data, the DAG simulations generate synthetic data with specified properties (such as effect sizes). Simulations allow a concrete demonstration of the extent to which regression techniques can and cannot recover causal information from data.\nThe DAG-simulation approach lends itself naturally to the demonstration of statistical phenomena such as sampling variation and estimation of prediction error. As an example, consider the statistical fallacy of regression to the mean, as with Galton’s finding about comparing children’s heights to their parents’. The natural hypothesis that heights are determined by genetic and other factors is represented by this DAG:\n\\[\\epsilon \\rightarrow parent \\longleftarrow GENES \\longrightarrow child \\leftarrow \\nu\\] In this DAG there is no causal mechanism included for “regression to the mean.” However, Galton’s empirical finding is replicated by data from the DAG-simulation."
  },
  {
    "objectID": "proposal.html#sec-broad-structure",
    "href": "proposal.html#sec-broad-structure",
    "title": "Proposal",
    "section": "Scope of the proposed changes",
    "text": "Scope of the proposed changes\nMath 300R will retain the first 17 lessons of Math 300. All teaching materials for this part of the course will be used unaltered. (Exception: revisions to Math 300 the Fall 2022 teaching team deems appropriate. Such revisions are not part of this proposal.)\nThe following 19 lessons are entirely refactored and based on new readings, NTIs, exams, and other materials. Objectives for each of these 19 lessons are itemized here.\n\nThe corresponding ModernDive chapters are not used in Math 300R.\nThe software used is the same as that used in the first half of the ModernDive book, specifically the ggplot2 graphics package and the tidyverse data wrangling packages. However, the infer package used in the second half of ModernDive is dropped.\n\nThe theme of the refactored 19 lessons is “informing decisions with data.” Statistical approaches that can inform decision-making include anticipating the impact of interventions, predicting individual outcomes, and the quantification of risk. These are all included in Math 300R.\nTopics to be de-emphasized are the algebra of computing confidence intervals and p-values and the (controversial) role of p-values as a guide to practical “significance.” About half of a traditional course is about the construction of confidence intervals in various settings and, more or less equivalently, the conversion of data into p-values. However, in the contemporary era, when “observational” data are collected en masse, p-values can become very small (“significant”) even when the relationship under study is slight and insubstantial.\nConfounding and methods for dealing with it (statistical adjustment, experiment) are treated substantially in Math 300R. Decision-making about interventions often relies on understanding causal effects. The possibility of confounding is a major source of skepticism about making causal judgments. In a world where much data is observational, the sweeping principles that “correlation is not causation” and “no causation without experimentation” do not support making responsible conclusions about causal connections and the need to make decisions even when data cannot provide a definitive answer. Decision-makers need this support."
  },
  {
    "objectID": "proposal.html#rationale",
    "href": "proposal.html#rationale",
    "title": "Proposal",
    "section": "Rationale for course revisions",
    "text": "Rationale for course revisions\n\nRelationship to Math 357 and Math 377\nDFMS offers three courses satisfying the statistics component of the Academy’s core requirements: Math 300, Math 357, and Math 377. In designing 300R, attention should be paid to the reasons for supporting three distinct courses. The catalog copy lays out the differences in terms of intended student major, software, mathematical background, and orientation to data science.\nIntended student major: The catalog says, “Math 300 is designed primarily for majors in the Social Sciences and Humanities.” while “Math 356 is primarily designed for cadets in engineering, science, or other technical disciplines. Math majors and Operations Research majors will take Math 377.” Math 377 is also the intended course for prospective Data Science majors, although this is not in the catalog.\nSoftware: The catalog does not describe any software component for either Math 300 or Math 357, but states that, in Math 377, “modern software appropriate for data analysis will be used.” In reality, as of Fall 2022, much the same software is used in all three courses: R with the dplyr package for data wrangling, ggplot2 for data visualization, and “R/Markdown” for creating computationally active documents.\nOne difference between Math 300 and 357/377 relates to computer programming. Both 357 and 377 include content about the underlying structure of the R language, object types, the construction of functions, and arrays and iteration. In contrast, Math 300 is based on a small set of command patterns using data frames. Students see R in Math 300 more or less as an extension of what they learned in 141Z/142Z; what’s added is a few statistical and data-wrangling functions and a handful of new graphics types.\nStudents’ mathematical background: Math 377 explicitly refers to “calculus-based probability.” Math 300 and 357 share identical catalog copy, though in reality Math 357 and Math 377 use the same textbook. Calculus is indeed necessary for the probability topics in Math 357 and 377. My interpretation is that Math 300 should serve as a safe haven for those who lack confidence in their calculus skills. Both the Fall 2022 edition of Math 300 and the proposed Math 300R serve this role as safe haven.\nOrientation to Data Science: Starting with the Fall 2022 edition, Math 300 develops and draws on data-science skills for wrangling and visualization. In this, the new Math 300 is in line with both Math 357 and 377.\nThe above analysis indicates that Math 300 and 300R should diverge from Math 357/377 in these ways:\n\nMath 300R should make little or no use of calculus operations.\nMath 300R should include little consideration of probability distributions or (non-automated) calculations with any but the simplest.\nMath 300R should be computational, but should not draw heavily on computer programming skills such as types of objects, arrays, indexing, and loop-style iteration. Use of R/Markdown documents should be considered as a pedagogical choice, and retained or discontinued based on how it contributes to student success in the other areas of the course.\n\nIn addition, I suggest that …\n\nMath 300R include some work with assembling/curating data using spreadsheets and basic data cleaning with spreadsheets. Awareness of the ubiquity of data errors and a basic understanding of how to deal with such errors is an important component of working with data. (This is not to suggest that data analysis, modeling, and graphical depiction be taught using spreadsheets, which are notoriously unreliable, difficult, and limiting for such purposes. Spreadsheets are, however, appropriate for the phase where non-tabular data is transcribed into a tabular arrangement.)\n\n\n\nInstitutional goals\nIt can be difficult to translate broadly stated institutional goals to apply them to a single course. However, catalog descriptions of programs and individual courses provide some assistance. Here is the catalog copy for Math 300 (which is identical to the catalog description of Math 357).\n\nMath 300. Introduction to Statistics. An introduction in probability and statistics for decision-makers. Topics include basic probability, statistical inference, prediction, data visualization, and data management. This course emphasizes critical thinking among decision-makers, preparing future officers to be critical consumers of data. (Emphasis added.)\n\nI interpret the final sentence as a description of the overall objective of the course:\n\nOverall objective: Prepare officers to use data to inform decisions.\n\nReturning to the idea that the topics listed in the catalog copy ought to be interpreted as serving the overall objective of the course, let’s consider those topics one at a time:\n\ndata management\ndata visualization\nprediction\nstatistical inference\nbasic probability\n\n\nStrictly speaking, as a term of art the phrase “data management” is business jargon describing enterprise-level activities that are unrelated to the other items on the list. It would be unheard of to include it, in this strict sense, in a statistics course. I believe the intent of the phrase to be better served by terms like “data wrangling,” “data cleaning,” “database querying,” and such which make up an important part of “data science.” Data wrangling is a major feature of Math 300 launched and is covered using professional level computing tools well suited to both small and large data. But whatever “data management” might reasonably be taken to mean, it was utterly ignored in Math 300CC.\n“Data visualization” is generally taken to be the process of using graphics to discover and highlight patterns shown in data. Math 300CC included only statistical graphics such as histograms, box-and-whisker plots, and basic “scatter plots.” Math 300 adds to this modern modes of graphics such as transparency, color, and faceting that make it possible to display relationships among multiple variables. The software used in Math 300 is the professional-level ggplot2 which provides the ability to increase the sophistication and generality of data display, using for example density graphics such as violin plots. As such, Math 300 is a big step on the road to rich data visualization. Some of these will be introduced in Math 300R in the second half of the course.\n“Prediction” is a central paradigm used in the important area of “machine learning.” It is also an often used method used to inform decision making and characterize risk, for instance, by indicating the distribution of plausible outcomes. Math 300CC emphasized paradigms such as hypothesis testing and confidence intervals that are not aligned with making and interpreting predictions. Math 300 focuses on these same paradigms. Math 300R will treat prediction as a central statistical path, as well as highlighting its proper use, interpretation, and evaluation.\n“Statistical inference” is traditionally taken to mean the calculation and interpretation of hypothesis tests and confidence intervals in various simple settings. Such settings include the “difference between two means,” the “correlation coefficient,” and the “slope of a regression line.” Math 300CC introduced a handful of such settings, providing distinct formulas for each of them. The “controversies” referred to in the title Concepts and controversies includes the problematic interpretation of “p-values” and the need to use random sampling and/or random assignment in data collection to get “correct” results. Math 300 retains the emphasis on confidence intervals and p-values in the simple settings, but emphasizes a more general and accessible methodology based on bootstrapping and permutation tests.\n\nUnfortunately, appealing to random sampling/assignment is often whistling past the graveyard, since these idealized data collection processes are rarely available. Instead, professionals include “covariates” in their data collection in order to “adjust” for the factors that would have been scrambled into insignificance by random sampling/assignment if it had been available. Math 300R incorporates covariate methods and highlights the importance of identifying appropriate covariates.\n\n“Basic probability” can mean different things to different people. In most introductory statistics courses it refers to the construction, calculation, and study of named distributions such as the binomial, normal, chi-squared, t, etc. Such distributions play an important role in the statistical theory of confidence intervals and hypothesis testing. That is, they are support for statistical inference. Math 300CC followed the traditional pattern of having students memorize which distribution is relevant to which setting and using printed tables for calculation. As described earlier, Math 300 provides a much more natural route to inference through bootstrapping and permutation tests.\n\nWhat’s left out in this conception of basic probability is the support for decision making. Essential to this is the proper use of “conditional probability.” Math 300R emphasizes appropriate use and interpretation of conditional probability, seen most clearly in the “classifiers” part of the course.\n\n\nFaculty opinions\nInsofar as faculty internalize the goals of the institution, their views can point to ways that existing courses do and do not reflect those goals.\nWithin DFMS and other departments, there is a general discontent that Math 300CC was not doing what it ought to. Reasons for this can be seen by examining the textbook used in Math 300CC. The book has clear deficiencies, among which are:\n\nthe material is out of date and does not reflect any of the consensus recommendations (such as GAISE) developed in the last 30 years.\nit does not use data at any level beyond hand calculation.\nit does not deal with decision making at any serious level. (The only decision formally supported is whether or not to reject the Null hypothesis.)\n\nThe opinions of faculty outside DFMS can also be an important guide to institutional priorities. In AY 2021-22 I contacted the departments in the social sciences and humanities. Three of these—history, political science, economics—responded with interest. Discussion with groups of faculty from these departments elucidated a number of points:\n\nThe faculty most highly valued the development of data-science skills such as computing for data wrangling and data visualization.\nThe then-current version of Math 300 did not contribute to the development of such skills.\nMath 357 is not seen as an appropriate alterative to Math 300, both because of perceived difficulty of 357 and because faculty do not value the emphasis on probability distributions seen in 357.\n\nFrom my experience at Macalester and in conducting reviews at many colleges, I am often wary of the motivation of faculty in other departments. These can represent a desire for service courses like Math 300 to cover discipline-specific techniques. However, the faculty I spoke to also had an eye on what their students will need for their post-graduation jobs. Particularly the USAF officers drew on their field experience in areas such as military intelligence.\nBased on these findings, the group of faculty planning for revisions to Math 300 made an easy decision: replace the textbook with one oriented to data science. We selected the ModernDive book, which is unique among introductory statistics textbooks in starting out with data wrangling and visualization. This change of textbook addresses the “use data” part of the course objective stipulated above.\nThe other part of the objective—inform decisions—remains problematic even with the switch in the Math 300 textbook. Discussions I had with the ModernDive authors made clear that their purpose in writing the book was to provide a way to introduce data science into introductory statistics, but that they stuck to the traditional hypothesis-testing/confidence-interval framework in order not to make the change too daunting for instructors thinking of adopting the text. In other words, they were not trying to turn the topic toward decision-making with data, the motivation of the ideas presented in this proposal for Math 300R."
  },
  {
    "objectID": "proposal.html#plan-of-work",
    "href": "proposal.html#plan-of-work",
    "title": "Proposal",
    "section": "Plan of work",
    "text": "Plan of work\n\nEarly October 2022: Preliminary approval, with appropriate modifications, of the proposed objectives.\nOctober 2022: DTK will draft new day-by-day NTIs for the second half of the course in the same style as the existing NTIs for the first half of the course. In the process of drafting, there will likely be some re-arrangement and modification of the objectives in (1).\nNovember 2022: With the draft NTIs in hand, a faculty team will make a more detailed examination of the proposed objectives. I recommend that this examination be structured as a set of hour-long discussions, one for each of the five divisions described in ?@sec-topics.\nNovember/December 2022: DTK (and others, as interested) will assemble student readings to replace the second half of ModernDive. Much of the content already exists in the form of a draft textbook by DTK. These will be re-arranged to correspond to the day-to-day objectives as determined in (3).\nJanuary/February 2023: The first 18 lessons of 300R will be taught as a repeat of those lessons from Math 300 Fall 2022. DTK will participate mainly as an observer.\nJanuary/February 2023: Revision and refinement will be made of the readings and NTIs in (3) and (4) above.\nMarch/April 2023: Teaching the new lessons. DTK will participate as an instructor for these lessons."
  },
  {
    "objectID": "student-notes.html",
    "href": "student-notes.html",
    "title": "Student Notes",
    "section": "",
    "text": "Will list day-by-day student notes here."
  },
  {
    "objectID": "Student-notes/Student-notes-lesson-23.html",
    "href": "Student-notes/Student-notes-lesson-23.html",
    "title": "Math 300 Lesson 23 Notes",
    "section": "",
    "text": "The authentic context for estimating the magnitude of sampling variation is when we have only a single sample, not the imagined set of samples that we studied in Lesson 23. The estimate of sampling variation is used to describe the precision of a sample summary which is often presented in the form of a confidence interval.\n\n\nLesson 23 from LST\n\n\n\n23.1 Construct and interpret confidence intervals on model coefficients and relate the intervals to the sampling distribution.\n23.2 Recognize that confidence intervals are only about sampling variation. They do not measure or summarize bias.\nUpdated list of objectives\n\n\n\n\nlibrary(mosaic)\nlibrary(math300)\ndata(\"Galton\", package=\"mosaicData\")"
  },
  {
    "objectID": "Student-notes/Student-notes-lesson-23.html#lesson",
    "href": "Student-notes/Student-notes-lesson-23.html#lesson",
    "title": "Math 300 Lesson 23 Notes",
    "section": "Lesson",
    "text": "Lesson\n\nExercise 23.1\nThe regression method was introduced in the 1880s by Francis Galton. In this exercise we’ll explore the same data used by Galton in his demonstration. The data are available to us as the Galton data frame in the {mosaicData} R package.\nThe unit of observation in Galton is a full-grown child living in a household with his or her parents. Each household is identified by a unique number, stored in the family column. The variable height records the child’s height in inches, while mother and father record the heights of the parents. The total number of children in the household is recorded in nkids. sex is also recorded.\nGalton’s particular interest was in the heritability of measurable traits like height. At the time he worked, there was no theory of “genetics” or detailed understanding of how traits were passed from parents to child.\n\nTask 1.1\nThe model specification height ~ father + mother can describe the extent to which children inherit their height at full-growth from their parents. Here are the coefficients from that model:\n\nlm(height ~ father + mother, data = Galton) %>%\n  coef()\n\n(Intercept)      father      mother \n 22.3097055   0.3798970   0.2832145 \n\n\nThe coefficients allow us to do a kind of thought experiment. Imagine a full-grown child of height 63 inches. Now imagine that same child but with a different father. The new father is 1 inch taller than the original father. According to the model coefficients, the child of the new father would be 63.38 inches tall, inheriting 0.38 of the new father’s extra height.\nWhose height, the father’s or the mother’s, has a greater influence on the child’s height. Explain what you see in the coefficients that leads you to your answer.\nYour answer:\n\n\nTask 1.2\nSince we know there is inevitably sampling variation, we shouldn’t take all the digits of the father or mother coefficient at face value. The confidence intervals on those coefficients summarize the actual precision of the coefficients.\nCalculate the confidence intervals from the same model as in Task 1.1.\n\n# For task 1.2\n\nLooking at the confidence interval, reconsider your answer to the question from Task 1.2: Whose height, the father’s or the mother’s, has a greater influence on the child’s height. Explain what you see in the confidence intervals that leads you to your answer.\nYour answer:\n\n\nTask 1.3\nConfidence intervals can be wider or narrower depending on what other explanatory variables are included in the model specification. Calculate the confidence intervals on the coefficients from the model specification height ~ father + mother + sex.\n\n# For task 1.3\n\nDoes including sex in the model make the confidence intervals broader or narrower?\nYour answer:\n\n\nTask 1.4\nIt’s conventional wisdom that a wife and her husband are more similar in their height than would be a randomly selected woman or man. If this is so, then variation in wive’s heights should account for variation in their husbands’ heights.\nTo check this out, we can use the mother and father variables from Galton and the model specification father ~ mother. Train that model and find the confidence interval on the mother coefficient.\n\n# For task 1.4\n\nDoes the confidence interval lead you to conclude that conventional wisdom matches what Galton has to say? Explain what specifically about the confidence interval leads to your conclusion.\nYour answer:\nDo the thought experiment in which you increase the mother’s height by 12 inches. (That’s a lot!) According to the confidence interval, how much taller will the father be? Give a confidence interval.\nYour answer:\n\n\nTask 1.5\nIf we were studying children and their parents in the same way an ecologist studies birds and their chicks, we might hypothesize that the children compete with one another for vital resources, and so the children from larger families will tend to be smaller than the children from smaller families.\nBuild the model height ~ mother + father + sex + nkids and look at the confidence interval on the nkids coefficient.\n\n# For task 1.5\n\nWhat do the data suggest, do kids compete for vital resources?\nYour answer:\nSo far as the nkids hypothesis is concerned, mother, father, and sex are not of direct interest. Such explanatory variables that are not of direct interest are called covariates. (They are perfectly ordinary explanatory variables, it’s just that we’re not directly interested in them.) The question might arise in your mind, why include explanatory variables if we’re not directly interested in them?\nTo answer this question, fit the simple model height ~ nkids and look at the confidence interval.\n\n# lm(height ~ nkids, data = Galton) %>% conf_interval()\n\nWhat does the confidence interval on the nkids coefficient from the simple model suggest to you about why including covariates is useful? (We’ll return to this topic in Lesson 29.)\nYour answer:\n\n\n\nExercise 23.2\nA more complete presentation of confidence intervals would point out that the length of the interval depends not only on the sample size \\(n\\), but also on something called the “confidence level,” which is a number between 0 and 100%. In practice, confidence intervals are almost always presented at a confidence level of 95%, and that is the default for conf_interval().\nThis exercise is a demonstration of what the “confidence level” is about. Understanding that will give you a better appreciation of why 95% is the confidence level used in practice.\nThe confidence level has to do with how the confidence interval might change from one sample to another. We’ll show this by generating many trials. We’ll use dag01 for the demonstration. dag01 has just two variables, x and y. The x variable is endogenous, but y is computed from x with the formula 1.5 * x + 4 + exo(). Consequently, it’s reasonable to expect that the confidence interval on the x coefficient will include the “true” value from the formula: 1.5.\nLet’s see if this works out. The following code implements drawing a sample from dag01, finding the confidence interval on the x coefficient, and setting color to black or red depending on whether the “true” value 1.5 is inside the confidence interval.\n\none_trial <- function(n = 10, level=0.95) {\n  lm(y ~ x, data=sample(dag01, size=n)) %>% \n    conf_interval(level=level) %>%\n    filter(term == \"x\") %>%\n    mutate(.color = ifelse(1.5 > .lwr & 1.5 < .upr,\n                          \"black\", \"red\"))\n}\n\nYou are not required to understand the code in one_trial(), but you should be able to make sense of the its output.\n\none_trial(n=20, level=0.95)\n\n# A tibble: 1 × 4\n  term   .lwr  .upr .color\n  <chr> <dbl> <dbl> <chr> \n1 x      1.28  2.35 black \n\none_trial(n=20, level=0.95)\n\n# A tibble: 1 × 4\n  term   .lwr  .upr .color\n  <chr> <dbl> <dbl> <chr> \n1 x     0.846  1.74 black \n\none_trial(n=20, level=0.95)\n\n# A tibble: 1 × 4\n  term   .lwr  .upr .color\n  <chr> <dbl> <dbl> <chr> \n1 x     0.599  1.58 black \n\n\nHere’s how to generate 100 trials, each involving a sample of size \\(n=20\\) turned into a confidence interval on x at the 95% confidence level.\n\nTrials <- do(100) * one_trial(n=20, level=0.95)\n\nThe next chunk defines a special-purpose function that will make a graphic showing all of the trials. The graphic is not in RESPEX format. The vertical axis is the trial number. The horizontal axis is in units of the x coefficient. Each horizontal line segment shows one confidence interval. There is also a blue vertical vertical line marking the value 1.5. By no means are you expected to create graphics of this sort, but you should be able to interpret the graph itself.\n\ngraph_trials <- function(Trials) {\n  ggplot(Trials, aes(x=.lwr, xend=.upr, \n                     y=.index, yend=.index,\n                     color=.color)) +\n    geom_segment() +\n    geom_vline(xintercept=1.5, color=\"blue\") +\n    ylab(\"Trial number\") + xlab(\"x coefficient\") + \n    scale_color_identity()\n}\n\nTo use this simulation, generate a set of trials and graph them, like this:\n\nTrials <- do(100) * one_trial(n=20, level=0.95)\ngraph_trials(Trials)\n\n\n\n\nEach of the 100 confidence intervals is drawn as a horizontal line. Whether or not a particular confidence interval includes the blue line is somewhat random, but the large majority of them do. The one’s that don’t are colored red to make them easy to spot.\n\nTask 2.1\nRun the code chunk to generate the samples several times in a row. Take note of how many of the 100 confidence intervals do not touch the blue line.\nBased on your observations, about what fraction of the confidence intervals do touch the blue line?\nYour answer:\n\n\nTask 2.2\nRepeat the simulation, but setting level=0.50.\n\n# Trials <- do(100) * one_trial(n=20, level=0.50)\n# graph_trials(Trials)\n\nBased on your observations, about what fraction of the confidence intervals touch the blue line?\nYour answer:\nCompare the typical length of the confidence interval in the level=0.50 simulation to those in the level=0.95 simulation. How are they different? Does this explain why more of the level=0.95 confidence intervals touch the blue line?\nYour answer:\n\n\nTask 2.3\nGo back to Task 2.2, still using the levels 0.95 and 0.50. But this time, change the sample size from \\(n=20\\) to \\(n=80\\).\nIn theory, how much shorter should the \\(n=80\\) confidence intervals be than the \\(n=20\\) intervals?\nYour answer:\nIn practice, do the \\(n=80\\) confidence intervals intersect the blue line in the fraction indicated by the confidence level used?\nYour answer:\nHow about when \\(n=500\\), do the confidence intervals intersect the blue line the expected fraction of times?\nYour answer: That’s pretty amazing that we can generate such confidence intervals!"
  }
]