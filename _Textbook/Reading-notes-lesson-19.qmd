# Preliminaries {#sec-lesson-19}

---
status: "proofed on Nov 28, 2022"
---

```{r setup19, include=FALSE}
lesson <- 19
source("../_startup.R")
```

## Statistical thinking

These lessons are about "**statistical thinking**," a phrase which includes habits of mind, routine questions to ask, and understanding of which statistical measures are informative---and which not---in different contexts. The goal of statistical thinking is to understand "how and when we can draw valid inferences from data." [[Source](https://nobaproject.com/modules/statistical-thinking)] The word "valid" means several things at once: faithful to the data, consistent with the process used to assemble the data, and informative for the uses to which the inferences are to be directed. 

Every person has a natural ability to think. We train our thinking skills by observing and emulating the logic and language of people and sources deemed authoritative. We have resources spanning several millennia to hone our ability to think. However, statistical thinking is a comparatively recent arrival on the intellectual scene, germinating and developing over only the last 150 years. As a result, hardly anything that we hear or read exemplifies statistical thinking. 

In general, effective thinking requires us to grasp various intellectual tools, for example, logic. Our mode of logical thinking was promulgated by Aristotle (384â€“322 BC) and, to quote the [Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/aristotle-logic/), "has had an unparalleled influence on the history of Western thought." In the 2500 years since Aristotle's time, the use of Aristotelian logic has been so pervasive that we expect any well-educated person to be able to identify logical thinking. For example, the statement "John's car is red" has implications. Which of these two statements are among those implications? "That red car is necessarily John's," or "The blue car is not John's car." Not so hard!

The intellectual tools needed for statistical thinking are, by and large, unfamiliar and non-intuitive. These Lessons are intended to provide the tools you will need to engage in effective statistical thinking. 

To get started, consider [this headline](https://www.economist.com/international/2022/12/15/the-pandemics-indirect-effects-on-small-children-could-last-a-lifetime) from *The Economist*, a well-reputed international news magazine: "The pandemic's indirect effects on small children could last a lifetime." As support for this claim, the headlined article provides more detail. For instance:

> "Stress and distraction made some patients more distant. LENA, a charity in Colorado, has for years used wearable microphones to keep track of how much chatter babies and the care-givers exchange. During the pandemic the number of such \"conversations\" declined. .... "[g]etting lots of interaction in the early years of life is essential for healthy development, so these kinds of data \"are a red flag\"."  The article goes on to talk of "*children starved of stimulation at home ....*." 

This short excerpt might raise some questions. Think about it briefly and note what questions come to mind. 

For those already along the road toward statistical thinking, the phrase,  "the number of such conversations declined" might prompt this question:  "By how much?" Similarly, reading the claim that "getting lots of interactions ... is essential for healthy development," your mind might insist on these questions:  How much is "lots?" How does the decline in the number compare to "lots?"

Not finding the answer to these questions in the article's text, it would be sensible to look for the primary source of the information. In our Internet age, that's comparatively easy to do. The LENA website includes [an article](https://www.lena.org/covid-infant-vocalizations-conversational-turns/), "COVID-era infants vocalize less and experience fewer conversational turns, says LENA research team." 
The article contains two graphs. (@fig-lena-two-graphs)

```{r}
#| label: fig-lena-two-graphs
#| fig-cap: "Graphics from the LENA website. The left is captioned, \"Children from the COVID-era sample produced significantly fewer vocalizations than their pre-COVID peers.\" The right, \"The differences in vocalizations and turns were greatest among children from families in the lowest SES [socio-economic status] quartile.\""
#| cap-location: margin
#| layout-ncol: 2
knitr::include_graphics("www/Lena-fig1.png")
knitr::include_graphics("www/Lena-fig2.png")
```

To make any proper sense of the graphs in @fig-lena-two-graphs, you need some basic technical knowledge. For example, what do the vertical bars in the graph mean? And the subcaptions, "t(628) = 3.03, p = 0.003" and "t(216)= 2.13, p=0.002": What do they mean, if anything? Turning back to the text of *The Economist*, do these graphs justify raising a "red flag?" More basically, are these graphs the "data," or is there more data behind the graphs? What would that data show?

The LENA article does not link to supporting data, that is, what lies behind the graphs in @fig-lena-two-graphs. But the LENA article does point to other publications. 

> "*These findings from LENA support a growing body of evidence that babies born during the COVID pandemic are, on average, experiencing developmental delays. For example, researchers from the COMBO (COVID-19 Mother Baby Outcomes) consortium at Columbia University published findings in the [January 2022 issue of JAMA Pediatrics](www/jamapediatrics_shuffrey_2022_oi_210081_1653493590.2509.pdf) showing that children born during the pandemic achieved significantly lower gross motor, fine motor, and personal-social scores at six months of age.*"

To the statistical thinker, phrases like "red flag," "growing body of evidence," and "significantly lower" are **weasel words**, that is, terms "used in order to evade or retreat from a direct or forthright statement or position." [[Source](https://www.merriam-webster.com/dictionary/weasel%20word)] In ordinary thinking, such evasiveness or lack of forthrightness would naturally prompt concern about the reliability of the claim. It makes sense to look deeper, for instance, by checking out the JAMA article. Many people would be hesitant to do this, anticipating that the article would be incomprehensible and filled with jargon. An important reason to study statistical thinking is to tear down barriers to substantiating or debunking claims. In fact, the JAMA article contains very little that requires knowledge of pediatrics or the meaning of "gross motor, fine motor, and personal-social scores," but a lot that depends on understanding statistical notation and convention and---more critical ---the reasoning behind the conventions.  

The tools of statistical thinking are the tools for making sense of data. Evaluating data is essential to determine whether to rely on claims supposedly based on those data. In the words of eminent engineer and statistician [W. Edwards Demming](https://en.wikipedia.org/wiki/W._Edwards_Deming): "In God we trust. All others must bring data." And former President Ronald Reagan famously quoted a Russian proverb: "Trust, but verify." Unfortunately, until you have the statistical thinking tools needed to interpret data reliably, all you can do is trust, not verify.

## Preliminaries

Statistical thinking builds on the data wrangling, visualization, and modeling skills that you have already started to develop. This Lesson introduces a handful of additional tools. In particular, we will look at how to place graphics like those in @fig-lena-two-graphs in the context of the data behind them, a first step to avoiding mis-interpretation. We will introduce the idea of **inverval summaries** of data, which provide essential information about what data can tell us. The Lesson also introduces a simple technique for encoding *categorical* data that allows us to apply the powerful tools of regression in a wider set of circumstances. 

I don't have access to the data behind @fig-lena-two-graphs, so I'll use another data set to illustrate some principles.

As all expecting parents know, a baby's "due date" is hardly exact. Pregnancies vary in length. @fig-gestation-jitter shows data from the `Gestation` data frame which records more than 1200 births. The `gestation` variable records the length of the pregnancy (in days). 

```{r warning=FALSE}
#| label: fig-gestation-jitter
#| fig-cap: "Gestational period for first-time mothers and mothers with a previous pregancy."
#| fig-cap-location: margin
#| code-fold: true
Gestation <- Gestation %>% 
  mutate(parity = ifelse(parity==0, "first-time", "previous-preg")) 
Plot1 <- Gestation %>%
  ggplot(aes(x=parity, y=gestation)) + 
  geom_jitter(alpha=0.2, width=0.2, height=0) +
  ylim(c(200,340))
Plot1
```



Such data could be made to serve more than one use. The statistical thinker always has in mind the purpose of the data presentation and uses statistical techniques appropriate for that purpose. Here are three distinct purposes:

a. Predict how long a first-time expectant mother's preganancy will last.

b. Display whether the prediction of the length of pregnancy depends on how many previous pregnancies (`parity`) the mother has had.

c. Detect whether `parity` has anything at all to do with the length of pregancy. 

Note that all three questions are fundamentally about the length of pregnancy, that is, the `gestation` variable. Since we are trying to say something about `gestation`, it is appropriate to use `gestation` as the *response variable*. Therefore, it is graphed along the vertical axis.

A simple and reasonable way to make a prediction is to look at the outcomes for the the relevant rows of the data. For question (a), we can focus on those data for mothers with `parity` zero. The dots themselves tell the story: pregnancy lasts approximately 280 days but it can vary. The large majority of pregancies are between 260 and 300 days long. 

A simpler say to describe the prediction summarizes the distribution of dots with a density plot. A good principle for presenting summaries is to do so within the context of the data themselves. So rather than make a histogram, which leaves out the raw data, we will use **violin** plot to smooth the data, as in @fig-violin-intro.

```{r warning=FALSE}
#| label: fig-violin-intro
#| fig-cap: "A violin plot. The long axis of the violin-like shape is oriented along the response-variable axis (that is, the vertical axis in our standard format). The width of the violin for each possible value of the response variable is proportional to the density of data near that value."
#| fig-cap-location: margin
#| code-fold: true
Plot1 +
  geom_violin(aes(group=parity), fill="blue", alpha=0.65, color=NA)
```

One reason to use a violin plot rather than the raw data on their own is to avoid reading too much into the raw data. Not all the gaps between data points are telling; the smooth violin plot emphasizes the overall pattern.

An even simpler summary of the prediction is called a **prediction interval**. @fig-gestation-prediction-interval shows prediction intervals separately for each level of `parity`. 

```{r warning=FALSE}
#| label: fig-gestation-prediction-interval
#| fig-cap: "Prediction intervals for each level of parity."
#| fig-cap-location: margin
#| code-fold: true
model <- lm(gestation ~ parity, data = Gestation)
Predictions <- model_eval(model, skeleton=TRUE, interval="prediction")
Plot1 +
  geom_errorbar(aes(ymin=.lwr, ymax=.upr, x=parity), y=NA, color="blue", width=0.3, data=Predictions)
```

@fig-gestation-prediction-interval shows that the prediction intervals includes most, but not all, of the raw data. In fact, it includes about 95% of the raw data and the full name for the prediction intervals is "95% prediction intervals." 

@fig-gestation-prediction-interval provides a pretty clear display for purpose (b): "Does the predicted duration of my pregnancy depend on whether I am a first-time mother?" The answer: "Yes, but `parity` has only a very small effect."

Purpose (c) has to do with a different question: Do the data enable us to detect an effect of `parity` on `gestation`? With this question we are not seeking to make a prediction for an individual mother but to answer a question about the average across the population of all mothers. Such an average is an abstraction: it is not informative about a single mother. 


@fig-gestation-confidence-interval shows the so-called "95% confidence intervals" on the duration of pregnancy. The left panel puts the confidence intervals in the context of the data, the right in isolation. Because of the zoomed in scale on the right, the difference between the intervals looks much more "significant." (Indeed, it has a similar "significance" to the intervals in @fig-lena-two-graphs.)

```{r warning=FALSE}
#| label: fig-gestation-confidence-interval
#| fig-cap: "Confidence intervals for the mean gestation duration for each level of parity."
#| fig-subcap:
#|   - "Plotted with the data"
#|   - "Plotted in isolation"
#| fig-cap-location: margin
#| code-fold: true
CIs <- model_eval(model, interval="confidence", skeleton=TRUE) %>% 
  mutate(parity = relevel(parity, "first-time"))
Plot2 <- Gestation %>%
  ggplot(aes(x=parity, y=gestation)) + 
  geom_jitter(alpha=0.05, width=0.2, height=0) +
  ylim(c(200,340)) + 
  geom_errorbar(aes(ymin=.lwr, ymax=.upr, x=parity), y=NA, color="blue", width=0.3, data=CIs)
Plot3 <- ggplot(CIs[c(2,1),], aes(x=parity)) + 
  geom_errorbar(aes(ymin=.lwr, ymax=.upr), y=NA, color="blue", width=0.3) +
  geom_point(aes(y=.output), ymin=NA, ymax=NA, color="red", data = CIs) 
gridExtra::grid.arrange(Plot2, Plot3, ncol=2)
```

@fig-gestation-confidence-interval address a different question than @fig-gestation-prediction-interval. From the perspective of an individual mother seeking to plan for her pregnancy, @fig-gestation-prediction-interval is relevant and gives a clear message: "Don't plan differently for your second pregancy than your first." In contrast, @fig-gestation-confidence-interval is about comparing two *groups* of mothers, not comparing a mother from each group.

Understanding the difference between questions (b) and (c) is not easy going for a person new to statistical thinking. Typically, research journals look for answers to (c), but this is not always relevant to (b). It will take some time before we can start to think clearly about whether the data presented in @fig-lena-two-graphs points to effects that "could last a lifetime." 




## Categorical response variables 

Regression modeling will be a fundamental tool in these Lessons for summarizing data. Regression models always have a quantitative response variable, although explanatory variables can be either quantitative or categorical. 

Often, the modeling situation calls for a response variable that is *categorical*. Expert modelers can use specialized modeling methods to handle such situations. However, categorical response variables often have just two levels, e.g., Alive/Dead, Promoted/Not, or Win/Loss. We will name the general class of such variables as "**yes/no**" or, equivalently, "**zero-one**" variables.[More formally, they are called "**binomial**" variables.]{.aside}

Yes/no response variables can be represented using 0 for one level and 1 for the other. This numerical "**0/1 encoding**" is directly suited for regression modeling and enables us to extend the scope of regression models. The *output* of the regression model is always numerical. Nothing in the regression technique restricts those outputs to exactly zero or one, even when the response variable is of the yes/no type. Usually, the modeler interprets such numerical output as probabilities or, more generally, as measures to be converted to probabilities.

::: {.callout-note}
## R technique: Using `zero_one()`.
The `zero_one()` function converts a yes/no variable to the numerical zero-one format. `zero_one()` allows you to specify which of the two levels is represented by 1.

To illustrate, consider the `mosaicData::Whickham` data frame, which records a 1972-1974 survey, part of a study of the relationship between smoking and mortality. Twenty years after the initial survey, a follow-up established whether or not each person was still alive. Here are a few rows from the data frame:

```{r echo=FALSE}
set.seed(201)
head(mosaicData::Whickham) 
```

The `outcome` variable in `Whickham` records the result of the follow-up survey. It is a categorical variable with levels "Alive" and "Dead." To examine what the data have to say about the relationship between smoking and mortality, we construct a model with `outcome` as the response variable and `smoking` as an explanatory variable. Before doing so, we translate `outcome` into a zero-one format. Like this:

```{r results="hide"}
Whickham %>% 
  mutate(alive = zero_one(outcome, one="Alive"))
```

```{r echo=FALSE}
Whickham %>% head() %>%
  mutate(alive = zero_one(outcome, one="Alive")) 
```

Note the correspondence between the `outcome` and the newly created `alive` variable.

:::


