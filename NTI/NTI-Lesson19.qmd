---
title: "Math 300R NTI Lesson `r (lesson <- 19)`"
subtitle: "Decisions with data"
author: "Prof. Danny Kaplan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
source("../_startup.R")
library(mosaicData)
```

In the first half of the course, we examined *data wrangling* methods---`group_by()`, `summarize()` and `tally()` in particular---for summarizing variables and breaking up the summaries by groups. 

In this second half of the course, we will be emphasizing the **relationships between variables**. The conceptual framework we've used for describing such relationships involves choosing a **response variable** and selecting one or more **explanatory variables**. Within this framework, you've already seen regression techniques for describing how a numerical response variable can be related to numerical explanatory variables. Something new you will see in the second half of the course is using regression techniques to handle *categorical* response variables. This will allow us to extend regression to cover such things as proportions and probabilities.

Graphics can be a powerful way to perceive relationships between variables. In keeping with the response/explanatory framework, our go-to graphical technique will be to plot data as a "**point plot**" absolutely sticking to the convention that the response variable will be assigned to the *vertical axis*. Note that we'll use the term "point plot" rather than the "scatter plot" that was used in the early graphics chapters. That's partly because we're going to use the idea of "scattering" in a different way.

We're also going to adopt a new graphical convention: that statistical summaries should always be graphed as a layer on top of the raw data from which the summaries are derived. This means that we'll switch away from histograms as a way of displaying distributions. Why? Because the vertical axis on a histogram does not correspond to the values of a response variable. Similarly, barplots won't be appropriate, because the response variable in a barplot is represented by color rather than position on a vertical axis.

Overall, both the graphical display of data and summaries and the calculation of numerical summaries like means and proportions will become much simpler to accomplish, since relationship summaries will be produced using using `lm()` and closely related model types. Data graphics will be made with `geom_point()` and closely related geoms.

## Graphing data and statistical annotations




## Categorical response variables

To get started, we'll work with categorical response variables that are "**dicotomous**" or, equivalently, "**binomial**," that is, with only two methods. This covers a large fraction of the situations where categorical response values are needed. We'll leave those situations where there are lots of levels for the response variable to courses on "machine learning," a topic we can only scratch the surface of in this introductory course.

The important insight into using categorical variables in regression models is encapsulated in the idea of the 0-1 ("zero-one") encoding. To illustrate, consider the `mosaicData::Whickham` data frame that records the age, smoking status, and survival of 1000 or so nurses in the UK. The relationship that motivated the collection of these data is between smoking and survival. Taking a few rows from the data frame let's us easily see the types of the variables involved:

```{r echo=FALSE}
set.seed(101)
sample_n(Whickham, size=10) %>% knitr::kable()
```

HOW TO USE `math300::zero_one()`

Plotting a zero-one response variable with correctly labelled axes.

```{r}
P <- Whickham %>% 
  gf_jitter(zero_one(outcome) ~ age, color=~smoker, height=0.1, alpha=0.5) %>% 
  label_zero_one()
P
```

We might equally well plot age as a function of outcome:

```{r}
gf_jitter(age ~ outcome, data = Whickham, width=0.2) %>% gf_violin(color=NA, fill="blue", alpha=0.5)
```

PLOT OUT A MODEL

```{r}
mod <- mod_train(zero_one(outcome) ~ age + smoker, data = Whickham)
fun <- makeFun(mod, type="response") # NEED TO FIX BUG in `makeFun.glm()`.
P %>% mosaicCalc::slice_plot(fun(age, smoker="Yes") ~ age, color="red")
```

## Intervals

Once you have FIXES MOSAICMODEL, Generate a "prediction" interval and use gf_errorbar() to plot it over the model.

## Objectives


```{r child=Obj_file(lesson)}
```

## Reading

TBD


## Lesson

*This lesson marks the beginning of a new phase of the course. Thus far, we've worked with *techniques* for data wrangling, graphics, and regression modeling. Now we address the question of what a regression model (and other information that we might have) can tell us about the real world.*

::: {.callout-tip icon=false}
## Setup

```r
library(mosaicData)
```
:::

:::: {.callout-note icon=false}
## Guided activity: House prices

*Have students do the calculations for the first model, answering the questions that follow. After this is complete, have students do the calculations for the second model and answer those questions.*

The `mosaicData::SaratogaHouses` data frame contains information about the sales price and various attributes of about 1700 houses. (See `?SaratogaHouses` for a detailed description.)

Do a regression of `price ~ bedrooms` and explain what the regression coefficients mean.

```{r}
lm(price ~ bedrooms, data=SaratogaHouses) |> coefficients()
```

1. What are the units of the intercept and of the `bedrooms` coefficient? *Intercept in dollars, `bedrooms` in dollars per bedroom.

2. Interpret what the coefficients indicate about the price of houses and bedrooms. *Each additional bedroom adds about $50000 to the value of a house.*

3. According to the model, predict what would be the sales price (at the time the data was collected, 2006) of a house with two bedrooms? *$59863 + 2\times 48218$*

Of course, bedrooms are not the only important thing about a house. Let's include `livingArea` along with `bedrooms` in the model.

```{r}
lm(price ~ livingArea + bedrooms, data=SaratogaHouses) |> coefficients()
```

1. What are the units of the `livingArea` coefficient? *dollars per square foot*
2. What does this model say about the value of adding a bedroom? *It seems to reduce the value of the house by about $15,000.*

Based on exactly the same data, the two models seem to give contradictory statements about the value of an additional bedroom. 

i. Is one model right and the other wrong? If so, which one is right? (Explain your reasoning.) *Both models are mathematically correct. But they need to be interpreted in different ways. Each is telling us something different about the real world.*
ii. Could both models be right? If so, explain why the `bedroom` coefficients have opposite signs. *We will need to develop some additional tools and concepts before we can take on this question.*

Learning how to interpret models in terms of what they say about the world is a major theme of this second half of Math 300. 

Another, more technical question that we will address has to do with the *precision* of coefficients like 125.40 dollars per square foot. Might it actually be $200/ft^2^? How about $500/ft^2^? And how seriously should we take the sales value that we calculate by setting numbers for `bedrooms` and `livingArea` into the model?

::::

## Learning Checks

```{r child=LC_file(lesson)}
```






## Documenting software

  * File creation date: `r Sys.Date()`
  * `r R.version.string`
  * `tidyverse` package version: `r packageVersion("tidyverse")`

