---
title: "A little more detail"
---

Put the odds and ends here, then sort them out.

## Standard errors, margins of error, and confidence intervals

## Tiny $n$ (optional)

When you have a very small sample size---say, $n=2$---the values may coincidentally be very close together. Around 1907, William Gosset, a scientist at Guinness, discovered that such coincidences force "twice" to be $> 2$ in order to produce confidence intervals that reliably cover the mean of the data-generating process. Gosset's particular interest was in making sense of Guinness's standard testing protocols, which involve averaging the results from three small batches of beer ingredients. Contacting the leading statisticians of the day, Gosset was told that such small $n$ is "brewing, not statistics." Nonetheless, Gosset had to work within Guinness's testing protocols, which were indeed brewing but still needed statistical interpretation. 

Gosset carried out trials by hand, a large number of measurements from a study of criminals' hand sizes. (They did this kind of thing in 1900.)  Each measurement was written on a card. A trial consisted of drawing $n$ cards from the deck and calculating the mean and standard deviation of the measurements. Using computers, we can simulate the calculation of results from a Gosset-like trials using a simple function that calculates the mean and standard deviation of data from a Gaussian distribution.

```{r}
one_trial <- function(n=2) {
  vals <- rnorm(n)
  tibble(m = mean(vals), s = sd(vals))
}
```

We can pick a small $n$ and running many trials using a candidate value for "twice."


::: {.callout-warning}
## IN DRAFT

CONVERT the `beta` to something named `twice`.

```{r}
n=10
beta <- 2 / sqrt(n)
Trials <- do(100) * one_trial(n=n) %>% 
  mutate(left = m - beta*s, right = m + beta*s) 
gf_errorbarh(.index ~ left + right, data = Trials, alpha=0.5) %>%
  gf_errorbarh(.index ~ left + right, 
               data = Trials %>% filter(left > 0 | right < 0)) %>%
  gf_vline(xintercept = ~ 0, color="blue", inherit=FALSE)
```
Gosset effectively tabulated the $\beta$ multipliers

n  | $\beta$ | $t = \beta / \sqrt{\strut n}$
---|---------|------------------
2  | 8.98    | 12.7
3  | 2.48    | 4.30
4  | 1.59    | 3.18
5  | 1.24    | 2.78
6  | 1.04    | 2.57
7  | 0.92    | 2.44
$\vdots$ |  |
10 | 0.72    | 2.26
15 | 0.55    | 2.14
20 | 0.47    | 2.09
50 | 0.28    | 2.01
100 | 0.20   | 1.98
500 | 0.088  | 1.96
1000 | 0.062 | 1.96

You can see that for $n$ bigger than 10 or 20, the $t$ multiplier is 2. But for very small $n$, the t-multiplier can be considerably larger. 

You can see the wisdom of brewers here. They made tests by averaging measurements from three small batches of beer. If they had used only two batches, the confidence interval would be almost three times larger than for $n=3$, making it very hard to conclude anything about whether the tests show the ingredients to be within the quality-control standards.

Gosset's work was published under the pseudonym "Student," since Guinness forbade employees to publish under their own names. Statisticians, recognizing the value of the work (and knowing the name behind the pseudonym), came to use the name $t$, perhaps because tea was considered more refined than "beer." In many statistics texts, you will see the phrase "Student t" to refer to how Gosset's work is used.

## Interaction

RETURN TO THIS MODEL, but add an interaction.

```{r}
Mod3 <- lm(list_price ~ hard_paper + num_pages, data = amazon_books)
model_eval(Mod3, hard_paper = c("P", "H"),  num_pages=c(200, 400))
```

