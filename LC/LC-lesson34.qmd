---
title: "Learning Checks Lesson 34"
---

```{r include=FALSE}
source("../_startup.R")
```


`Stat2Data::FaithfulFaces`. Come back to it concerning prevalence.

## 34.1

```{r ant-take-room-default, include = FALSE}
library(tibble)
Our_data <- tribble(
  ~ species, ~ size, ~ color,
  "A", "large", "reddish",
  "B", "large", "brownish",
  "B", "small", "brownish",
  "A", "large", "brownish", 
)
Table1 <- tribble(
  ~ size, ~ prop_of_A,
  "large", "",
  "small", "",
)
Table2 <- tribble(
  ~ color, ~ prop_of_A,
  "reddish", "", 
  "brownish", "", 
)
Table3 <- tribble(
  ~ color, ~ size, ~ prop_of_A,
  "reddish", "large", "", 
  "reddish", "small", "", 
  "brownish", "large", "", 
  "brownish", "small", "", 
)
```

To illustrate how stratification is used to build a classifier, consider this very simple, unrealistically small, made-up data frame listing observations of animals:


```{r ant-take-room-1, echo = FALSE}
knitr::kable(Our_data)
```

You are going to build classifiers using the data. The output of the classifier will be the probability that the species is A. The classifier itself will be a simple table: each row lists the different levels of the explanatory variable(s) the the classifier output (as a probability that the species is A).

1. Use just `size` as an explanatory variable. Since there are two levels for size, the classifier can take the form of a simple table, giving the proportion of rows for each of the two sizes. Fill in the table to reflect the data. 


```{r ant-take-room-2, echo = FALSE}
knitr::kable(Table1)
```
::: {.callout-note}
## Solution
There are three rows where the size is large, of which one is species A. The classifier output is thus 2/3 for large.

Similarly, there is only one row where the size is small, none of which are species A. The classifier output is 0/1 for small.
:::

2. Repeat (1), but instead of "size", use just "color" as an explanatory variable.
```{r ant-take-room-3, echo = FALSE}
knitr::kable(Table2)
```

::: {.callout-note}
## Solution
There are three rows where the color is brownish, of which two are species A. The classifier output is thus 1/3 for brownish.

There is only one row where the color is reddish, and it is species A. The classifier output is 1/1 for reddish.
:::

3. Again build a classifier, but use both color and size as explanatory variables.

```{r ant-take-room-4, echo = FALSE}
knitr::kable(Table3)
```

::: {.callout-note}
## Solution
There is just one row in which color is reddish and size is large, and it is species A. The classifier output is thus 1/1.

There are two rows in which color is brownish and size is large, one of which is species A. The classifier output is thus 1/2.

There is one row in which color is brownish and size is small. It is species B. The classifier output is 1/1.

There are no rows in which color is reddish and size is small. A classifier output of 0/0 is meaningless. So our classifier has nothing to say for these inputs. 
:::

4. Finally, build the "null model", a no-input classifier. This means there is just one group, which has all four rows. -A- Of the four rows, two are species A, so the classifier output is 2/4.


--------

## 34.2

The graph below shows data on marital status versus age from National Health and Nutrition Evaluation Survey data. You can see that the probability of the various possibilities are a function of age.

```{r echo=FALSE}
library(kernlab)
library(NHANES)

NHANES_small <- 
  NHANES %>%
  dplyr::select(Age, Gender, MaritalStatus) %>%  
  mutate(MaritalStatus = as.character(MaritalStatus)) %>% 
  mutate(MaritalStatus = 
           ifelse(is.na(MaritalStatus), "NeverMarried", MaritalStatus))  %>%
  mutate(MaritalStatus = 
           factor(MaritalStatus, 
                  levels = c("NeverMarried", "LivePartner",
                             "Married", "Separated", "Divorced", "Widowed"))) 
gf_jitter(MaritalStatus ~ Age | Gender, 
          data = NHANES_small %>% filter(MaritalStatus %in% c("Widowed", "NeverMarried", "Married")), 
          alpha=0.1)
```

A very simple classifier can be constructed just by indicating at each age which marital status is the most likely, as seen in the figure below.


```{r ash-chew-kitchen-0, echo = FALSE, message=FALSE}
mod1 <- kernlab::ksvm(MaritalStatus ~ Age + Gender, data = NHANES_small, prob.model = TRUE)
Eval_at <- unique(NHANES_small)
Eval_at$response <- predict(mod1, newdata = Eval_at)
gf_line(response ~ Age | Gender, data = Eval_at, size = 2) %>%
  gf_labs(y = "Model output: Marital Status")
```

A classifier output should be a probability, not a categorical level. On the blank graph below, sketch out a plausible form for probability vs age for each of three categorical levels shown in the above plot.  (Hint: At an age where, say, "NeverMarried" is the categorical output, the probability for "NeverMarried" will be higher than the other categories.)

```{r ash-chew-kitchen-1, echo = FALSE}
Probs <- data.frame(predict(mod1, newdata = Eval_at , type  = "probabilities"))
Probs$Age <- Eval_at$Age
Probs$Gender <- Eval_at$Gender
gf_blank(NeverMarried ~ Age | Gender, data = Probs) %>%
  gf_lims(y = c(0,1)) %>%
  gf_labs(y = "Probability")
```

<!--answer-start-->

Presumably the probability output for each category varies somewhat smoothly. There are two constraints:

1. At any age/sex, one probability will be the highest of the three. That one should correspond to the category shown in the first graph.
2. The probabilities should add up to 1. 

Here's one possibility. Note that for females, the highest probability around age 80 is "widowed".

```{r ash-chew-kitchen-2, echo = FALSE}
Labels <- tribble(
  ~ Age, ~ Prob, ~  Gender, ~ Label, ~ Color,
  20, .7, "female", "Never Married", "black",
  45, 0.0, "female", "Widowed", "red",
  55, .35, "female", "Married", "blue",
  
)
gf_line(NeverMarried~ Age | Gender, data = Probs) %>%
  gf_line(Married ~ Age, color = "blue") %>%
  gf_line(Widowed ~ Age, color = "red") %>%
  gf_label(Prob ~ Age | Gender, color = ~ Color, label = ~ Label,  data = Labels) %>%
  gf_refine(scale_color_manual(values = c("black", "blue", "red"))) %>%
  gf_theme(legend.position = "none")  %>%
  gf_labs(y = "Probability")

```

<!--answer-end-->


--------

From CPS §32.6: `openintro::possum`.  Let’s investigate the possum data set again. This time we want to model a binary outcome variable. As a reminder, the common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum. We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population. The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast. The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.

We use logistic regression to differentiate between possums in these two regions. The outcome variable, called pop, takes value Vic when a possum is from Victoria and other when it is from New South Wales or Queensland. We consider five predictors: sex, head_l, skull_w, total_l, and tail_l.

Explore the data by making histograms or boxplots of the quantitative variables, and bar charts of the discrete variables.

- Are there any outliers that are likely to have a very large influence on the logistic regression model?
- Build a logistic regression model with all the variables. Report a summary of the model.
- Using the  p-values decide if you want to remove a variable(s) and if so build that model.
- For any variable you decide to remove, build a 95% confidence interval for the parameter.
- Explain why the remaining parameter estimates change between the two models.
- Write out the form of the model. Also identify which of the following variables are positively associated (when controlling for other variables) with a possum being from Victoria: head_l, skull_w, total_l, and tail_l.
- Suppose we see a brushtail possum at a zoo in the US, and a sign says the possum had been captured in the wild in Australia, but it doesn’t say which part of Australia. However, the sign does indicate that the possum is male, its skull is about 63 mm wide, its tail is 37 cm long, and its total length is 83 cm. What is the reduced model’s computed probability that this possum is from Victoria? How confident are you in the model’s accuracy of this probability calculation?

--------

## 34.3

The `HELPrct` date frame (in the `mosaicData` package) is about a clinical trial (that is, an experiment) conducted with adult inpatients recruited from a detoxification unit. The response variable of interest reflects the success or failure of the detox treatment, namely, did the patient continue use of the substance abused after the treatment.

Figure \@ref(fig:giraffe-fall-door-1) shows the output of a simple classifier (maybe too simple!) of the response given these inputs: the average number of alcoholic drinks consumed per day in the past 30 day (before treatment); and the patient's self-perceived level of social support from friends. (The scale for social support is zero to fourteen, with a higher number meaning more support.)

```{r giraffe-fall-door-1, echo = FALSE, fig.cap = "Classifier based on data from a clinical trial"}
New <- mosaicData::HELPrct %>%
  rename(social_support = pss_fr)
mod2 <- glm(anysub == "yes" ~ ns(i1,2) * social_support, data = New, 
            family = binomial )
mod_plot(mod2, data = New, social_support = c(0, 5, 10, 14 )) %>% 
  gf_labs(y = "Probability of treatment failure", 
          x = "Alcoholic Drinks per day") %>%
  gf_lims(y = c(NA,1)) %>%
  gf_theme(legend.position="top")
```

1. What's the probability of treatment failure for a patient who has 25 alcoholic drinks per day? Does the probability depend on the level of social support? -A- Probability of failure is 75%, and doesn't depend on the level of social support.

2. For a patient at 0 to 10 alcoholic drinks per day, what's the probability of treatment failure? Does the probability depend on the level of social support? -A- The probability of failure ranges from about 72% for those with no social support to 82% for those with high social support?

3. You are thinking about a friend who has roughly five alcoholic drinks per day. You are concerned that he will go on to substance abuse. Do the data from the clinical trial give good reason for your concern? Explain why or why not.

::: {.callout-note}
## Solution

It's always a good idea to be concerned for your friend, but the data reported here are not a basis for that concern. These data are from a population consisting of inpatients from a detoxification unit. These are people who have already shown strong substance abuse. The classifier is not generalizable to your friend, unless he is an inpatient from a detox unit.
:::

4. Explain what's potentially misleading about the y-axis scale selected for the plot. 

::: {.callout-note}
## Solution

The selected scale doesn't include zero and so tends to over-emphasize what amount to small differences in the probability of failure.
:::
