---
title: "Learning Checks Lesson 29"
---

```{r include=FALSE}
source("../_startup.R")
```


## LC 29.A

::: {.callout-warning}
## Still a draft

Look at `dag07`. Notice that `d` is not connected to any of the other variables.

Generate a sample of size $n=6$. Compare the sum of square residual (in sample) from the nested  models `c ~ 1`, `c ~ a` `c ~ a + b`, and `c ~ a + b + d`. (Use the `compare_model_residuals()` using the argument `method="SS"`.

Which, if any, of the variables `a`, `b`, or `d` reduces the in-sample sum-of-squared residuals compared to the previous model.


::: {.callout-note}
## Solution

```{r}
compare_model_residuals(dag07, c ~ 1, c ~ a, c ~ a + b, c ~ a + b + d, 
                        n=6, measure="SS", in_sample=TRUE)
```
:::

Out of sample, the useless covariate often *increases* the SS error.

--------

## LC 29.1

In `dag04`, build models to predict `c` from the other variables. Does one of those variables "block" the others? 

- Explain how you know this from your models. Try to give an answer in everyday language as well.
- Repeat but use a very small sample size, say $n=5$. Has your conclusion about blocking changed? Explain why.

::: {.callout-note}
## Solution
```{r}
compare_rms_error(dag04, c~ 1, c ~ d, c~ b + d, c ~ a + b + d, n=50, in_sample = TRUE)
```

`d` seems to block effect of `a` and `b` on `c`.


```{r}
compare_rms_error(dag04, c~ 1, c ~ d, c~ b + d, c ~ a + b + d, n=5, in_sample = TRUE)
```
:::

## LC 29.2

We are using in-sample testing because that is often the case in the model-building stage. However, in the model-**using** stage, things are different. You will be making predictions of new cases, that is, out-of-sample.

For out-of-sample, when working with new data, it's not just a matter of being tricked into thinking covariates are useful when they're not. Using irrelevant covariates can be genuinely harmful to the predictions.

Compare these in-sample and out-of-sample results. 

```{r}
set.seed(101)
compare_rms_error(dag07, d ~ 1, d ~ c, d~ b + c, d ~ a + b + c, n=4, in_sample = TRUE)
set.seed(101)
compare_rms_error(dag07, d ~ 1, d ~ c, d~ b + c, d ~ a + b + c, n=4, in_sample = FALSE)
```

What do you see in the results that tells you that incorporating irrelevant covariates hurts the out-of-sample predictions?




--------

## LC 29.3

::: {.callout-warning}
## In draft

`openintro::teacher`. What's the `base` pay difference between a teacher with an MA and a BA degree? What's a confidence interval on this effect size? How does the confidence interval change if you include `years` as a covariate.
:::

--------

## LC 29.4

::: {.callout-warning}
## In draft

`openintro::census` Predict log personal income based on other variables. Eat variance using the `total_family_income` variable.

```{r}
mod <- lm(log10(total_personal_income) ~ log10(age) + sex + marital_status + log10(total_family_income), data = openintro::census %>% filter(total_personal_income > 0, total_family_income > 0))
anova(mod)
gf_jitter(total_personal_income ~ total_family_income | sex, 
         data =openintro::census %>% filter(total_personal_income > 3000),
         color=~marital_status, alpha=0.3) %>% 
  gf_refine(scale_y_log10(), scale_x_log10())
```


:::

--------

## 29.5

`openintro::starbucks`  where do the calories come from?  Find effect size of, say, protein on calories. Then see what happens if you use carbohydrates as a covariate.

YOU WERE HERE

```{r}
lm( calories ~ protein, data = openintro::starbucks) %>% confint()
lm( calories ~ fat + carb + fiber + protein, data = openintro::starbucks) %>% confint()
```

::: {.comment-warning}
## In draft

Maybe come back to this in confounding lesson. Look for components that tend to go together

```{r}
with(openintro::starbucks, cor(fat, protein))
with(openintro::starbucks, cor(fiber, protein))
lm( calories ~ fiber , data = openintro::starbucks) %>% confint()
lm( calories ~ protein, data = openintro::starbucks) %>% confint()
lm( calories ~ protein + fiber, data = openintro::starbucks) %>% confint()

```

--------

## 29.6

::: {.callout-note}
## In draft

For each of a set of explanatory and response variables (possibly in different data), ask for the units of 

i. The RMS residual.
ii. The sum-of-square residual
iii. The effect size

--------



