---
title: "Learning Checks Lesson 19"
---

## Setup

The `math300` package will be needed for lessons 20 through 39.

```{r message=FALSE}
library(math300)
library(moderndive)
library(NHANES)
```


1.  One of these pipeline commands will work and the other won't. Which one will work? Explain why the other one doesn't work.

    ```{r eval=FALSE}
    lm(net ~ age, data = TenMileRace)
    TenMileRace %>% lm(net ~ age)
    ```

2.  An example from the *OpenIntro* book uses data on promotions. Some data wrangling commands that might be relevant are these:

    ```{r}
    promotions %>% tally()
    promotions %>% group_by(decision) %>% tally()
    promotions %>% group_by(gender) %>% tally()
    promotions %>% group_by(gender, decision) %>% tally()
    ```

You could use such wrangling to compare groups. For instance, you can use the results of the last command to calculate separately the proportion of males who were promoted and, similarly, the proportion of females.

a\. **What are those proportions?**

The following wrangling command will calculate the proportions for you, but it is a bit complicated:

```{r eval=FALSE}
promotions %>%
  group_by(gender) %>%
  summarize(prop_promoted = sum(decision=="promoted") / n())
```

b\. **Use the above command to check your calculations in (a).**

c\. In the regression paradigm, the comparison of proportions between the two groups is done directly in `lm()`, like this:

```{r}
promotions %>%
  mutate(promoted = zero_one(decision, one="promoted")) %>%
  lm(promoted ~ gender, data = .) %>%
  coef()
```

We'll explain the purpose of `zero_one()` in Lesson 19, but putting that matter aside for a moment, compare the two coefficients in the regression model to the proportion results you got from wrangling.

i.  **What does the value of the intercept coefficient correspond to in the wrangling results?**

ii. **What does the `genderfemale` coefficient correspond to in the wrangling results?** (Hint: you will have to do a bit of arithmetic on the wrangling results.)





## 19.1

Consider the `moderndive::evals` data that records students' evaluations (`score`, on a 1-5 scale) of the professors in each of several courses (the course `ID`), as well as the `age`, "average beauty rating" (`bty_avg`) of the professor, enrollment in the course (`cls_students`) and the level o the course (`cls_level`). Each row in the data frame is an individual course section.


```{r echo=FALSE}
set.seed(101)
sample_n(moderndive::evals %>% select(ID, score, age, bty_avg, cls_students, cls_level ),
         size=10) %>% knitr::kable()
```

The following commands model `score` versus `age` and plots the data as a point plot.

```{r}
lm(score ~ age, data = moderndive::evals) %>% coef()
openintro::evals %>% gf_point(score ~ age, alpha=0.2 )
```
1. Explain why some of the dots are darker than others?

::: {.callout-note}
## Solution

All the ages have integer values---e.g., 43, 44, 45---so the dots line up in vertical lines.

Similarly, the scores have values only to one decimal place---e.g., 3.1, 3.2, 3.3---so the dots line up in horizontal lines. If there are two or more rows in `evals` that have the same age and score, the dots will be plotted over one another. Since transparency (`alpha = 0.2`) is being used, points where there is a lot of overplotting will appear darker.
:::

2. Remake the plot, but using `gf_jitter()` instead of `gf_point()`. Explain what's different about the jittered plot. (Hint: Almost all of the dots are the same lightness.)

::: {.callout-note}
## Solution

```{r}
openintro::evals %>% gf_jitter(score ~ age, alpha=0.2 )
```

"Jittering" means to shift each dot by a small random amount. This reduces the number of instances where dots are overplotted.
:::

3. Now make a jitter plot of score versus class level (`cls_level`).
    a. What do the tick-mark labels on the horizontal axis describe? Are they numerical?
    b. To judge from the plot, are their more lower-level than upper-level courses? Explain briefly what graphical feature lets you answer this question at a glance.

::: {.callout-note}
## Solution

```{r}
openintro::evals %>% gf_jitter(score ~ cls_level)
```

a. The tick-mark labels are the levels of the categorical variable `cls_level`. The are words, not numbers.
b. There are many more dots in the right column than in the left. Since `lower` level class are shown in the left column, there are fewer lower-level courses than upper-level courses. 
:::

4. The two columns of points in the plot you made in (3) are not separated by very much empty space. You can fix this by giving `gf_jitter()` an argument `width=0.2`. Try different numerical values for `width` and report which one you find most effective at making the two columns clearly separated while avoiding overplotting.

5. Are the scores, on average, different for the lower- vs upper-level classes? It's hard to get more than a rough idea of the distribution of scores by looking at the "density" of points. The reason is that the number of points differs in the two columns. But there is an easy fix: add a layer to the graphic that shows the distribution (more or less like a histogram displays a distribution of values). You can do this by piping the jitter plot layer into a geom called a "violin," like this:

```{r}
openintro::evals %>% 
  gf_jitter(score ~ cls_level) %>%
  gf_violin(fill="blue", alpha=0.2, color=NA)
```

Explain how to read the violins.

--------

## 19.2

The `openintro::promotions` data comes the the 1970s and records the gender of 38 people along with the result of a decision to promote (or not) the person. =

Chapter 2 of ModernDive suggests graphically depicting `decision` versus `gender` by using a bar plot. There are two ways to make the bar plot, depending on which variable you assign to the horizontal axis and which to the fill color.

```{r}
#| label: fig-promotion-bars
#| fig-cap: "Two different ways to plot promotion outcome and gender"
promotions %>% gf_bar(~ decision, fill=~ gender)
promotions %>% gf_bar(~ gender, fill=~decision)
```

Plots like those in @fig-promotion-bars might be attractive or not, depending on your taste. What they don't accomplish is to make sure which is the response variable and which the explanatory variable.

The choice of response and explanatory variables depends, of course, on what you are trying to display. But everyday English gives a big hint. For instance, you might describe the question at hand as, "Does gender affect promotion decisions." Here, the variable doing the affecting is `gender`, and the outcome is the `decision`.

Modeling decision as a function of gender is easy once you convert the response variable to a zero-one variable. Like this:

```{r}
mod <- lm(zero_one(decision, one="promoted") ~ gender, data = promotions)
coefficients(mod)
mosaicModel::mod_eval(mod)
```

1. Explain what is the relationship between the model coefficients and the model outputs.

::: {.callout-note}
## Solution

The coefficients tell how to calculate the model output. These coefficients say that the model output will be 0.875, but subtract 0.292 if the person is female.

The model outputs give the probability of being promoted for each of the two genders.
:::

2. Make this plot and explain what the red lines show. (We don't expect you to be able to write the command to generate such plots on your own, but we do expect you to be able to interpret them.)

```{r eval=FALSE}
promotions %>% 
  gf_jitter(zero_one(decision) ~ gender, height=0.2, width=0.2) %>%
  gf_errorbar(model_output + model_output ~ gender, data=mod_eval(mod), 
              color="red", inherit=FALSE) %>%
  label_zero_one()
```

::: {.callout-note}
## Solution

The red lines show the proportion of the people in each gender group who were promoted. The y-axis scale on the left refers to the zero-one encoding of `decision`, while the y-axis labels on the right make it easier to read off the numerical value of the proportion.
:::

--------

## 19.3

The `mosaicData::Whickham` data from comes from a survey of a thousand or so nurses in the UK in the 1970s. The data record the `age` of each nurse along with whether the nurse was still alive in a follow-up survey 20 years later (`outcome`).

Make this graph from the `Whickham` data:

```{r}
gf_jitter(zero_one(outcome) ~ age, data = Whickham, alpha=0.3, height=0.1) %>% 
  label_zero_one() 
 
```
1. Explain in everyday language what the graph shows about the lives of humans.

2. Make the graph again, but leave out the `%>% label_zero_one()`. Then explain what `label_zero_one()` does.

::: {.callout-note}
## Solution

1. The graph shows that young nurses tended to be alive at the 20-year follow-up, older nurses not so much.

2. `%>% label_zero_one()` adds an axis on the left of the graph showing that in the zero-one tranform of `outcome`, "Alive" is assigned the value 1 and "Dead" the value 0.
:::

### Solution

--------

## 19.4

About the summarization of models. Pipe the model fit into any of four functions:

i. `%>% coef()`
ii. `%>% regression_summary()`
iii. `%>% rsquared()`
iv. `%>% confint()`

REDO `confint()` so that the columns are named `lower`, `middle`, `upper`

### Solution


--------

## 19.5 (Obj. 19.3)

Calculation of a 95% coverage interval (or any other percent level interval) is straightforward with the right software. To illustrate, consider the efficiency of cars and light trucks in terms of CO_2 emissions per mile driven. We'll use the `CO2city` variable in the `math300::MPG` data frame. The basic calculation using the `mosaic` package is:


```{r kangaroo-freeze-candy-1, echo = TRUE}
df_stats( ~ CO2city, data = math300::MPG, coverage(0.95))
```

The following figure shows a violin plot of `CO2city` which has been annotated with various coverage intervals. Use the calculation above to identify which of the intervals corresponds to which coverage level.

1. 50% coverage interval -A- (c)
2. 75% coverage interval -A- (e)
3. 90% coverage interval -A- (g)
4. 100% coverage interval -A- (i). This extends from the min to the max, so you could have figured this out just from the figure.

```{r kangaroo-freeze-candy-2, echo = FALSE}
Res <- NULL
levels <- c(0.2, 0.4, 0.5, 0.6, 0.75, 0.80, 0.90, 0.95, 1.00)
letters <- base::letters[1:length(levels)]
for (k in 1:length(levels)) {
  new <- df_stats( ~ CO2city, data = math300::MPG, coverage(!!levels[k]))
  new$id <- paste0("(", letters[k], ")")
  new$x <- 0.75 + k/20
  Res <- bind_rows(Res, new)
}
gf_violin(CO2city ~ 1, data = math300::MPG, alpha = 0.25, fill = "blue", color = NA) %>%
  gf_errorbar(lower + upper ~ x, data = Res, inherit=FALSE) %>%
  gf_text(upper ~ x, label = ~ id, data = Res, nudge_y = 30) %>%
  gf_lims(x = c(.5, 1.5))
```


--------

## 19.6 (Obj 19.3)

The two jitter + violin graphs below show the distribution of two  different variables, X and Y. Which variable has more variability?



```{r goat-take-linen-1, echo = FALSE, fig.show = "hold", out.width = "50%"}
set.seed(101)
Data <- data.frame(x = rnorm(500, mean = 50, sd = 10)) %>%
  mutate(y = 7 * round(x /  7), pos = " ")
gf_jitter(x ~ pos, data = Data, seed = 400, width = 0.2, alpha = 0.5) %>%
  gf_violin(fill = "gray", color = NA, alpha = 0.5) %>%
  gf_labs(y = "Variable A", x = "", title = "(a)") %>%
  gf_lims(y = c(15, 85))
gf_jitter(y ~ pos, data = Data, height = 1,  seed = 400, alpha = .5) %>%
  gf_violin(fill = "gray", color = NA, alpha = 0.5, bw = 2) %>%
  gf_labs(y = "Variable B", x = "", title = "(b)")   %>%
  gf_lims(y = c(15, 85))
```

::: {.callout-note}
## Solution

There is about  the same level of variability in variable A and variable B. This surprises some people. Remember, the amount of variability has to do with the spread of *values* of the variable. In variable B, those values are have a 95% prediction interval of about 30 to 65,  about the same as for variable A. There are two things about plot (b) that  suggest to many people that there is more variability in  variable B. 

1. The larger horizontal spread of the dots. Note that variable B is shown along the vertical axis. The horizontal spread imposed by  jittering is completely arbitrary: the only values that count are on the y axis.  
2.  The  scalloped, irregular edges of the violin plot. 

On the other hand, some people look at the clustering of the data points in graph (b) into several discrete values, creating empty spaces in between. To them, this clustering implies less variability. And, in a way, it does. But the *statistical* meaning of variability has to do with  the overall spread of the  points, not whether they are restricted to discrete values.   

:::

--------

## 19.7 (Objs. 19.3 & 19.4)

The graphs below show a violin plot of body mass index (BMI) for adults and children. One of the graphs shows a correct 95% coverage interval on BMI, the other does not.

Identify the incorrect graph and say what feature of the graph led to your answer.


```{r goat-hurt-painting-1, echo = FALSE}
Dat <- NHANES %>%
  dplyr::select(BMI, Age) %>%
  mutate(age_group = ifelse(Age < 18, "Child", "Adult")) %>%
  na.omit() 
Intervals <- df_stats(BMI ~ age_group, data = Dat, 
                      ci = coverage(0.95))
P <- gf_violin(BMI ~ age_group, data = Dat, alpha = 0.2, fill = ~ age_group, color = NA) %>%
  gf_theme(legend.position="none",axis.text = element_text(size = 20), 
           plot.title = element_text(size = 30)) %>%
  gf_labs(y = "Body Mass Index", x = "")
Bogus_intervals <- Intervals %>% mutate(age_group = ifelse(age_group == "Child", "Adult", "Child"))

P %>% 
  gf_errorbar(ci_lower + ci_upper ~ age_group, data = Bogus_intervals,
              width = 0.2, size = 2, color = ~ age_group, inherit=FALSE) %>%
  gf_labs(title = "(a)")
P %>% 
  gf_errorbar(ci_lower + ci_upper ~ age_group, data = Intervals,
              width = 0.2, size = 2, color = ~ age_group, inherit=FALSE) %>%
  gf_labs(title = "(b)")
```

::: {.callout-note}
## Solution
Graph (b) is correct. In graph (a), you can see that the interval fails to include a lot of the low BMI children and extends too high. For adults, the graph (a) interval extends too far low and doesn't go high enough.
:::

--------

## 19.E

There are two equivalent formats describing an interval numerically that are widely used:

i. Specify the lower and upper endpoints of the interval, e.g. 7 to 13.
ii. Specify  the center and half-width of the interval, e.g. 10 ± 3, which is  just the same as 7 to 13.

Complete the following table to show the equivalences between the two notations.

```{r rabbit-put-pen-1, echo=FALSE}
This_table <- tribble(
~ Interval, ~ "bottom-to-top", ~ "plus-or-minus",
"(a)", "3 to 11", "",
"(b)",  "" , "108 ± 10",
"(c)", "", "30 ± 1",
"(d)",  "97 to  100"  , "",
"(e)",  "-4 to  16"   , "",
)
knitr::kable(This_table)
```

::: {.callout-note}
## Solution

a. 7 ± 4
b. 98 to 118
c. 29 to 31
d. 98.5 ± 1.5
e. 6 ± 10

It's a matter of judgement which format to use. The bottom-to-top notation highlights the range of the interval  while the plus-or-minus notation emphasizes the center of the interval. As a rule of thumb, I suggest this:

* If the first two digits are different between the top and bottom of the interval, use the bottom-to-top notation. So,  write 387 to 393.  If the first two digits are the same, use plus-or-minus. For instancer, the ratio of the mass of the Earth to that of the Moon is 81.3005678 ± 0.0000027. This is easier to take in at a glance than the equivalent 81.3005651 - 81.3005708

:::

--------

## 19.F

::: {.callout-warning}
## Still in draft

Suppose there are other explanatory variables to be displayed. In that case, we will use color and faceting. If there are *no* explanatory variables, as in `y ~ 1`, we will jitter the data horizontally to avoid overplotting.]
:::


--------

## Demonstration: Predicting calorie content

Starbucks is a famous coffee-shop franchise with more than 30,000 branches (as of 2021). People go to Starbucks for coffee, but they often buy something to eat as well. In this demonstration, we will look at the calorie content of Starbucks' food offerings. As always, when conducting a statistical analysis, it is helpful to have in mind the motivation for the task. So we will imagine, tongue in cheek, that we want to make food recommendations for the calorie-conscious consumer.

First, a **point summary** of the calories in the different types of food products available at Starbucks:

```{r echo=FALSE}
point_summary <- 
  df_stats(calories ~ type, 
           data = openintro::starbucks, mean)
```

```{r}
df_stats(calories ~ type, 
         data = openintro::starbucks, mean)
```

This summary supports the sensible advice to choose salads or smaller portions (type "petite") to avoid calories. One might go further, for example, concluding that a sandwich is a poor choice (in terms of calorie content), so lean toward parfaits or hot breakfasts. We can even imagine someone concluding from this summary that a bistro box is a better calorie-conscious choice than a sandwich.

@fig-starbucks-food shows the point summary, using the raw data to put things in context.

```{r}
#| label: fig-starbucks-food
#| fig-cap: "Calories of the various food items sold by Starbucks, annotated with point and interval summaries."
#| fig-cap-location: margin
#| code-fold: true
openintro::starbucks %>% 
  ggplot(aes(x=type, y=calories)) +
  geom_jitter(width=0.2, alpha=0.5) +
  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), 
                y=NA, color="blue") +
  geom_point(data=point_summary, aes(y=mean), color="red")
```

Plotting the point summary in the context of the raw data shows at a glance that the point summary is not of any genuine use. For instance, using the point summary without the data, we might conclude that hot breakfasts are better than sandwiches. However, the data display suggests otherwise; there is just one low-calorie breakfast. The others are much like sandwiches.

A point summary is compact but cannot represent the *variation* within each food type. An interval summary, as in @fig-starbucks-food2, does show this variation. 

```{r}
#| label: fig-starbucks-food2
#| fig-cap: "Calories of the various food items sold by Starbucks, annotated with point and interval summaries."
#| fig-cap-location: margin
#| code-fold: true
openintro::starbucks %>% 
  ggplot(aes(x=type, y=calories)) +
  geom_jitter(width=0.2, alpha=0.5) +
  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), 
                y=NA, color="blue") 
```

Unlike point summaries, interval summaries can overlap. Such overlap indicates that the groups are not all that different. Here, the interval summary indicates an appropriate conclusion; "Don't make your diet choices based on food type. Look at the calorie content of individual items before choosing."

Admittedly, in this simple setting the data themselves would lead to the conclusion. However, as we move into more complicated settings, it will become infeasible to see patterns quickly straight from the data. 






