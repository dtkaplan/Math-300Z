---
title: "Learning Checks Lesson 24"
---

```{r include=FALSE}
source("../_startup.R")
```

::: {.callout-warning}
## Just to help when writing problems

24.1 Estimate an effect size from a regression model of one and two variables.

24.2 Construct a confidence interval on the effect size.

24.3. Gaming: Evaluate whether confidence interval indicates that estimated effect size is consistent with simulation.
:::

SOME IDEAS FOR EXERCISE MODES

a. Use `mod_plot()` and look at the slope of lines and offsets. Compare to the model coefficients.

b. Generate data from a DAG and look at the confidence interval on the effect size. Then make new samples and see if the effect size in those samples is consistent with the confidence interval. 

c. In text, maybe look at the confidence intervals across new samples and show that they tend to overlap. Only a few of them don't touch a common line. This is basically just a review of confidence intervals, but why not?

d. Interaction. Show that when there is an interaction term, the effect size (as calculated by `mod_effect()`) is not constant, as it is for models with purely linear terms. 

## LC 24.1

The [*Computational Probability and Statistics*](https://github.com/DS-USAFA/Computational-Probability-and-Statistics/blob/main/data/Stanford_heart_study.csv) text describes an early study on human-to-human heart transplantation:

> "The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. [[Not in data set: Another variable called [MISSING] was used to indicate whether or not the patient was alive at the end of the study.]]"

The data frame is called `Transplants`. [NEED TO MOVE TO PACKAGE]

```{r echo=FALSE}
Transplants <- read.csv("data/Stanford_hear_study.csv")
```

You're going to build a model of `outcome` vs `group` based on the data in `Transplants`. The `outcome` variable has levels `"Dead"` and `"Alive"`, that is, it is a two-level categorical variable. Consequently, the model output will be the **probability** that the transplant candidate was alive at the end of the study.

1. Build a model `outcome == "Alive" ~ group` from the `Transplants` data. Pay close attention to the left-hand side of the tilde expression: it is a calculation that produces a 1 if `outcome` is `"Alive"` and zero otherwise. Notice the **double equal signs** and the quotes around `"Alive"`.

::: {.callout-note}
## Solution

```{r}
mod <- lm(outcome == "Alive" ~ group, data = Transplants)
```
:::

2. The sole explanatory variable here, `group` also is categorical. It has levels `"Control"` and `"Treatment"`. 

    i. Using `eval_mod()`, find the probability of being alive at the end of the study for the Control group and for the treatment group.
    ii. The two probabilities in (ii) do not add up to zero. Explain why.

::: {.callout-note}
## Solution

```{r}
mod_eval(mod, group="Treatment")
mod_eval(mod, group="Control")
```
:::
  
    
3. Find the effect size of the treatment. All you need is your results from (2)? 

4. Use `mod_effect(`modelname`, ~ group)` to calculate the effect size. 

    i. Is the result consistent with what you found in (3).
    ii. Explain in everyday language what this effect size means.
    
::: {.callout-note}
## Solution

```{r}
mod_effect(mod, ~ group)
```
:::

--------

## 24.2

Effect sizes generally come with *units* and you have to take into account the units in order to know if the effect is important or not.

::: {.callout-warning}
## In draft

Move the `Loans` data into the `math300` package. But for now ...

```{r}
Loans <- readr::read_csv("data/loans.csv")
```

A case in point is provided by the `Loans` data frame, which records dozens of variables on each of 10,000 loans made through the Lending Club. The interest rate at which the loans are made varies substantially from loan to loan. Presumably, higher interest rates reflect a higher perception of risk of default (which would lead to the lender losing his or her money).

Here's a model of the interest rate. (This is for the borrowers who have a low debt-to-income percent; we won't worry about the few very high debt-to-income cases.) We're only interested in this problem with the effect size, which is the same as the coefficients on the model.

```{r}
mod <- lm(interest_rate ~ homeownership + debt_to_income + 
            account_never_delinq_percent + verified_income, 
          data = Loans %>% filter(debt_to_income<50))
mod %>% confint()
```

There are two *quantitative* explanatory variables---`debt_to_income` and `account_never_delinq_percent`---both of which are measured in percent. 

There are two *categorical* explanatory variables: `homeownership` and `verified_income`. The levels for `homeownership` are "MORTGAGE" (meaning money is still owed on the house), "OWN" (without a mortgage), and "RENT" (meaning the borrower rents rather than owning a home). The levels for `verified_income` are "Not Verified", "Verified", "Source Verified". 

For the categorical explanatory variables (and the intercept) the effect-size units are "percent interest." For the quantitative explanatory variables, the effect-size units are "percent interest per percent," so that when multiplied by the `debt_to_income` percent or the `account_never_delinq_percent` the result will be in "percent interest."

1. According to the model, who pays the higher interest rate (on average): people who OWN their home, people who RENT, or people who have a mortgage on their home? How much higher than the lowest-interest rate category.

::: {.callout-note}
## Solution

People who rent pay the highest interest rate, a little more than 1 percentage point higher than people who have mortgages. It's interesting that people who own their homes outright pay (on average) pay about 0.45 percentage points more than people who own outright. This might be because having a mortgage means you also have a credit history.
:::

2. According to the model, who pays the higher interest rate (on average): people whose income is "not verified," people whose income is "verified," or people who have the source of income verified (level: "source verified")?

::: {.callout-note}
## Solution

People whose income is verified pay about 3 percentage points higher interest than people whose income is "not verified." This seems surprising, but it may be that people who have higher perceived default risk are also the people who are asked to verify their income. Things get complicated when explanatory variables are linked to each other.
:::

3. The coefficients on `debt_to_income` and `account_never_delinq_percent` are the smallest numerically. Does this mean that the effects of `debt_to_income` and `account_never_delinq_percent` are smaller than the other two explanatory variables in the model? Explain why or why not. (Hint: Look at the distribution of `debt_to_income` and `account_never_delinq_percent` to get an idea for the range of values these variables take on.)

::: {callout-note}
## Solution

`debt_to_income` varies over about 25 percentage points. The variation in `account_never_delinq_percent` is about the same, varying from about 80 to 100 percentage points. The effect of the variables (in percent interest) is determined by multiplying the coefficients by the amount of variation in the variables. So, from one extreme to the other, the effect of `debt_to_income` is about 2 perentage points of interest, and roughly the same for `debt_to_income`.
:::



--------

## 24.3

In very simple settings, you don't need access to the original data: a simple summary will do.  

::: {.callout-warning}
## In draft

Use the `data/bloodthinner.csv` data from *CPS* chapter 19. Create the table of counts and calculate the effect size/probabilities from that.
:::

--------


Possibly `Stat2Data::ArcheryData` and ask about effect size.


