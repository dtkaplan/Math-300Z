[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math 300Z",
    "section": "",
    "text": "Math 300Z is the prototype for scheduled revisions to Math 300. The revisions apply only to Lessons 19 and up; the first 18 lessons come from Math 300.\nLesson 19. Topic: Variation (Mar 3) Reading, Activity: Measuring by eye\nLesson 20: Topic: DAGs and simulation (Mar 7) Reading, Activity: Life savers?\nLesson 21: Topic: Signal and noise (Mar 9) Reading, Activity: Membrane channels Handout\nLesson 22: Topic: Sampling variation (Mar 13) Reading, Activity: Counts and waiting times\nLesson 23: Topic: Confidence intervals (Mar 15) Reading, Activity: Got you covered!\nLesson 24: Topic: Effect size (Mar 17) Reading, Activity: With respect to …\nLesson 25: Topic: Prediction mechanics (Mar 19) Reading, Activity:\nLesson 26: Topic: Prediction intervals (Mar 23) Reading, Activity: Intervals by eye, Handout\nLesson 27: REVIEW of lessons 19-26 :: Reading\nLesson 28: Topic: Covariates :: Reading, Activity:\nLesson 29: Topic: Covariates eat variance :: Reading, Activity:\nLesson 30: Topic: Confounding :: Reading, Activity:\nLesson 31: Topic: Spurious correlation :: Reading, Activity:\nLesson 32: Topic: Experiment & random assignment :: Reading, Activity:\nLesson 33: Topic: Measuring and accumulating risk :: Reading, Activity:\nLesson 34: Topic: Constructing a classifier :: Reading, Activity:\nLesson 35: Topic: Accounting for prevalence :: Reading, Activity:\nLesson 36: Topic: Hypothesis testing :: Reading, Activity:\nLesson 37: Topic: Calculating a p-value :: Reading, Activity:\nLesson 38: Topic: False discovery with hypothesis testing :: Reading, Activity:\nLesson 39: REVIEW of lessons 28-38 :: Reading\nLesson 40: Review of entire course"
  },
  {
    "objectID": "index.html#course-textbooks",
    "href": "index.html#course-textbooks",
    "title": "Math 300Z",
    "section": "Course textbooks",
    "text": "Course textbooks\n\n\nFor Lessons 19-39, the textbook is Lessons in Statistical Thinking"
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Math 300Z",
    "section": "Software",
    "text": "Software\nThe POSIT.cloud workspaces will already have the packages installed. If you are running RStudio on your laptop (that is, not in a browser), the following command will install the packages.\ninstall.packages(c(\"mosaic\", \"ggplot\", \"dplyr\", \"openintro\", \"moderndive\", \"nycflights13\", \"knitr\"))\n# addition package for Math 300Z\nremotes::install_github(\"dtkaplan/math300\")\n\nA note on computing summaries of data"
  },
  {
    "objectID": "index.html#first-half",
    "href": "index.html#first-half",
    "title": "Math 300Z",
    "section": "First half of Math 300, Jan. and Feb. 2023",
    "text": "First half of Math 300, Jan. and Feb. 2023\n\n\nFor Lessons 1-18, the textbook is Statistical Inference via Data Science\n\n\n\n\nData, graphics, wrangling\nReading: SIDS Chapters 1 through 4\n\nData with R\nScatterplots\nLinegraphs, histograms, facets\nBoxplots and barcharts\nfilter and summarize\ngroup_by, mutate, arrange\njoin, select, rename, & top n\nImporting data\nCase study/review\nGR1 (chapters 1-4)\n\nRegression\nReadings 11. SLR: Continuous x 12. SLR: Discrete x 13. SLR: Related topics 14. Multiple regression: Numerical & discrete 15. Multiple regression: Two numerical 16. Multiple regression: Related topics 17. Multiple regression: Conclusion/review 18. GR 2 (chapters 5-6)"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Ruler-activity-handout.html",
    "href": "Day-by-day/Lesson-19/Ruler-activity-handout.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "In this activity, you will be given two strips of paper printed with:\n\nAn empty rectangular box\nA ruler\n\n\n\n\nWithout using the ruler at all, subdivide by eye the rectangular box into three equal-sized sections, like this:\n\n\n\n\n\n\n\nNow the ruler comes into play. Measure the lengths of your three subdivisions using the ruler.\nRecord your three measurements in this spreadsheet. Also create an ID for yourself, for example your initials or the initials of your favorite aunt, baseball player, or whatever.\n\n\n\nLink to a spreadsheet for data entry\n\nOnce everyone has entered their measurements, copy the following statement into the console in Posit.cloud and run it to create a data frame named Thirds.\n\n\nThirds <- readr::read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT_asFV5LD312bYaGgHK3F91kgLVSiaQpNhggDilfPKAiDBNz9iueOiYWKgAtRRwkFlOz6U9znbiMGK/pub?gid=0&single=true&output=csv\")\n\n\nFollow the instructions given in class. These will have you\n\nCalculate the variance of the three measurements for each student separately. Use mutate() to calculate modulus <- ((left-middle)^2 + (left-right)^2 + (middle-right)^2)/3, storing the result back in Thirds as a variable named modulus.\nAnalyze how good you and your colleagues are at sub-dividing evenly by eye.\nCreate a new dataframe that is Thirds re-arranged into “long” format.\n\n Long_form <- tidyr::pivot_longer(Thirds, !Student_initials, names_to = \"position\")\n\nGroup Long_form by student initials and calculate the variance of value. Compare these values to those stored under modulus in Thirds.\n\n\n\n\n\n\nWhy is it not useful, for the purposes of measuring the quality of the subdivision, to calculate the mean of the left, middle, and right segment lengths?\nWhat did you look for in Step (ii)?"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "You have been learning some basics of data wrangling and visualization, along with what ModernDive calls “basic regression” and “multiple regression.” These are tools which you will continue to use in the second half of the semester.\nThe major theme of the second half of the semester is to identify patterns in data and evaluate/assess what you’ve identified to see if it’s useful for your purposes.\nAs an example of a pattern, let’s look at some Department of Transportation data on models of cars stored in the MPG data frame. We will start by looking at the link between fuel economy and CO_2_ production.\n\nggplot(MPG, aes(x = fuel_year, y = CO2_year)) +\n  geom_jitter(alpha=.3)\n\n\n\n\nThis is a very strong pattern. fuel_year and CO2_year are practically the same thing.\n\nWhy?\nWhy are there some points off of the straight line describing the large majority of points?\n\nMachine learning approach: Start with nothing and take away variables that are meaningless\n\nrpart::rpart(CO2_year ~ fuel_year + ., \n             data = MPG %>% \n               select(-CO2combined, -mpg_comb, -EPA_fuel_cost))\n\nn= 1154 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 1154 983805200 4055.459  \n   2) fuel_year< 477.3361 727 203825200 3497.221  \n     4) fuel_year< 382.5226 278  40816780 2953.129  \n       8) CO2hwy< 229.5 43   5251163 2259.070 *\n       9) CO2hwy>=229.5 235  11061500 3080.128 *\n     5) fuel_year>=382.5226 449  29755260 3834.098  \n      10) fuel_year< 427.1553 211   4069879 3610.758 *\n      11) fuel_year>=427.1553 238   5829750 4032.101 *\n   3) fuel_year>=477.3361 427 167698900 5005.902  \n     6) fuel_year< 597.6272 328  33347410 4736.738  \n      12) fuel_year< 536.1372 181   5201859 4490.884 *\n      13) fuel_year>=536.1372 147   3734356 5039.456 *\n     7) fuel_year>=597.6272 99  31857170 5897.677  \n      14) model=488 Pista Spider,911 GT3,911 GT3 RS,911 GT3 Touring,AMG GLE 63,AMG GLE 63 S,AMG GLE 63 S (coupe),AMG GLS 63,AMG S 65,AMG S 65 (convertible),AMG S 65 (coupe),ARMADA 2WD,ARMADA 4WD,C10 SIERRA 2WD CAB CHASSIS,C10 SILVERADO 2WD CAB CHASSIS,CAMARO,CANYON CAB CHASSIS 2WD,Challenger SRT,Charger SRT,COLORADO CAB CHASSIS 2WD,COLORADO ZR2 4WD,CORVETTE,CTS-V,Cullinan,Dawn,Durango AWD,Durango SRT AWD,ESCALADE 4WD,F150 5.0L 4WD FFV GVWR>7599 LBS,F150 RAPTOR 4WD,G 550,Ghost,Ghost EWB,GLS 550 4MATIC,Grand Cherokee 4X4,Grand Cherokee SRT 4x4,GRANTURISMO CONVERTIBLE,GX 460,Huracan,Huracan 2WD,Huracan Spyder,Huracan Spyder 2WD,K10 SIERRA 4WD,K10 SIERRA 4WD CAB CHASSIS,K10 SILVERADO 4WD CAB CHASSIS,K10 SILVERADO 4WD TRAILBOSS,K1500 SUBURBAN 4WD,K1500 YUKON XL 4WD,LAND CRUISER WAGON 4WD,LEVANTE GTS,LEVANTE Trofeo,LX 570,M6 Gran Coupe,M760i xDrive,Maybach S 650,MKT HEARSE AWD,MKT LIMO AWD,Phantom,Phantom EWB,QX80 2WD,QX80 4WD,Range Rover LWB SVA,Range Rover Sport SVR,Range Rover SVA,Roush Stage 3 Mustang,SEQUOIA 2WD,SEQUOIA 4WD,Transit T150 Wagon,TRANSIT T150 WAGON FFV,TUNDRA 2WD,TUNDRA 4WD,TUNDRA 4WD FFV,Urus,Wraith,X6 M 89   6972789 5743.371 *\n      15) model=812 Superfast,Aventador Coupe,Aventador Roadster,Chiron,F150 Pickup 2WD,F150 Pickup 4WD,FORD GT,Grand Cherokee Trackhawk 4x4,GTC4Lusso,Mulsanne 10   3905090 7271.000 *\n\n\n\nggplot(MPG, aes(x = fuel_year, y = CO2_year)) +\n  geom_jitter(alpha=.3, aes(color=fuel))\n\n\n\n\nThe main tool we will use to identify patterns is regression modeling. Here’s the regression modeling description of the CO_2_ production problem:\n\nmod1 <- lm(CO2_year ~ fuel_year, data = MPG)\nmod2 <- lm(CO2_year ~ fuel_year * fuel, data = MPG)\n\nHow do we compare these two models to see if fuel is really the explanation? You will be learning a handful of techniques for summarizing models and, more important, when and why you would want to use each of the tools.\n\nmod1\n\n\nCall:\nlm(formula = CO2_year ~ fuel_year, data = MPG)\n\nCoefficients:\n(Intercept)    fuel_year  \n     54.050        8.782  \n\nmod2\n\n\nCall:\nlm(formula = CO2_year ~ fuel_year * fuel, data = MPG)\n\nCoefficients:\n      (Intercept)          fuel_year              fuelG             fuelGM  \n         118.8428             9.8895          -121.7502          -127.5287  \n           fuelGP            fuelGPR    fuel_year:fuelG   fuel_year:fuelGM  \n         -93.9667           -94.9800            -0.9971            -0.9866  \n fuel_year:fuelGP  fuel_year:fuelGPR  \n          -1.0758            -1.0686  \n\nanova_summary(mod1, mod2)\n\n# A tibble: 2 × 7\n  term                        df.residual      rss    df   sumsq stati…¹ p.value\n  <chr>                             <dbl>    <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n1 CO2_year ~ fuel_year               1152 7020002.    NA NA          NA       NA\n2 CO2_year ~ fuel_year * fuel        1144  917314.     8  6.10e6    951.       0\n# … with abbreviated variable name ¹​statistic\n\n\n\nVals <- model_eval(mod2)\n\nUsing training data as input to model_eval().\n\nggplot(Vals, aes(y=.resid, x=1)) +\n  geom_jitter()\n\n\n\nBig_ones <- abs(Vals$.resid) > 100\nMPG[Big_ones,]\n\n# A tibble: 16 × 39\n   manufacturer divis…¹ model fuel_…² CO2_y…³ hybrid class doors vol_p…⁴ vol_l…⁵\n   <chr>        <chr>   <chr>   <dbl>   <dbl> <chr>  <chr> <dbl>   <dbl>   <dbl>\n 1 aston martin Aston … Vant…    477.    4350 not    Two …    NA      NA      NA\n 2 Volkswagen … Lambor… Aven…    912.    7840 not    Two …    NA      NA      NA\n 3 Volkswagen … Lambor… Aven…    923.    7940 not    Two …    NA      NA      NA\n 4 Volkswagen … Lambor… Hura…    674.    5850 not    Two …    NA      NA      NA\n 5 Volkswagen … Lambor… Hura…    674.    5850 not    Two …    NA      NA      NA\n 6 Toyota       LEXUS   RC 3…    465.    4360 not    Subc…     2      84      10\n 7 Toyota       LEXUS   RC 3…    465.    4360 not    Subc…     2      84      10\n 8 General Mot… Chevro… CRUZE    272.    2940 not    Comp…     4      94      10\n 9 Subaru       Subaru  WRX      487.    4200 not    Comp…     4      97      12\n10 General Mot… Chevro… CRUZ…    286.    3100 not    Mids…    NA      95      19\n11 Nissan       INFINI… Q70      469.    4330 not    Mids…     4     104      15\n12 Kia          KIA MO… Opti…    347.    3250 not    Larg…     4     105      16\n13 FCA US LLC   Chrysl… Paci…    451.    4160 not    Spec…    NA      NA      NA\n14 Jaguar Land… Jaguar  Jagu…    419.    3950 not    Smal…    NA      NA      NA\n15 Toyota       LEXUS   RX 3…    471.    4320 not    Smal…    NA      NA      NA\n16 Volkswagen … Lambor… Urus     718.    6170 not    Stan…    NA      NA      NA\n# … with 29 more variables: displacement <dbl>, model_year <dbl>,\n#   transmission <chr>, mpg_city <dbl>, mpg_hwy <dbl>, mpg_comb <dbl>,\n#   CO2city <dbl>, CO2hwy <dbl>, CO2combined <dbl>, regen <lgl>,\n#   valves_exhaust <dbl>, valves_intake <dbl>, start_stop <chr>,\n#   cyl_deact <chr>, vol_passengers2D <dbl>, vol_passengers4D <dbl>,\n#   vol_passengersH <dbl>, vol_luggage2D <dbl>, vol_luggage4D <dbl>,\n#   vol_luggageH <dbl>, fuel <chr>, drive <chr>, n_gears <dbl>, n_cyl <dbl>, …\n\nggplot(MPG %>% mutate(ratio=CO2_year/fuel_year), aes(y=ratio, color=fuel, x=1)) + geom_jitter()\n\n\n\n\n\n\n\nMotivating problem: Designing an enforcement regime for limits on scallop fisheries.\n\n\n\n\n\nFigure 1: Life cycle of a scallop\n\n\n\n\nFisheries are regulated by states and the Federal government in order to avoid collapse due to over-fishing. Often, the regulations attempt to protect juveniles—animals that have not yet reached reproductive age. If the juveniles are harvested, their potential progeny are annihilated. There are various ways to do this, for instance restricting fishing to months where adults are most prevalent, closing fisheries to provide an opportunity for the reproductive stock to recover, and so on.\nIn the 1990s, one of the ways the Federal government regulated scallop fisheries was by setting a minimum acceptable size for harvested scallops. For practical reasons, rather than monitoring individual scallops, the government monitored the average per scallop weight of each boat’s catch. For the sake of the example, imagine that the minimum acceptable weight is 1/30 pound.\nA fishing boat might have 10,000 or more bags of scallops, which can be handled individually: weigh the bag, then count the number of scallops to get the average weight per scallop.\nDiscussion questions:\n\nHow many bags should be sampled? Should this depend on the number of bags in the cargo. For instance, should a cargo of 1000 bags be sampled differently than a cargo of 10,000 bags.\nWhat should be the threshold for declaring the whole cargo below minimum size? (The whole catch is confiscated in such a case.)\n\nIn this section of the course, you’ll learn some statistical concepts and methods that allow the above questions to be answered to produce a regulation that is protective and fair to the fishermen.\nOne idea is very simple: sampling variation. This is about how much the average per-scallop weight will vary from one bag to another.\nAnother idea is very subtle: What you can say about the whole cargo based on a sample of \\(n\\) bags.\n\n\n\n\nWhy variation is central to thinking about data.\nHow to measure variation: the variance.\nAccounting with variance: what’s explained and what’s still not explained."
  },
  {
    "objectID": "Day-by-day/Lesson-26/Intervals-by-eye.html#intervals-by-eye",
    "href": "Day-by-day/Lesson-26/Intervals-by-eye.html#intervals-by-eye",
    "title": "Spring 2023 Math 300Z",
    "section": "Intervals by eye",
    "text": "Intervals by eye\n\nIn this activity, you are given some point plots of data: y vs x. Your job is to\n\nsketch in an appropriate model fitted (by eye) to the data.\nadd a prediction band showing for each value of x what is the prediction interval\ntransform the prediction band into a confidence band.\n\nTIPS:\n\nThe fitted model will be a line or curve, or in the case of Model 3, two lines.\nThe bounds of the prediction band will be more-or-less parallel to the fitted model, but should include roughly 95% of the \\(n\\) points in the plot.\nThe confidence band is narrower than the prediction band by a factor of \\(1/\\sqrt{n}\\).\n\n\n\n\n\nModel 1: A straight-line model y ~ x\n\n\n\n\n\n\n\n\nModel 2: A sine-wave model, y ~ sin(x)\n\n\n\n\n\n\n\n\n\nModel 3: A function of two variables, y ~ x + group"
  },
  {
    "objectID": "Day-by-day/Lesson-21/Patch-clamping.html#membrane-channels",
    "href": "Day-by-day/Lesson-21/Patch-clamping.html#membrane-channels",
    "title": "Spring 2023 Math 300Z",
    "section": "Membrane channels",
    "text": "Membrane channels\nElectrical signaling is one of the means of cell-to-cell communication in organisms. Familiar examples are nerve cells and muscle cells. The electrical activity is mediated by assemblies of a few proteins—called “membrane channels”—that penetrate the cell membrane and switch minute flows of electrical current on and off depending on conditions in the cell and the influence of neighboring cells.\nAmazingly, even though this activity involves only thousands of atoms, it is possible to record the on-again-off-again activity of a single channel. (The 1991 Nobel Prize in Physiology or Medicine was awarded to E. Neher and B. Sakmann for their invention of the measurement technique, which is now widely used in electrophysiology research.)\nThe figure shows 16 recordings of the activity of different channels. Each of the recordings is a combination of signal and noise.\nTASK: In three recordings of your choice,\n\nIdentify the signal by drawing it over the recording.\nMeasure the typical amplitude of the noise. For this purpose, use the guide at the lower-right corner of the figure: a short vertical line marks the amplitude of 5 pA, that is, 5 pico-Amps.\n\nTo identify the signal, you need to know something about what the signal looks like. In our work in Math 300Z, the “signal” corresponds to a relationship between two variables or more. Here, one of the variables is time, the other is electrical current. Usually in Math 300Z we will be interested in “linear” relationships between the variables and we seek to identify the signal using only that limited piece of information. To define the signal in the single-channel recordings, use this information: the channels open and close to current, occasionally staying open (or closed) for the better part of a second, but also opening (or closing) for a much shorter time, say 0.01 second.\n\n\n\n\n\nSource of image: Kawano, R., Tsuji, Y., Sato, K. et al. (2013) “Automated Parallel Recordings of Topologically Identified Single Ion Channels”. Scienfic Reports **3(#1995) https://doi.org/10.1038/srep01995"
  },
  {
    "objectID": "Day-by-day/Lesson-20/Life-savers.html#saving-lives",
    "href": "Day-by-day/Lesson-20/Life-savers.html#saving-lives",
    "title": "Spring 2023 Math 300Z",
    "section": "Saving Lives",
    "text": "Saving Lives\nA tourniquet is a belt-like device used to cut off the blook supply to a damaged and severely bleeding limb. A 2014 study of 1413 US casualities in Afghanistan and Iraq concluded that “those who received tourniquets had survival rates similar to those of comparable, transfused casualties who did not receive tourniquets.” That study was careful to take into account injury severity when comparing the casualties with tourniquets to those without. (JF Kragh et al. (2014) “Transfusion for Shock in US Military War Casualties With and Without Tourniquet Use” Annals of Emergency Medicine 65(3) link)\nThe study authors pointed out a potential bias in the collection of data. Only those soldiers who survived up to arrival at the hospital were included.\nConsider these four factors:\n\nInjury SEVERITY\nTourniquet USE (at the battle location)\nADMISSION, that is, arrival at the hospital\nPost-Admission SURVIVAL\n\nTASK: Construct a directed acyclic graph with a node for each of these factors. Draw directed causal links between each pair of nodes that you think are likely to be connected. For each link that you draw, make sure to show the direction of causation, giviving a few words of explanation. Similarly, when there is a pair of nodes without a direct connection, explain why not.\n \n \n \nNote: The direct paths you draw may create longer, indirect paths. For instance, \\(\\mathbb{A} \\longrightarrow \\mathbb{B} \\longrightarrow \\mathbb{C}\\) has direct paths between \\(\\mathbb{A}\\) and \\(\\mathbb{B}\\) as well as between \\(\\mathbb{B}\\) and \\(\\mathbb{C}\\). However, there is no direct connection between \\(\\mathbb{A}\\) and \\(\\mathbb{C}\\).\n\nReference: J Pearl and D Mackenzie (2018) The Book of Why pp343-7"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html",
    "href": "Worksheets/Worksheet-20.html",
    "title": "Lesson 20: Worksheet",
    "section": "",
    "text": "20.1 [Technical] Collect a sample from a DAG simulation.\n20.2 [Technical] Examine the formulas behind a DAG simulation and compare to the results of a regression model trained on a sample from the DAG simulation.\n20.3 [Conceptual] Recognize properties of a DAG. i. Identify exogenous nodes. ii. Identify all pathways between two specified end nodes. iii. On a given pathway, is there causal flow from one end node to another? iv. On a given pathway, is there a causal flow from some node on the pathway to both end nodes?"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-1-samples-from-dags",
    "href": "Worksheets/Worksheet-20.html#part-1-samples-from-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 1: Samples from DAGs",
    "text": "Part 1: Samples from DAGs\n\nUse dag_draw() to draw a picture of the dag08 directed acyclic graph. From this graph, explain why node c is exogenous and why x and y are not.\n\nANSWER:\n\nUse print() to view the formulas used by dag08 to simulate data. What about the formula for y indicates that it’s receives inputs from x and c.\n\nANSWER:\n\nThere are three coefficients in the formula for y: an intercept, an x coefficient, and a c coefficient. (There is also some random input from an exogenous source unrelated to c or x.) What are the numerical values of the three coefficients?\n\nANSWER:\n\nCollect a sample of size \\(n=100\\) from dag08 and use it to train the model with specification y ~ x. Do the coefficients reported match those you found in part (c)? (If you are not sure, use a bigger sample size, say \\(n=1000\\) or even bigger.)\n\nANSWER:\n\nSimilar to (4), but use the specification y ~ x + c. How do the coefficients for this model compare to those you found in (3)?\n\nANSWER"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-2-paths-in-dags",
    "href": "Worksheets/Worksheet-20.html#part-2-paths-in-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 2: Paths in DAGs",
    "text": "Part 2: Paths in DAGs\n\nIn dag08 there are two paths connecting x andy. One path is direct, \\(X \\longrightarrow Y\\). The other path is indirect, \\(X \\longleftarrow C \\longrightarrow Y\\).\n\nAlong the indirect path, is there a causal flow from x to y?\nAlong the indirect path, is there a causal flow from any node on the graph that reaches both endpoints, x and y?\n\n\nANSWER:\n\ndag_school2 is a highly simplistic model of the relationship between expenditures on schools and student outcomes in terms of, say, standardized test scores.\n\n\ndag_draw(dag_school2, vertex.label.cex=1, vertex.size=40)\n\n\n\n\nThere is a direct pathway from expenditure to outcome as well as another, indirect pathway.\n\nAre there any exogenous nodes in the graph?\nOn the indirect pathway, is there a causal from from expenditure to outcome?\nIs there a causal flow from any node on the indirect pathway to both expenditure and outcome? Which one?\nExplain why any node you identified in part (c) must be an exogenous node.\n\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "href": "Worksheets/Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "title": "Lesson 20: Worksheet",
    "section": "Part 3: Are expenditures good for school outcomes?",
    "text": "Part 3: Are expenditures good for school outcomes?\n\nLook at the formulas for dag_school2. Is a higher expenditure connected to a higher outcome?\n\nANSWER:\n\nGenerate a simple of size 1000 from dag_school2 and use it to train the model outcome ~ expenditure. Is the coefficient on expenditure consistent with what you found in (1)? (If you aren’t sure, use a larger sample size, say 10,000.) What about the coefficient on expenditure leads to your conclusion?\n\nANSWER:\n\nSpeculate on what might be the origin of the evident inconsistency between (1) and (2)?\n\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-4-constructing-a-dag",
    "href": "Worksheets/Worksheet-20.html#part-4-constructing-a-dag",
    "title": "Lesson 20: Worksheet",
    "section": "Part 4: Constructing a DAG",
    "text": "Part 4: Constructing a DAG\nIn this task, you will construct DAGs using dag_make() and draw them using dag_draw().\nA DAG is defined by a series of tilde expressions, one for each node in the graph. The tilde expression for a node has the node’s name on the left-hand side of the tilde. The right-hand side contains the nodes which serve as inputs to the node named on the left-hand side. If there are no inputs, write exo().\nFor example, consider a DAG with three nodes: one, two, and three. To define a DAG where node two receives input from node one, and node three receives input from nodes one and two, use make_dag() with three tilde expressions:\n\nexample_dag <- dag_make(\n  one ~ exo(),\n  two ~ one,\n  three ~ two + one\n)\ndag_draw(example_dag)\n\n\n\n\nThe right-hand side of a formula can be any arithmetic expression involving the node names, but we will keep it simple: just use + to separated the node names. If a node receives no inputs, the right-hand side should be simply exo() to mark that node as exogenous.\n\nWhat happens if node one, instead of being exogenous, takes as input one of the other two nodes in example_dag?\n\nANSWER: The graph would become cyclic, hence not a DAG. Notice that by using a node on the right-hand side of a tilde expression only when it has already been created by a previous tilde expression, you guarantee that the graph will be acyclic.\n\nCreate and draw a DAG that has the same arrangement of causal connections as “Professor Butts and the Self-Operating Napkin,” illustrated below:\n\n\nProfessor Butts and the Self-Operating Napkin (1931). Soup_spoon (A) is raised to mouth, pulling string (B) and thereby jerking ladle (C), which throws cracker (D) past toucan (E). Toucan jumps after cracker and perch (F) tilts, upsetting seeds (G) into pail (H). Extra weight in pail pulls cord (I), which opens and ignites lighter (J), setting off skyrocket (K), which causes sickle (L) to cut string_m (M), allowing pendulum with attached napkin to swing back and forth, thereby wiping_chin.\nWatch your spelling of node names! Use this command to draw your napkin_dag:\ndag_draw(napkin_dag, vertex.label.cex=.5, vertex.size=10, edge.arrow.size = 0.2)\nANSWER:\n\nnapkin_dag <- dag_make(\n  soup_spoon ~ exo(),\n  string ~ soup_spoon,\n  ladle ~ string,\n  cracker ~ ladle,\n  toucan ~ cracker,\n  perch ~ toucan,\n  seeds ~ perch,\n  pail ~ seeds,\n  cord ~ pail,\n  lighter ~ cord,\n  skyrocket ~ lighter,\n  sickle ~ skyrocket,\n  string_m ~ sickle,\n  wiping_chin ~ string_m\n)\ndag_draw(napkin_dag, vertex.label.cex=.5, vertex.size=10, edge.arrow.size = 0.2)"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html",
    "href": "Worksheets/Worksheet-19.html",
    "title": "Lesson 19: Worksheet",
    "section": "",
    "text": "19.1. [Conceptual] Master the use and units of variance and standard deviation in measuring variability.\n19.2. [Conceptual] Understand the equivalence between mean and proportion on a zero-one variable.\n19.3. [Technical] Use var() and sd() within summarize()\n19.4. [Technical] Use model_plot() to graph models with one or two explanatory variables.\n19.5. [Technical] Use zero_one() with mutate() to create a zero-one variable."
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#preliminaries-how-we-will-work-with-r.",
    "href": "Worksheets/Worksheet-19.html#preliminaries-how-we-will-work-with-r.",
    "title": "Lesson 19: Worksheet",
    "section": "Preliminaries: How we will work with R.",
    "text": "Preliminaries: How we will work with R.\nIn the first half of Math 300Z, the daily student notes were largely structured around “scaffolded” R code, which often involved filling in the blanks. In this second half of 300Z, we will start to use a new way of helping you construct appropriate R command. We call this “command patterns. For instance,\nDF %>% summarize(NM=var(VAR)) \nis a command pattern.\nOne reason for the shift to the command-pattern style is that there will be only a handful of new patterns in the second half of the course that you’ll be using over and over again. Another reason is to help you develop “finger memory” for the most common patterns. An analogy: scaffolding is like GPS navigation which certainly makes it easier to drive but harder to get to know the town. Command patterns are like a paper map, there to help you when you need it.\nThere is a specific notation for command patterns, which you should memorize. Instead of the blanks used in a scaffold, the command pattern uses a CAPITALIZED abbreviation for the **kind of thing* that should be put in the position. Common kinds of thing are\n\nDF: a data frame, almost always referred to by name.\nVAR: a variable in a data frame. Many command patterns involve multiple variables, each of which is referred to by VAR. You will replace each VAR with the appropriate variable name.\nVARS: one or more variable names. When these are the right-hand side of a tilde expression, separate the names with + punctuation. When we mean to indicate that there is only one variable, we use VAR instead of VARS. If we want to say, “use two variables,” we would write VAR + VAR.\nMODEL refers to the name of a model that you have previously constructed with lm().\nNM means a name that you will be calling something by. For instance, NM <- lm(VAR ~ VARS, data=DF). Another occasion for using NM is as part of an argument to summarize() or mutate().\n[, MORE] means that you can have multiple additional arguments of the same form as the previous argument.\nVALUE a number, quoted string (e.g., \"red\"), or multiple values inside c( ).\nMODSPEC is a model specification, which could equally well be written VAR ~ VARS\n\nAnything in a command pattern that is not a CAPITALIZED abbreviation is a specific part of the command to be used as-is. For instance, lm(VAR ~ VARS, data=DF) refers explicitly to the lm() function whose first argument is a tilde expression and whose second argument is named data.\nOccasionally, you will refer to a data frame by naming the package from which it comes. For example, the moderndive package includes (among many others) the amazon_books data frame. Think of amazon_books as a first name, and moderndive as a family name. When you see PACKAGE::DF it is meant to indicate, for instance, moderndive::amazon_books. (Note that the :: in the command pattern is to be taken literally; there are two successive colons separating the package name from the name of the data frame.)"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#part-1",
    "href": "Worksheets/Worksheet-19.html#part-1",
    "title": "Lesson 19: Worksheet",
    "section": "Part 1",
    "text": "Part 1\nCommand patterns:\n\nDF %>% summarize(NM = var(VAR)) Calculate variance of a variable in a data frame.\n`DF %>% summarize(NM1 = var(VAR1), NM2 = var(VAR2) [, MORE])\nPACKAGE::DF The name of a data frame within a package.\n\n\nIn the mosaicData::Galton data frame, find the variance of mother and father. Give both the numerical value and the units.\n\nANSWER:\n\nIn the moderndive::amazon_books data frame, find the variance of list_price and num_pages. Give both the numerical value and the units.\n\nANSWER:\n\nCalculate the variance of sex from Galton. If something goes wrong, explain why.\n\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#part-2",
    "href": "Worksheets/Worksheet-19.html#part-2",
    "title": "Lesson 19: Worksheet",
    "section": "Part 2",
    "text": "Part 2\nCommand patterns:\n\nNM <- lm(VAR ~ VARS, data = DF)\nlm(VAR ~ VARS, data=DF) %>% conf_interval()\nlm(MODSPEC, data=DF) %>% conf_interval() means the same as (b).\n\n\n(Easy, no computing needed.) What kind of a thing is conf_interval(). (Hint: It’s the same kind of thing as lm().)\n\nANSWER:\n\nUsing the moderndive::amazonbooks data frame, fit the model list_price ~ num_pages:\n\nWhat are the units of the “(Intercept)” coefficient?\nReport the confidence interval on num_pages. Give both the numerical bounds and the units.\nDoes the confidence interval of either of the terms include zero?\n\n\nANSWER:\n\nSimilar to (2) but with the model list_price ~ numpages + hard_paper\n\nWhat does the term hard_paperH refer to?\nAccording to the coefficients, is a hardcover book any more expensive (on average) than a softcover book?\nDoes the confidence interval of any of the terms include zero?\n\n\nANSWER:\n\nStore the model you created in (3) under the name mod3. We’ll use it in the next part. For your answer, put the R command you used to store the model as mod3.\n\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#graphics-review",
    "href": "Worksheets/Worksheet-19.html#graphics-review",
    "title": "Lesson 19: Worksheet",
    "section": "Graphics review",
    "text": "Graphics review\nCommand patterns:\n\nggplot(DF, aes(x=VAR, y=VAR)) + geom_jitter()\nggplot(DF, aes(x=VAR, y=VAR)) + geom_jitter() + geom_violin(fill=\"blue\", alpha=0.3)\nggplot(DF, aes(x=\"all\", y=VAR)) + geom_jitter()\nmodel_plot(MODEL, x=VAR)\nmodel_plot(MODAL, x=VAR, color=VAR)\n\n\nMake a jitter plot of list_price ~ hard_paper from moderndive::amazon_books.\n\nANSWER:\n\nUsing your command from (1), add a new layer: + geom_violin(fill=\"blue\", alpha=0.3)\n\nANSWER:\n\nUse model_plot() to draw a picture of mod3. Set x=hard_paper. What do you think the horizontal line segments refer to?\n\nANSWER:\n\nRepeat (3), but now set x=num_pages, color=hard_paper. Explain the meaning of the line segments in everyday terms.\n\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-25.html",
    "href": "Worksheets/Worksheet-25.html",
    "title": "Lesson 25: Worksheet",
    "section": "",
    "text": "Count the points above and below the prediction band. What fraction of the points are within the band.\nPull out the values in one category and use them for prediction directly."
  },
  {
    "objectID": "Worksheets/Worksheet-24.html",
    "href": "Worksheets/Worksheet-24.html",
    "title": "Lesson 24: Worksheet",
    "section": "",
    "text": "USE model_eval() to evaluate the function. Calculate the effect size by hand. Is it a slope or a difference?\nCompare the effect size to a model coefficient."
  },
  {
    "objectID": "Worksheets/Worksheet-23.html",
    "href": "Worksheets/Worksheet-23.html",
    "title": "Lesson 23: Worksheet",
    "section": "",
    "text": "Use models to calculate a confidence interval.\nCompare the band on a model_plot() view to the numbers in the confidence interval for a slope. Do they correspond.\nMaybe have them add a geom_abline() to the plot to compare to the slope of the top and bottom of the confidence band."
  },
  {
    "objectID": "Worksheets/Worksheet-21.html",
    "href": "Worksheets/Worksheet-21.html",
    "title": "Lesson 21: Worksheet",
    "section": "",
    "text": "Command patterns:\n\nNM <- model_eval(MODEL)\nNM %>% summarize(NM = var(VAR) [, MORE] )\nmodel_eval(MODEL, VAR=VALUE [, MORE] )\n\n\nUse model_eval() on mod3, using as inputs the values num_pages=250, hard_paper=\"H\". What is the model output for these inputs?\n\nANSWER:\n\nSimilar to 2, but set the inputs to num_pages=c(250, 500), hard_paper=c(\"H\", \"P\").\n\nHow many rows are in the result from model_eval()? Explain what they stand for.\nWhat’s the difference in model output for a paperback book of 250 versus 500 pages? Make sure to give the units for the model output.\n\n\nANSWER:\n\nWhen you use command pattern (a), model_eval() evaluates the model on each row in the training data.\n\nRun model_eval(mod3), , without any additional arguments, storing the result under the name Book_pts.\nLook at the first few lines of Book_pts. What variables are in the result that weren’t in the result from (2).\nThe columns .lwr and .upr define an interval. (It happens to be called the “prediction interval”, but we will get to that in another Lesson.) Does zero fall inside any of the intervals reported in (i).\nThe variable named .response holds the values of the response variable from the model. What was the original name for the response variable in mod3?\nThere is a simple arithmetic relationship among .response, .output, and .resid that holds true for each row individually. Using mental arithmetic, what is the arithmetic relationship?\n\nUsing wrangling, summarize Book_pts, calculating the variance of each of .response, .output, and .resid. What is the simple arithmetic relationship among the three variances?\n\nANSWER:"
  },
  {
    "objectID": "Day-by-day/Lesson-22/counts-and-waiting-times.html#counts-and-waiting-times",
    "href": "Day-by-day/Lesson-22/counts-and-waiting-times.html#counts-and-waiting-times",
    "title": "Spring 2023 Math 300Z",
    "section": "Counts and waiting times",
    "text": "Counts and waiting times\nGENERATE SEQUENCES FROM POISSON and EXPONENTIAL.\nFirst, generate a sample of size 1: find the largest and smallest across the class.\nThen generate a sample of size 20:\n\nfind the largest and smallest. are they pretty consistent across the class?\n\nfind the variance. Is that pretty consistent across the class?\n\nfind the mean:\n\nis that as spread out as the largest and smallest?\nhow spread out is it? (variance)\n\n\nKeep a table\n\n\n\nsample size\nvariance\nstandard deviation\n\n\n\n\n20.\n\n\n\n\n20\n\n\n\n\n20\n\n\n\n\n40\n\n\n\n\n80\n\n\n\n\n\nMaybe add a parameter or distribution argument to sample.dag_system()"
  },
  {
    "objectID": "Day-by-day/Lesson-24/with-respect-to.html#with-respect-to",
    "href": "Day-by-day/Lesson-24/with-respect-to.html#with-respect-to",
    "title": "Spring 2023 Math 300Z",
    "section": "With respect to …",
    "text": "With respect to …\nBuild a model with a single quantitative explanatory variable. Maybe palmerpenguins::penguins\n- What is the effect size?\n- What are the units? Is it a rate or a difference?\nBuild a model with a single categorical explanatory variable.\n- What is the effect size?\n- What are the units? Is it a rate or a difference?\nCombine the two and calculate effect sizes again.\n- Do the effect sizes change?\n- Do the units change? \n- Is it still a rate?\nInclude many explanatory variables: Find the effect sizes with respect to each."
  },
  {
    "objectID": "Day-by-day/Lesson-23/got-you-covered.html#got-you-covered",
    "href": "Day-by-day/Lesson-23/got-you-covered.html#got-you-covered",
    "title": "Spring 2023 Math 300Z",
    "section": "Got you covered",
    "text": "Got you covered\nSimulate from a DAG and calculate the confidence interval @ 95%\nDid everybody’s interval include the parameter from the DAG?\nMove to an 80% interval. About 4 students should not cover the parameter.\nMove to a 50% interval. About 10 students should not cover the parameter.\nMove to a 100% interval. What do the results tell you?\nFrederick the Great said, “To defend everything is to defend nothing.” paraphrase as “To try to cover everything is to cover nothing.”"
  }
]