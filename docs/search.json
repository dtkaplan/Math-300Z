[
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "",
    "text": "The entire box is 14.43 “inches” long. This should be the total of the left, right, and middle measurements, but people tended to round.\n\nThirds <- readr::read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT_asFV5LD312bYaGgHK3F91kgLVSiaQpNhggDilfPKAiDBNz9iueOiYWKgAtRRwkFlOz6U9znbiMGK/pub?gid=0&single=true&output=csv\")\n\nRows: 16 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Student_initials\ndbl (3): left, middle, right\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nLong_form <- tidyr::pivot_longer(Thirds, !Student_initials, names_to = \"position\")\nLong_form |> group_by(Student_initials) |> summarize(tot = sum(value), v = var(value))\n\n# A tibble: 16 × 3\n   Student_initials   tot        v\n   <chr>            <dbl>    <dbl>\n 1 AMA               13.8 0.0208  \n 2 BAK               14.5 0.271   \n 3 DQS               14.4 0.416   \n 4 EDS               16   0.646   \n 5 EFSF              14.1 0.00750 \n 6 EJD               13.8 0.271   \n 7 HAM               14.2 0.188   \n 8 HJB               14.3 0.000833\n 9 IMW               14   0.396   \n10 JK                14.2 0       \n11 JTSF              14.8 0.271   \n12 KDL               14.2 0.0625  \n13 KZC               14   0.583   \n14 RHP               14.2 0       \n15 RRP               14.2 0.188   \n16 SJA               14.5 1.65    \n\nLong_form |> summarize(vmeas = var(value))\n\n# A tibble: 1 × 1\n  vmeas\n  <dbl>\n1 0.240\n\nlm(value ~ position, data=Long_form) |> conf_interval()\n\n# A tibble: 3 × 4\n  term             .lwr .coef  .upr\n  <chr>           <dbl> <dbl> <dbl>\n1 (Intercept)     4.29  4.50  4.70 \n2 positionmiddle  0.392 0.678 0.964\n3 positionright  -0.126 0.159 0.445\n\nggplot(Long_form, aes(y=value, x=position)) + geom_jitter(width=0.2, alpha=0.5)"
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#variation",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#variation",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Variation",
    "text": "Variation\nRemember that statistics focus on variation in the characteristics of a set of multiple specimens. The characteristics of each individual specimen are recorded in a row of a data frame. The data frame itself, with its multiple rows, represents the set of specimens. Each characteristic is arranged as a column in the data frame. We call such columns “variables,” a name that emphasizes that our particular interest is to understand/explain/account-for the variation of the values stored in the column.\nIn a regression model, we attempt to understand/explain/account-for the variation in a single variable, called the “response variable.” We accomplish this explanation by associating the variation in the response with the simultaneous variation in other variables called “explanatory variables.”\nThe lm() model-building function does the work of quantifying the associations. Your task in model building is to provide data for training and to specify which are the explanatory variables you want to use to account for the variation in the response variable. The specification takes the form of a tilde expression listing the response and explanatory variables. All these variables must be in the data frame used for training. We say such variables are “observed.”\nThere are usually other characteristics that are relevant to the system being studied that are not observed, that is, they are not in the data frame. It’s a bad idea to ignore such things."
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#starting-lesson-20",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#starting-lesson-20",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Starting Lesson 20",
    "text": "Starting Lesson 20\nToday is a meta-day. It is about tools for learning about statistical methods and gaining insight into why certain kinds of questions/techniques come up over and over again as you work on genuine statistical problems.\nThe two kinds of tools for learning are:\n\nTools for thinking and communicating about hypotheses about causal connections.\n\nDiagrams called “DAGs” for sketching out causation.\nGenerating random, simulated data consistent with the mechanism described by a DAG.\n\nWays to automate the process of random trials. This is purely a labor-saving measure. You are not responsible to generate the code for this automation, but you should learn to read the code to be able to say what’s going on."
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#causation-examples",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#causation-examples",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Causation examples",
    "text": "Causation examples\n\nSystolic blood pressure in the elderly:\n\nExperiment shows that lowering SBP reduces mortality.\nObservation shows that lower SBP is associated with increased mortality.\n\nCongressional elections\n\nAmong incumbents, higher election spending is associated with worse vote outcomes.\n\nVitamin D and disease\n\nLow vitamin linked to adverse outcomes in many diseases\nIll people go outside less often so are less exposed to sunlight AND Vitamin D is an acute phase reactant and declines with the inflammatory cytokine rise in acute and chronic diseases AND No evidence from randomized trials that vitamin D supplementation lessens mortality risks in such conditions.\nBring up article"
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#directed-acyclic-graphs-dags",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#directed-acyclic-graphs-dags",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Directed acyclic graphs (DAGs)",
    "text": "Directed acyclic graphs (DAGs)\nA DAG is a format for writing down which characteristics, either observed or unobserved, are important in the operation of a system.\nA good dictionary definition of “system” is:\n\nA set of things working together as parts of a mechanism or an interconnecting network.\n\nGraphs, Directed, Acyclic"
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#sampling-from-dags",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#sampling-from-dags",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Sampling from DAGs",
    "text": "Sampling from DAGs\nIn Math 300Z, DAGs have been augmented with a simulation mechanism. This consists of formulas that are invoked to create each variable in the DAG."
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#activity-life-savers",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#activity-life-savers",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Activity: Life Savers",
    "text": "Activity: Life Savers"
  },
  {
    "objectID": "Day-by-day/Lesson-20/Teaching-notes-20.html#repeating-trials",
    "href": "Day-by-day/Lesson-20/Teaching-notes-20.html#repeating-trials",
    "title": "Instructor Teaching Notes for Lesson 20",
    "section": "Repeating trials",
    "text": "Repeating trials\n\nfoo <- do(100000)*sum(runif(10))\nggplot(foo, aes(x=\" \", y = sum)) + geom_violin(alpha=0.5)\n\n\n\n\n\nTrials <- do(100) * {lm(x ~ y, data=sample(dag03, size=5)) |> R2()}"
  },
  {
    "objectID": "Day-by-day/Lesson-22/counts-and-waiting-times.html#counts-and-waiting-times",
    "href": "Day-by-day/Lesson-22/counts-and-waiting-times.html#counts-and-waiting-times",
    "title": "Spring 2023 Math 300Z",
    "section": "Counts and waiting times",
    "text": "Counts and waiting times\nGENERATE SEQUENCES FROM POISSON and EXPONENTIAL.\nFirst, generate a sample of size 1: find the largest and smallest across the class.\nThen generate a sample of size 20:\n\nfind the largest and smallest. are they pretty consistent across the class?\n\nfind the variance. Is that pretty consistent across the class?\n\nfind the mean:\n\nis that as spread out as the largest and smallest?\nhow spread out is it? (variance)\n\n\nKeep a table\n\n\n\nsample size\nvariance\nstandard deviation\n\n\n\n\n20\n\n\n\n\n20\n\n\n\n\n20\n\n\n\n\n40\n\n\n\n\n80"
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "",
    "text": "Open your Z-section project in Posit.cloud. Use get_lesson_worksheet(22) to bring in today’s worksheet.\n\nOpen the worksheet and leave it for later in class.\nCreate a new Rmd file, say, \"Scratch22.Rmd\". We’ll do scratch work there."
  },
  {
    "objectID": "Day-by-day/Lesson-24/with-respect-to.html#with-respect-to",
    "href": "Day-by-day/Lesson-24/with-respect-to.html#with-respect-to",
    "title": "Spring 2023 Math 300Z",
    "section": "With respect to …",
    "text": "With respect to …\nThe palmerpenguins::penguins data frame records body size and shape of penguins of three different species.\n\nBuild a model bill_length_mm ~ bill_depth_mm with a single quantitative explanatory variable.\n\nWhat is the effect size?\nWhat are the units? Is it a rate or a difference?\n\nBuild a model bill_length_mm ~ species with a single categorical explanatory variable.\n\nWhat is the effect size?\nWhat are the units? Is it a rate or a difference?\n\nNow a model bill_length_mm ~ flipper_length + body_mass_g. There are two variables, so there will be two effect sizes.\n\nWhat are the effect sizes? What are their units.\nWhich of the two are rates?"
  },
  {
    "objectID": "Day-by-day/Lesson-24/Teaching-notes-24.html",
    "href": "Day-by-day/Lesson-24/Teaching-notes-24.html",
    "title": "Teaching notes, Lesson 24",
    "section": "",
    "text": "Here are some fundamentals:"
  },
  {
    "objectID": "Day-by-day/Lesson-23/got-you-covered.html#got-you-covered",
    "href": "Day-by-day/Lesson-23/got-you-covered.html#got-you-covered",
    "title": "Spring 2023 Math 300Z",
    "section": "Got you covered",
    "text": "Got you covered\nSimulate from a DAG, use the data to train a model that has all the same explanatory variables as in the formula for y in the DAG, and calculate the confidence interval @ 95%\nDid everybody’s interval include the parameter from the DAG?\nMove to an 80% interval. About 4 students should not cover the parameter.\nMove to a 50% interval. About 10 students should not cover the parameter.\nMove to a 100% interval. What do the results tell you?\nFrederick the Great said, “To defend everything is to defend nothing.” paraphrase as “To try to cover everything is to cover nothing.”"
  },
  {
    "objectID": "textbooks.html",
    "href": "textbooks.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "For Lessons 1-17, the textbook is Statistical Inference via Data Science (“ModernDive”)"
  },
  {
    "objectID": "textbooks.html#lessons-19-onward",
    "href": "textbooks.html#lessons-19-onward",
    "title": "Spring 2023 Math 300Z",
    "section": "Lessons 19 onward …",
    "text": "Lessons 19 onward …\n\n\nFor Lessons 19-39, the textbook is Lessons in Statistical Thinking"
  },
  {
    "objectID": "math300-software.html",
    "href": "math300-software.html",
    "title": "R package for Math 300Z",
    "section": "",
    "text": "Most students will want to use POSIT.cloud. Use the “Z-Section” project."
  },
  {
    "objectID": "math300-software.html#accessing-the-daily-worksheet",
    "href": "math300-software.html#accessing-the-daily-worksheet",
    "title": "R package for Math 300Z",
    "section": "Accessing the daily worksheet",
    "text": "Accessing the daily worksheet\nAlmost all class days there will be a worksheet in the form of an Rmd file.\nFrom within your POSIT.cloud project, download the Rmd file using this command, substituting the number of the relevant Lesson:\nmath300::get_lesson_worksheet(19)\n\nMake a habit of reading each day’s Rmd file before class. This way you can note what doesn’t yet make sense so that you can be receptive to the topic in class.\nComplete the worksheet after class."
  },
  {
    "objectID": "math300-software.html#math-300z-r-commands",
    "href": "math300-software.html#math-300z-r-commands",
    "title": "R package for Math 300Z",
    "section": "Math 300Z R commands",
    "text": "Math 300Z R commands\nThere will be only a dozen commands that you will be using in the second half of Math 300Z. Almost all of them involve constructing or summarizing models.\nAs a reminder, here are some of the commands/syntax that should be familiar to you from the first half of the course.\n\nlm() fits (or “trains”) a “linear model” on data from a data frame.\nggplot() sets things up for a new graphic. Use aes() as an argument.\ngraphics layers to add onto the output of ggplot():\n\ngeom_point(), geom_jitter(alpha=0.5)\n\nfilter(), mutate() and summarize() are basic data-wrangling commands we will use often.\n\nNew commands in the second half of the course:\n\nsummarize a model: conf_intervals(), R2()\nevaluate a model: model_eval()\ngraphic of a model: model_plot() (This replaces the geom_smooth() used in the first half of the course.)\nvariance of a variable in a data frame: DF %>% summarize(NM = var(VAR))\ndraw a DAG: dag_draw()\nsample from a DAG: sample(DAG, size=100)\n\nA few other commands will be used occasionally in examples and demonstrations. You should know what they do, but typically there will be a reminder of the syntax: zero_one(), shuffle(), do() * {}, dag_intervene(), tibble(), regression_summary(), anova_summary()."
  },
  {
    "objectID": "math300-software.html#running-rrstudio-on-your-laptop",
    "href": "math300-software.html#running-rrstudio-on-your-laptop",
    "title": "R package for Math 300Z",
    "section": "Running R/RStudio on your laptop?",
    "text": "Running R/RStudio on your laptop?\nInstall the {math300} and other packages with these two commands:\ninstall.packages(c(\"mosaic\", \"ggplot\", \"dplyr\", \"openintro\", \"moderndive\", \"nycflights13\", \"knitr\"))\n# additional package for Math 300Z\nremotes::install_github(\"dtkaplan/math300\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math 300Z",
    "section": "",
    "text": "Take-aways from the most recent class\n\n\n\nOn Math 300 Blog\n\n\n\n\n\n\n\n\n\nDate\nClass day\nTopic\nActivity\nSoln\nTake away\nClassroom video\n\n\n\n\nMar 3\nLesson 19 Notes:Reading\nVariation & variance\nMeasuring by eye\nSoln\nBlog-19\nvideo\n\n\nMar 7\nLesson 20 Notes:Reading\nDAGs & simulation\nLife savers?\nSoln\nBlog-20\nvideo\n\n\nMar 9\nLesson 21 Notes:Reading\nSignal & noise\nMembrane channels Handout\nSoln\nBlog-21\nvideo\n\n\nMar 13\nLesson 22 Notes:Reading\nSampling variation\nCounts and rates\nSoln\nBlog-22\nvideo\n\n\nMar 15\nLesson 23 Notes:Reading\nConfidence intervals\nGot you covered!\nSoln\nBlog-23\nvideo\n\n\nMar 17\nLesson 24 Notes:Reading\nEffect size\nWith respect to …\nSoln\nBlog-24\nvideo\n\n\nMar 21\nLesson 25 Notes:Reading\nPrediction mechanics\nTBA\nSoln\nBlog-25\nvideo\n\n\nMar 23\nLesson 26 Notes:Reading\nPrediction intervals\nIntervals by eye & Handout\nSoln\nBlog-26\nvideo\n\n\n\nSPRING BREAK\nKeep in mind that Problem Set 5\nwill be due April 6.\n\n\n\n\n\nApr 3\nLesson 28 Notes:Reading\nCovariates\nCovariates change coefficients\nSoln\nBlog-28\nvideo\n\n\nApr 5\nLesson 29 Notes:Reading\nCovariates eat variance Adjustment for covariates\nAdjusting activity\nSoln\nBlog-29\nvideo\n\n\n\nAPRIL 6: Problem Set 5 due.\nSee Z-section Problem Set 5 on posit.com\n\n\n\n\n\n\nApr 7\nLesson 30 Notes:Reading\nConfounding\nTBA\nSoln\nBlog-30\nvideo\n\n\nApr 11\nLesson 31 Notes:Reading\nSpurious correlation\nTBA\nSoln\nBlog-31\nvideo\n\n\nApr 13\nLesson 32 Notes:Reading\nExperiment & random assignment\nTBA\nSoln\nBlog-32\nvideo\n\n\nApr 17\nLesson 33 Notes:Reading\nMeasuring and accumulating risk\nTBA\nSoln\nBlog-33\nvideo\n\n\n\nAPRIL 19\nGR 3\n\n\n\n\n\n\nApr 24\nLesson 34 Notes:Reading\nConstructing a classifier\nTBA\nSoln\nBlog-34\nvideo\n\n\nApr 27\nLesson 35 Notes:Reading\nAccounting for prevalence\nlink\nSoln\nBlog-35\nvideo\n\n\nMay 1\nLesson 36 Notes:Reading\nHypothesis testing\nTBA\nSoln\nBlog-36\nvideo\n\n\nMay 3\nLesson 37 Notes:Reading\nCalculating a p-value\nTBA\nSoln\nBlog-37\nvideo\n\n\n\nMAY 4\nPS6 due\n\n\n\n\n\n\nMay 5\nLesson 38 Notes:Reading\nFalse discovery with hypothesis testing\nTBA\nSoln\nBlog-38\nvideo\n\n\nMay 9\nLesson 39 Notes:Reading\nREVIEW of lessons 28-38\nTBA\nSoln\nBlog-39\nvideo\n\n\nMay 11\nLesson 40 Notes:Reading\nReview of entire course\nN/A\nSoln\nBlog-40\nvideo\n\n\n\n\nMath 300Z is the prototype for scheduled revisions to Math 300. The revisions apply only to Lessons 19 and up; the first 18 lessons come from Math 300."
  },
  {
    "objectID": "index.html#day-by-day-plan",
    "href": "index.html#day-by-day-plan",
    "title": "Math 300Z",
    "section": "Day-by-day plan",
    "text": "Day-by-day plan\nMar 3 Lesson 19: Topic: Variation Reading, Activity: Measuring by eye, Worksheet Solns, take-aways\nMar 7 Lesson 20: Topic: DAGs and simulation Reading, Activity: Life savers?, Worksheet Solns, take-aways\nMar 9 Lesson 21: Topic: Signal and noise Reading, Activity: Membrane channels Handout, Worksheet Solns, take-aways class video\nMar 13 Lesson 22: Topic: Sampling variation Reading, Activity: Counts and rates, Worksheet Solns, take-aways class video\nMar 15 Lesson 23: Topic: Confidence intervals Reading, Activity: Got you covered!, Worksheet Solns, take-aways class video\nMar 17 Lesson 24: Topic: Effect size Reading, Activity: With respect to …, Worksheet Solns, take-aways\nMar 21 Lesson 25: Topic: Prediction mechanics Reading, Activity: To be determined, Worksheet Solns, take-aways\nMar 23 Lesson 26: Topic: Prediction intervals Reading, Activity: Intervals by eye, Handout, Worksheet Solns, take-aways\nSPRING BREAK. Keep in mind that Problem Set 5 will be due April 6.\nApr 3 Lesson 28: Topic: Covariates :: Reading, Activity: TBA, Worksheet Solns, take-aways\nAPRIL 6: Problem Set 5 due. See Z-section Problem Set 5 on posit.com\nApr 5 Lesson 29: Topic: Covariates eat variance :: Reading, Activity: TBA. Homework assignment due. (link to come)\nApr 7 Lesson 30: Topic: Confounding :: Reading, Activity: TBA, Worksheet Solns, take-aways\nApr 11 Lesson 31: Topic: Spurious correlation :: Reading, Activity: TBA, Worksheet Solns, take-aways\nApr 13 Lesson 32: Topic: Experiment & random assignment :: Reading, Activity: TBA, Worksheet Solns, take-aways\nApr 17 Lesson 33: Topic: Measuring and accumulating risk :: Reading, Activity: TBA, Worksheet Solns, take-aways\nAPRIL 19: GR 3\nApr 24 Lesson 34: Topic: Constructing a classifier :: Reading, Activity: TBA, Worksheet Solns, take-aways\nApr 27 Lesson 35: Topic: Accounting for prevalence :: Reading, Activity: TBA, Worksheet Solns, take-aways\nMay 1 Lesson 36: Topic: Hypothesis testing :: Reading, Activity: TBA, Worksheet Solns, take-aways\nMay 3 Lesson 37: Topic: Calculating a p-value :: Reading, Activity: TBA, Worksheet Solns, take-aways\nMAY 4, PS6 due\nMay 5 Lesson 38: Topic: False discovery with hypothesis testing :: Reading, Activity: TBA, Worksheet Solns, take-aways\nMay 9 Lesson 39: REVIEW of lessons 28-38 :: Reading\nMay 11 Lesson 40: Review of entire course"
  },
  {
    "objectID": "Day-by-day/Lesson-34/Teaching-notes-34.html#in-draft",
    "href": "Day-by-day/Lesson-34/Teaching-notes-34.html#in-draft",
    "title": "Instructor Teaching Notes for Lesson 34",
    "section": "IN DRAFT",
    "text": "IN DRAFT\nTell the story of the Chinese spy balloon. After it was detected, the Air Force (according to news reports) increased the sensitivity of radars. This led to an increase in detection and a week-long rash of high-altitude detections, two of which were shot down. Eventually it was realized that there is a surprising amount of stuff floating around at high altitude. https://www.nytimes.com/live/2023/02/16/us/biden-china-balloon-ufo?smid=nytcore-ios-share&referringSource=articleShare"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "",
    "text": "You have been learning some basics of data wrangling and visualization, along with what ModernDive calls “basic regression” and “multiple regression.” These are tools which you will continue to use in the second half of the semester.\nSuch tools are necessary but usually not sufficient. Data only occasionally speak for themselves. Most often, we need to interpret data in the context of what we already know or believe about the system under study.\nExample: As you’ve seen, merely fitting a regression model does not demonstrate that there is a causal relationship between the explanatory variables and the response variable. We will need some new concepts to encode our ideas (and speculations) about causal relationships and to use regression modeling to inform (or contradict) our ideas.\nExample: We’ll see how to avoid seeing patterns and relationships for which the evidence in unpersuasive. Example: We will see how detection thresholds can be set to reflect our opinions about the costs and benefits of different ways of getting it right or wrong and our prior knowledge of the frequency of different kinds of events."
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#regression-models",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#regression-models",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Regression models",
    "text": "Regression models\nThe point of regression modeling is to detect and quantify patterns of relationship between variables. Sometimes simple data graphics are enough to display a pattern. For instance, let’s look at some Department of Transportation data on models of cars stored in the MPG data frame. We will start by looking at the link between fuel economy and CO_2_ production.\n\nggplot(MPG, aes(x = fuel_year, y = CO2_year)) +\n  geom_jitter(alpha=.3)\n\n\n\n\nThis is a very strong pattern. fuel_year and CO2_year are practically the same thing.\n\nWhy?\nWhy are there some points off of the straight line describing the large majority of points?\n\nOther times, patterns are hidden by extreme variability in the data. For instance, here are data on the effect of kindergarden class size on student outcomes.\n\nggplot(STAR, aes(x=classtype, y=g4math)) + geom_jitter() + geom_violin(alpha=.5, fill=\"blue\")\n\n\n\n\n\n\n\n\nRegression modeling is a technique for looking for simple forms of patterns in the relationships among variables. It is not the only such technique, but it is by far the most widely used in practice across diverse fields.\nWe will use only regression modeling (and allied methods) in this course. You may have heard about other methods such as “deep learning” or “neural networks,” but regression modeling is the basis for most of the others.\nIt’s critically important that you understand the framework for regression modeling.\n\nIn any one model, there is one variable that is identified as the response variable.\n\nThis identification depends on the purpose behind your work. You’ll learn it mostly by example.\n\nOther variables in the model are cast in the role of explanatory variables. There might be one explanatory variable or there might be other. There’s even a use for the case where there are no explanatory variables, but we don’t need to worry about that now.\nIn fitting a model to data (sometimes called “training a model on data”) the computer does the heavy lifting of finding a relationship between the response and explanatory variables that stays close to the data. Often, the “shape” of the relationship is very simple, e.g. a straight-line relationship or, more generally, a linear combination. That’s where the l comes in the function lm() that you will be using again and again in this course.\nIn using lm(), you specify which variables you want in the explanatory role and which single variable you have selected to be the response variable. The computer language syntax is very simple:\n\nresponse ~ var1 + var2 + ...\nThe name of the response variable is always on the left-hand side of the TILDE.\nThe explanatory variables are listed by name on the right side of the TILDE.\nThe + between the names of explanatory variables is mostly just punctuation. You can read it as “and”.\n\nThe TILDE character is usually just pronounced “tilde,” but English-language equivalents are\n\n“as explained by”\n“as accounted for by”\n“as modeled by”\n“versus”"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#data-graphics",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#data-graphics",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Data graphics",
    "text": "Data graphics\nSince the distinction between the response and the explanatory variables is so central, we are going to enforce a graphical style that reflects the distinction.\n\nThe response variable will always be on the vertical axis.\nOne of the explanatory variables will be on the horizontal axis.\nIf there is a second explanatory variable, we will use color.\nWhen we need a third or fourth explanatory variable, we will use faceting.\n\nIn the ggplot2 graphics system, this policy will appear like this:\nggplot(Dataframe, aes(y=response, x=var1, color=var2)) + geom_jitter() or geom_point() and so on."
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#models",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#models",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Models",
    "text": "Models\nWe have been working a lot with data frames. Now we are going to add a new type of R object, which we can call a “model”. A model is NOT a data frame, it is a different kind of thing with different properties and different operations.\nMaking a model:\n\nmod1 <- lm(sat~ expend, data=SAT)\n\nOperations we will perform on models:\n\nGraph the model (and usually the data used for training)\n::: {.cell}\nmodel_plot(mod1)\n::: {.cell-output-display}  ::: :::\n\nBeing able to use multiple explanatory variables allows us to see patterns that may be subtle.\n\nmod2 <- lm(sat ~ expend + frac, data=SAT)\nmodel_plot(mod2)\n\nWarning: Ignoring unknown aesthetics: fill\n\n\n\n\n\n\nModel summaries, especially conf_interval() and R2()\n\n\nmod2 |> conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr  .coef    .upr\n  <chr>        <dbl>  <dbl>   <dbl>\n1 (Intercept) 950.   994.   1038.  \n2 expend        3.79  12.3    20.8 \n3 frac         -3.28  -2.85   -2.42\n\nmod2 |> R2()\n\n   n k  Rsquared        F     adjR2 p df.num df.denom\n1 50 2 0.8194726 106.6741 0.8117906 0      2       47\n\n\n\nEvaluate the model at each of the rows of the training data.\n::: {.cell}\nmodel_eval(mod2) |> head()\n::: {.cell-output .cell-output-stderr} Using training data as input to model_eval(). :::\n::: {.cell-output .cell-output-stdout} .response expend frac   .output     .resid     .lwr      .upr  1      1029  4.405    8 1025.1463   3.853661 958.2677 1092.0250  2       934  8.963   47  969.9621 -35.962052 900.0065 1039.9176  3       944  4.778   27  975.5616 -31.561556 909.1283 1041.9948  4      1005  4.459    6 1031.5117 -26.511670 964.6071 1098.4162  5       902  4.992   45  926.8741 -24.874145 860.0437  993.7046  6       980  5.443   29  978.0302   1.969768 912.0035 1044.0570 ::: :::"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#todays-lesson",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#todays-lesson",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Today’s Lesson",
    "text": "Today’s Lesson\nA definition of “statistical thinking” from the book:\n\nStatistic thinking is the accounting for variation in the context of what remains unaccounted for.\n\nImplicit in this definition is a pathway for learning to think statistically:\n\nLearn how to measure variation;\nLearn how to account for variation;\nLearn how to measure what remains unaccounted for.\n\nToday: How to measure variation.\nConsider some closely related words: variable, variation, vary, various, variety, variant. The root is vari.\nOur preferred way to measure the amount of variation numerically: the variance, a single number, always positive.\n\nVariance always involves a single variable; it is about the variation in that variable.\nCalculate the variance is with var() within summarize() r DF |> summarize(NM = var(VAR))\nA good way to conceptualize the variance is as the average squared pairwise difference between values\nThe units of the variance are the square of the units of the variable.\nWhy square the pairwise differences? It’s a convention. Experience has shown this convention simplifies many operations we do with models. Underlying mathematics: Pythagorean theorem and formula for bell-shaped curve.\nOften people talk about the “standard deviation.” This is merely the square-root of the variance. But the variance is more fundamental mathematically. Using standard deviations introduces square roots in many calculations that don’t need to be there if we use variance."
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#activity",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#activity",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "Day-by-day/Lesson-19/Teaching-notes-19.html#administration",
    "href": "Day-by-day/Lesson-19/Teaching-notes-19.html#administration",
    "title": "Instructor Teaching Notes for Lesson 19",
    "section": "Administration",
    "text": "Administration\n\nUse “300Z Section” under Teams.\nClone the Z-section project on posit.cloud. We’ll use this project for the rest of the semester.\nThere will be a “worksheet” almost every day.\n\nThe worksheet is in the form of an Rmd file. To access it, go into the Z-section project and give a command like this: get_lesson_worksheet(19) or whatever the lesson number is.\nAn effective way to prepare for a class is to look at the worksheet before class. Just read it and take note of what doesn’t make sense to you. That way you can be attentive to those things in class.\nComplete the worksheet after class.\nCome with unresolved questions about the worksheet for the next class or for EI.\n\nMost days there will also be a group activity.\nThere will be a couple of problem sets that will be graded.\nThere will be one GR about half-way through the rest of the semester. And a final GR."
  },
  {
    "objectID": "Worksheet-20.html",
    "href": "Worksheet-20.html",
    "title": "Lesson 20: Worksheet",
    "section": "",
    "text": "20.1 [Technical] Collect a sample from a DAG simulation.\n20.2 [Technical] Examine the formulas behind a DAG simulation and compare to the results of a regression model trained on a sample from the DAG simulation.\n20.3 [Conceptual] Recognize properties of a DAG. i. Identify exogenous nodes. ii. Identify all pathways between two specified end nodes. iii. On a given pathway, is there causal flow from one end node to another? iv. On a given pathway, is there a causal flow from some node on the pathway to both end nodes?"
  },
  {
    "objectID": "Worksheet-20.html#part-1-samples-from-dags",
    "href": "Worksheet-20.html#part-1-samples-from-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 1: Samples from DAGs",
    "text": "Part 1: Samples from DAGs\n\nUse dag_draw() to draw a picture of the dag08 directed acyclic graph. From this graph, explain why node c is exogenous and why x and y are not.\n\nANSWER:\n\nUse print() to view the formulas used by dag08 to simulate data. What about the formula for y indicates that it’s receives inputs from x and c.\n\nANSWER:\n\nThere are three coefficients in the formula for y: an intercept, an x coefficient, and a c coefficient. (There is also some random input from an exogenous source unrelated to c or x.) What are the numerical values of the three coefficients?\n\nANSWER:\n\nCollect a sample of size \\(n=100\\) from dag08 and use it to train the model with specification y ~ x. Do the coefficients reported match those you found in part (c)? (If you are not sure, use a bigger sample size, say \\(n=1000\\) or even bigger.)\n\nANSWER:\nThe model says the x coefficient is about 1.5, not the same as in the DAG formula for y.\n\nSimilar to (4), but use the specification y ~ x + c. How do the coefficients for this model compare to those you found in (3)?\n\nANSWER:"
  },
  {
    "objectID": "Worksheet-20.html#part-2-paths-in-dags",
    "href": "Worksheet-20.html#part-2-paths-in-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 2: Paths in DAGs",
    "text": "Part 2: Paths in DAGs\n\nIn dag08 there are two paths connecting x andy. One path is direct, \\(X \\longrightarrow Y\\). The other path is indirect, \\(X \\longleftarrow C \\longrightarrow Y\\).\n\nAlong the indirect path, is there a causal flow from x to y?\nAlong the indirect path, is there a causal flow from any node on the graph that reaches both endpoints, x and y?\n\n\nANSWER:\n\ndag_school2 is a highly simplistic model of the relationship between expenditures on schools and student outcomes in terms of, say, standardized test scores.\n\n\ndag_draw(dag_school2, vertex.label.cex=1, vertex.size=40)\n\n\n\n\nThere is a direct pathway from expenditure to outcome as well as another, indirect pathway.\n\nAre there any exogenous nodes in the graph?\nOn the indirect pathway, is there a causal flow from expenditure to outcome?\nIs there a causal flow from any node on the indirect pathway to both expenditure and outcome? Which one?\n\nANSWER:"
  },
  {
    "objectID": "Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "href": "Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "title": "Lesson 20: Worksheet",
    "section": "Part 3: Are expenditures good for school outcomes?",
    "text": "Part 3: Are expenditures good for school outcomes?\n\nLook at the formulas for dag_school2. Is a higher expenditure connected to a higher outcome?\n\nANSWER:\n\nGenerate a simple of size 1000 from dag_school2 and use it to train the model outcome ~ expenditure. Is the coefficient on expenditure consistent with what you found in (1)? (If you aren’t sure, use a larger sample size, say 10,000.) What about the coefficient on expenditure leads to your conclusion?\n\nANSWER:\n\nSpeculate on what might be the origin of the evident inconsistency between (1) and (2)?\n\nANSWER:"
  },
  {
    "objectID": "Worksheet-20.html#part-4-constructing-a-dag",
    "href": "Worksheet-20.html#part-4-constructing-a-dag",
    "title": "Lesson 20: Worksheet",
    "section": "Part 4: Constructing a DAG",
    "text": "Part 4: Constructing a DAG\nIn this task, you will construct DAGs using dag_make() and draw them using dag_draw().\nA DAG is defined by a series of tilde expressions, one for each node in the graph. The tilde expression for a node has the node’s name on the left-hand side of the tilde. The right-hand side contains the nodes which serve as inputs to the node named on the left-hand side. If there are no inputs, write exo().\nFor example, consider a DAG with three nodes: one, two, and three. To define a DAG where node two receives input from node one, and node three receives input from nodes one and two, use make_dag() with three tilde expressions:\n\nexample_dag <- dag_make(\n  one ~ exo(),\n  two ~ one,\n  three ~ two + one\n)\ndag_draw(example_dag)\n\n\n\n\nThe right-hand side of a formula can be any arithmetic expression involving the node names, but we will keep it simple: just use + to separated the node names. If a node receives no inputs, the right-hand side should be simply exo() to mark that node as exogenous.\n\nWhat happens if node one, instead of being exogenous, takes as input one of the other two nodes in example_dag?\n\nANSWER:\n\nCreate and draw a DAG that has the same arrangement of causal connections as “Professor Butts and the Self-Operating Napkin,” illustrated below:\n\n\nProfessor Butts and the Self-Operating Napkin (1931). Soup_spoon (A) is raised to mouth, pulling string (B) and thereby jerking ladle (C), which throws cracker (D) past toucan (E). Toucan jumps after cracker and perch (F) tilts, upsetting seeds (G) into pail (H). Extra weight in pail pulls cord (I), which opens and ignites lighter (J), setting off skyrocket (K), which causes sickle (L) to cut string_m (M), allowing pendulum with attached napkin to swing back and forth, thereby wiping_chin.\nWatch your spelling of node names! Use this command to draw your napkin_dag:\ndag_draw(napkin_dag, vertex.label.cex=.5, vertex.size=10, edge.arrow.size = 0.2)\nANSWER:"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html",
    "href": "Worksheets/Worksheet-19.html",
    "title": "Lesson 19: Worksheet",
    "section": "",
    "text": "19.1. [Conceptual] Master the use and units of variance and standard deviation in measuring variability.\n19.2. [Conceptual] Understand the equivalence between mean and proportion on a zero-one variable.\n19.3. [Technical] Use var() and sd() within summarize()\n19.4. [Technical] Use model_plot() to graph models with one or two explanatory variables.\n19.5. [Technical] Use zero_one() with mutate() to create a zero-one variable."
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#preliminaries-how-we-will-work-with-r.",
    "href": "Worksheets/Worksheet-19.html#preliminaries-how-we-will-work-with-r.",
    "title": "Lesson 19: Worksheet",
    "section": "Preliminaries: How we will work with R.",
    "text": "Preliminaries: How we will work with R.\nIn the first half of Math 300Z, the daily student notes were largely structured around “scaffolded” R code, which often involved filling in the blanks. In this second half of 300Z, we will start to use a new way of helping you construct appropriate R command. We call this “command patterns. For instance,\nDF %>% summarize(NM=var(VAR)) \nis a command pattern.\nOne reason for the shift to the command-pattern style is that there will be only a handful of new patterns in the second half of the course that you’ll be using over and over again. Another reason is to help you develop “finger memory” for the most common patterns. An analogy: scaffolding is like GPS navigation which certainly makes it easier to drive but harder to get to know the town. Command patterns are like a paper map, there to help you when you need it.\nThere is a specific notation for command patterns, which you should memorize. Instead of the blanks used in a scaffold, the command pattern uses a CAPITALIZED abbreviation for the **kind of thing* that should be put in the position. Common kinds of thing are\n\nDF: a data frame, almost always referred to by name.\nVAR: a variable in a data frame. Many command patterns involve multiple variables, each of which is referred to by VAR. You will replace each VAR with the appropriate variable name.\nVARS: one or more variable names. When these are the right-hand side of a tilde expression, separate the names with + punctuation. When we mean to indicate that there is only one variable, we use VAR instead of VARS. If we want to say, “use two variables,” we would write VAR + VAR.\nMODEL refers to the name of a model that you have previously constructed with lm().\nNM means a name that you will be calling something by. For instance, NM <- lm(VAR ~ VARS, data=DF). Another occasion for using NM is as part of an argument to summarize() or mutate().\n[, MORE] means that you can have multiple additional arguments of the same form as the previous argument.\nVALUE a number, quoted string (e.g., \"red\"), or multiple values inside c( ).\nMODSPEC is a model specification, which could equally well be written VAR ~ VARS\n\nAnything in a command pattern that is not a CAPITALIZED abbreviation is a specific part of the command to be used as-is. For instance, lm(VAR ~ VARS, data=DF) refers explicitly to the lm() function whose first argument is a tilde expression and whose second argument is named data.\nOccasionally, you will refer to a data frame by naming the package from which it comes. For example, the moderndive package includes (among many others) the amazon_books data frame. Think of amazon_books as a first name, and moderndive as a family name. When you see PACKAGE::DF it is meant to indicate, for instance, moderndive::amazon_books. (Note that the :: in the command pattern is to be taken literally; there are two successive colons separating the package name from the name of the data frame.)"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#part-1",
    "href": "Worksheets/Worksheet-19.html#part-1",
    "title": "Lesson 19: Worksheet",
    "section": "Part 1",
    "text": "Part 1\nCommand patterns:\n\nDF %>% summarize(NM = var(VAR)) Calculate variance of a variable in a data frame.\n`DF %>% summarize(NM1 = var(VAR1), NM2 = var(VAR2) [, MORE])\nPACKAGE::DF The name of a data frame within a package.\n\n\nIn the mosaicData::Galton data frame, find the variance of mother and father. Give both the numerical value and the units.\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmosaicData::Galton |> \n  summarize(vmother = var(mother), vfather = var(father))\n\n   vmother  vfather\n1 5.322365 6.102164\n\n\nThe units for both are `inches-squared” since the variables themselves have units “inches.”\n\n\n\nIn the moderndive::amazon_books data frame, find the variance of list_price and num_pages. Give both the numerical value and the units.\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmoderndive::amazon_books |>\n  summarize(vprice = var(list_price), vpages = var(num_pages))\n\n# A tibble: 1 × 2\n  vprice vpages\n   <dbl>  <dbl>\n1     NA     NA\n\n\nThe units of list_price are dollars, so the variance has units “square-dollars”.\nnum_pages is dimensionless, so the variance is also dimensionless.\n\n\n\nCalculate the variance of sex from Galton. If something goes wrong, explain why.\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nGalton |> summarize(vsex = var(sex))\n\nError in `summarize()`:\n! Problem while computing `vsex = var(sex)`.\nCaused by error in `stats::var()`:\n! Calling var(x) on a factor x is defunct.\n  Use something like 'all(duplicated(x)[-1L])' to test for a constant vector.\n\n\nsex is a categorical variable. There’s no such thing as the variance of a categorical variable."
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#part-2",
    "href": "Worksheets/Worksheet-19.html#part-2",
    "title": "Lesson 19: Worksheet",
    "section": "Part 2",
    "text": "Part 2\nCommand patterns:\n\nNM <- lm(VAR ~ VARS, data = DF)\nlm(VAR ~ VARS, data=DF) %>% conf_interval()\nlm(MODSPEC, data=DF) %>% conf_interval() means the same as (b).\n\n\n(Easy, no computing needed.) What kind of a thing is conf_interval(). (Hint: It’s the same kind of thing as lm().)\n\n\n\n\n\n\n\nANSWER:\n\n\n\nconf_interval() is a function.\n\n\n\nUsing the moderndive::amazonbooks data frame, fit the model list_price ~ num_pages:\n\nWhat are the units of the “(Intercept)” coefficient?\nReport the coefficient on num_pages. Give both the numerical bounds and the units.\n\n\n\n\n\n\n\n\nANSWER:\n\n\n\nThe intercept always has the same units as the response variable. Here, that’s dollars.\n\nlm(list_price ~ num_pages, data = moderndive::amazon_books) |>\n  conf_interval()\n\n# A tibble: 2 × 4\n  term          .lwr   .coef    .upr\n  <chr>        <dbl>   <dbl>   <dbl>\n1 (Intercept) 8.33   11.8    15.4   \n2 num_pages   0.0105  0.0199  0.0293\n\n\nCoefficient on num_pages: .02 dollars per page. Multiplying the coefficient by the number of pages will give dollars: the units of the response variable.\n\n\n\nSimilar to (2) but with the model list_price ~ numpages + hard_paper\n\nWhat does the term hard_paperH refer to?\nAccording to the coefficients, is a hardcover book any more expensive (on average) than a softcover book?\n\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nlm(list_price ~ num_pages + hard_paper, data = moderndive::amazon_books) |>\n  conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr   .coef    .upr\n  <chr>        <dbl>   <dbl>   <dbl>\n1 (Intercept) 7.04   10.6    14.2   \n2 num_pages   0.0102  0.0196  0.0289\n3 hard_paperH 1.56    4.96    8.36  \n\n\nhard_paperH refers to the H level of the hard_paper variable. According to the model, a hardback costs $4.96 more than a paperback, on average.\n\n\n\nStore the model you created in (3) under the name mod3. We’ll use it in the next part. For your answer, put the R command you used to store the model as mod3.\n\n\n\n\n\n\n\nANSWER:\n\n\n\nNote that we are asked to store the model itself, not the confidence interval.\n\nmod3 <- lm(list_price ~ num_pages + hard_paper, data = moderndive::amazon_books)"
  },
  {
    "objectID": "Worksheets/Worksheet-19.html#graphics-review",
    "href": "Worksheets/Worksheet-19.html#graphics-review",
    "title": "Lesson 19: Worksheet",
    "section": "Graphics review",
    "text": "Graphics review\nCommand patterns:\n\nggplot(DF, aes(x=VAR, y=VAR)) + geom_jitter()\nggplot(DF, aes(x=VAR, y=VAR)) + geom_jitter() + geom_violin(fill=\"blue\", alpha=0.3)\nggplot(DF, aes(x=\"all\", y=VAR)) + geom_jitter()\nmodel_plot(MODEL, x=VAR)\nmodel_plot(MODAL, x=VAR, color=VAR)\n\n\nMake a jitter plot of list_price ~ hard_paper from moderndive::amazon_books.\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmoderndive::amazon_books |>\n  ggplot(aes(x=hard_paper, y = list_price)) + \n  geom_jitter(alpha=0.5)\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nUsing your command from (1), add a new layer: + geom_violin(fill=\"blue\", alpha=0.3)\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmoderndive::amazon_books |>\n  ggplot(aes(x=hard_paper, y = list_price)) + \n  geom_jitter(alpha=0.5) +\n  geom_violin(fill=\"blue\", alpha=0.3)\n\nWarning: Removed 1 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nUse model_plot() to draw a picture of mod3. Set x=hard_paper and num_pages=200. What do you think the horizontal line segments refer to?\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmodel_plot(mod3, x=hard_paper, num_pages=200)\n\n\n\n\nThe vertical position of the horizontal lines indicates the model output for books with 200 pages.\n\n\n\nRepeat (3), but remove num_pages = 200. Instead, set x=num_pages and color=hard_paper. Explain the meaning of the line segments in everyday terms.\n\n\n\n\n\n\n\nANSWER:\n\n\n\n\nmodel_plot(mod3, x=hard_paper, color=num_pages)\n\n\n\n\nThe parallel line segments in each column show the model output for books with 200, 400, and 600 pages respectively."
  },
  {
    "objectID": "Worksheets/Worksheet-20.html",
    "href": "Worksheets/Worksheet-20.html",
    "title": "Lesson 20: Worksheet",
    "section": "",
    "text": "20.1 [Technical] Collect a sample from a DAG simulation.\n20.2 [Technical] Examine the formulas behind a DAG simulation and compare to the results of a regression model trained on a sample from the DAG simulation.\n20.3 [Conceptual] Recognize properties of a DAG. i. Identify exogenous nodes. ii. Identify all pathways between two specified end nodes. iii. On a given pathway, is there causal flow from one end node to another? iv. On a given pathway, is there a causal flow from some node on the pathway to both end nodes?"
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-1-samples-from-dags",
    "href": "Worksheets/Worksheet-20.html#part-1-samples-from-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 1: Samples from DAGs",
    "text": "Part 1: Samples from DAGs\n\nUse dag_draw() to draw a picture of the dag08 directed acyclic graph. From this graph, explain why node c is exogenous and why x and y are not.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\ndag_draw(dag08)\n\n\n\n\nNode C is exogenous because it has no incoming arrows.\n\n\n\nUse print() to view the formulas used by dag08 to simulate data. What about the formula for y indicates that it’s receives inputs from x and c.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nprint(dag08)\n\nc ~ exo()\nx ~ c + exo()\ny ~ x + c + 3 + exo()\n\n\nThe right-hand side of the formula for y says that y will be calculated as the sum of x and c (plus 3 plus some random noise). That is, x and c directly shape the value of y.\n\n\n\nThere are three coefficients in the formula for y: an intercept, an x coefficient, and a c coefficient. (There is also some random input from an exogenous source unrelated to c or x.) What are the numerical values of the three coefficients?\n\n\n\n\n\n\n\nANSWER\n\n\n\nFrom the formula for y in the dag, the coefficients are 1 for x, 1 for c, and 3 for the intercept.\n\n\n\nCollect a sample of size \\(n=100\\) from dag08 and use it to train the model with specification y ~ x. Do the coefficients reported match those you found in part (c)? (If you are not sure, use a bigger sample size, say \\(n=1000\\) or even bigger.)\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nSamp <- sample(dag08, size=1000)\nlm(y ~ x, data=Samp) |> conf_interval()\n\n# A tibble: 2 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept)  2.83  2.90  2.98\n2 x            1.36  1.41  1.47\n\n\n\n\nThe model says the x coefficient is about 1.5, not the same as in the DAG formula for y.\n\nSimilar to (4), but use the specification y ~ x + c. How do the coefficients for this model compare to those you found in (3)?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nSamp <- sample(dag08, size=1000)\nlm(y ~ x + c, data=Samp) |> conf_interval()\n\n# A tibble: 3 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept) 2.90  2.97   3.03\n2 x           0.919 0.983  1.05\n3 c           0.901 0.989  1.08\n\n\nWhen we include both x and c in the model specification, the coefficients work out to match those of the DAG formula for y."
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-2-paths-in-dags",
    "href": "Worksheets/Worksheet-20.html#part-2-paths-in-dags",
    "title": "Lesson 20: Worksheet",
    "section": "Part 2: Paths in DAGs",
    "text": "Part 2: Paths in DAGs\n\nIn dag08 there are two paths connecting x andy. One path is direct, \\(X \\longrightarrow Y\\). The other path is indirect, \\(X \\longleftarrow C \\longrightarrow Y\\).\n\nAlong the indirect path, is there a causal flow from x to y?\nAlong the indirect path, is there a causal flow from any node on the graph that reaches both endpoints, x and y?\n\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nYes, the flow runs directly from x to y.\nYes. The flow runs from c to each of x and y.\n\n\n\n\ndag_school2 is a highly simplistic model of the relationship between expenditures on schools and student outcomes in terms of, say, standardized test scores.\n\n\ndag_draw(dag_school2, vertex.label.cex=1, vertex.size=40)\n\n\n\n\nThere is a direct pathway from expenditure to outcome as well as another, indirect pathway.\n\nAre there any exogenous nodes in the graph?\nOn the indirect pathway, is there a causal flow from expenditure to outcome?\nIs there a causal flow from any node on the indirect pathway to both expenditure and outcome? Which one?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nCulture is an exogenous node; there are no incoming arrows to culture.\nYes.\nFrom Culture there is a flow to outcome through expenditure. There is also a flow from Culture to Outcome via Participation."
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "href": "Worksheets/Worksheet-20.html#part-3-are-expenditures-good-for-school-outcomes",
    "title": "Lesson 20: Worksheet",
    "section": "Part 3: Are expenditures good for school outcomes?",
    "text": "Part 3: Are expenditures good for school outcomes?\n\nLook at the formulas for dag_school2. Is a higher expenditure connected to a higher outcome?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nprint(dag_school2)\n\nculture ~ unif(-1, 1)\nexpenditure ~ 12000 + 4000 * culture + exo(1000)\nparticipation ~ (50 + 30 * culture + exo(15)) %>% pmax(0) %>% \n    pmin(100)\noutcome ~ 1100 + 0.01 * expenditure - 4 * participation + exo(50)\n\n\nThe formula for Outcome has a positive coefficient (0.01) on expenditure. So when expenditure goes up, so will outcome. The magnitude of the coefficient is neither here nor there. Remember that there are always units associated with a coefficient. It’s impossible to say whether a magnitude is large or small unless you know the units.\n\n\n\nGenerate a simple of size 1000 from dag_school2 and use it to train the model outcome ~ expenditure. Is the coefficient on expenditure consistent with what you found in (1)? (If you aren’t sure, use a larger sample size, say 10,000.) What about the coefficient on expenditure leads to your conclusion?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nSamp <- sample(dag_school2, size=1000)\nlm(outcome ~ expenditure, data=Samp) |> conf_interval()\n\n# A tibble: 2 × 4\n  term             .lwr     .coef      .upr\n  <chr>           <dbl>     <dbl>     <dbl>\n1 (Intercept) 1191.     1215.     1239.    \n2 expenditure   -0.0179   -0.0160   -0.0140\n\n\nThe coefficient on Expenditure is negative in contrast to the known positive coefficient in the DAG formula for Outcome.\n\n\n\nSpeculate on what might be the origin of the evident inconsistency between (1) and (2)?\n\n\n\n\n\n\n\nANSWER\n\n\n\nIn the DAG, Outcome is influenced negatively by Participation. And Expenditure is influenced positively by Participation. The two effects of Participation combine to produce an overall negative link between Expenditure and Outcome. By overall, we mean the combination of the direct Expenditure to Outcome link and the indirect path from Expenditure to Outcome via Participation."
  },
  {
    "objectID": "Worksheets/Worksheet-20.html#part-4-constructing-a-dag",
    "href": "Worksheets/Worksheet-20.html#part-4-constructing-a-dag",
    "title": "Lesson 20: Worksheet",
    "section": "Part 4: Constructing a DAG",
    "text": "Part 4: Constructing a DAG\nIn this task, you will construct DAGs using dag_make() and draw them using dag_draw().\nA DAG is defined by a series of tilde expressions, one for each node in the graph. The tilde expression for a node has the node’s name on the left-hand side of the tilde. The right-hand side contains the nodes which serve as inputs to the node named on the left-hand side. If there are no inputs, write exo().\nFor example, consider a DAG with three nodes: one, two, and three. To define a DAG where node two receives input from node one, and node three receives input from nodes one and two, use make_dag() with three tilde expressions:\n\nexample_dag <- dag_make(\n  one ~ exo(),\n  two ~ one,\n  three ~ two + one\n)\ndag_draw(example_dag)\n\n\n\n\nThe right-hand side of a formula can be any arithmetic expression involving the node names, but we will keep it simple: just use + to separated the node names. If a node receives no inputs, the right-hand side should be simply exo() to mark that node as exogenous.\n\nWhat happens if node one, instead of being exogenous, takes as input one of the other two nodes in example_dag?\n\n\n\n\n\n\n\nANSWER\n\n\n\nThe graph would become cyclic, hence not a DAG. Notice that by using a node on the right-hand side of a tilde expression only when it has already been created by a previous tilde expression, you guarantee that the graph will be acyclic.\n\n\n\nCreate and draw a DAG that has the same arrangement of causal connections as “Professor Butts and the Self-Operating Napkin,” illustrated below:\n\n\nProfessor Butts and the Self-Operating Napkin (1931). Soup_spoon (A) is raised to mouth, pulling string (B) and thereby jerking ladle (C), which throws cracker (D) past toucan (E). Toucan jumps after cracker and perch (F) tilts, upsetting seeds (G) into pail (H). Extra weight in pail pulls cord (I), which opens and ignites lighter (J), setting off skyrocket (K), which causes sickle (L) to cut string_m (M), allowing pendulum with attached napkin to swing back and forth, thereby wiping_chin.\nWatch your spelling of node names! Use this command to draw your napkin_dag:\ndag_draw(napkin_dag, vertex.label.cex=.5, vertex.size=10, edge.arrow.size = 0.2)\n\n\n\n\n\n\nANSWER\n\n\n\n\nnapkin_dag <- dag_make(\n  soup_spoon ~ exo(),\n  string ~ soup_spoon,\n  ladle ~ string,\n  cracker ~ ladle,\n  toucan ~ cracker,\n  perch ~ toucan,\n  seeds ~ perch,\n  pail ~ seeds,\n  cord ~ pail,\n  lighter ~ cord,\n  skyrocket ~ lighter,\n  sickle ~ skyrocket,\n  string_m ~ sickle,\n  wiping_chin ~ string_m\n)\ndag_draw(napkin_dag, vertex.label.cex=.5, vertex.size=10, edge.arrow.size = 0.2)"
  },
  {
    "objectID": "Worksheets/Worksheet-21.html",
    "href": "Worksheets/Worksheet-21.html",
    "title": "Lesson 21: Worksheet",
    "section": "",
    "text": "Command patterns:"
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#basic-regression-patterns",
    "href": "Worksheets/Worksheet-21.html#basic-regression-patterns",
    "title": "Lesson 21: Worksheet",
    "section": "Basic regression patterns",
    "text": "Basic regression patterns\nEvery regression model involves a response variable, which Lessons in Statistical Thinking always plots on the vertical axis. Most of the regression models we will consider in these Lessons have one or two explanatory variables, although sometimes there will be more than two and sometimes none at all.\nIt is worth memorizing the forms of the tilde-expression specifications of the zero-, one-, and two-explanatory models, as well as their shapes. For this purpose, we’ll write the forms using five generic variable names. In practice, you will replace these generic names with specific names from the data frame of interest.\n\ny — a quantitative response variable (which might be the result of a zero-one transformation).\nx and z — quantitative explanatory variables\ng and h — categorical explanatory variables.\n\n\n\n\n\n\n\n\nModel specification\nShape\n\n\n\n\ny ~ 1\nA line with slope zero.\n\n\ny ~ x\nA line with possibly non-zero slope.\n\n\ny ~ g\nA value for each level of g.\n\n\ny ~ x + g\nSeparate lines for each level of g, all with the same slope.\n\n\ny ~ x + z\nParallel, evenly spaced lines.\n\n\ny ~ g + h\nFor each level of g, a set of spaced values, one for each level of h. The h-spacing will be the same for every level of g.\n\n\n\nNote: It doesn’t matter what order the explanatory variables are given in. The name of the response variable is always on the left-hand side of the tilde expression."
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#part-1",
    "href": "Worksheets/Worksheet-21.html#part-1",
    "title": "Lesson 21: Worksheet",
    "section": "Part 1",
    "text": "Part 1\nDo Exercise 21.4."
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#part-2",
    "href": "Worksheets/Worksheet-21.html#part-2",
    "title": "Lesson 21: Worksheet",
    "section": "Part 2",
    "text": "Part 2\nBy fitting a regression model, we divide the response variable into two components: a signal component and a noise component. The model specification tells what sort of signal to look for. For instance, the Clock_auction data frame records the sales price of antique grandfather clocks sold at auction. Presumably, the price reflects some feature of the clock itself as well as the market conditions. We have only the variables age and bidders to represent the the value of the clock and the market conditions.\nUsing lm() with the specification price ~ age directs the computer to look for a signal in the form of a straight-line relationship between age and price. The estimated noise is the difference between the response variable values (price) and the signal.\n\nHow much clock-to-clock variation is there in price? (Use the variance to measure variation.)\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nClock_auction |> summarize(vprice = var(price), sd=sqrt(vprice))\n\n# A tibble: 1 × 2\n   vprice    sd\n    <dbl> <dbl>\n1 134203.  366.\n\n\nSince the price is in dollars, the variance of price has units of “square dollars.” This is a unit that’s hard to get your head around. That’s why many people prefer the “standard deviation”, which is the square root of the variance.\n\n\n\nFit a model price ~ age, then plot with model_plot(). Describe the pattern between price and age you see in the plot.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nmod1 <- lm(price ~ age, data=Clock_auction)\nmodel_plot(mod1)\n\n\n\n\nAccording to the model, price goes up with age. A 25 year increase in age corresponds to about a $200 increase in price.\n\n\n\nUse model_eval() to find the model output for each clock for the model you constructed in (2).\n\nWhat’s the variance of the model .output? How does it compare to the variance of the response variable price?\nThe amount of noise can be measured with the variance of .resid. How much noise is there for price ~ age?\nDemonstrate arithmetically the relationship between the variance of the response variable, the variance of the model .output, and the variance of the noise.\n\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nValues <- model_eval(mod1)\n\nUsing training data as input to model_eval().\n\nValues |> summarize(voutput = var(.output))\n\n   voutput\n1 66352.26\n\n\nThe variance of the model output (note the dot used in the name .output) is 66-thousand square dollars. (Why “square dollars?” Because the response variable is price which is in dollars. The model output always has the same units as the response variable. And the variance of a variable always has units that are the square of the variable’s units.) The variance of the price variable is about 134-thousand square dollars, so the model output has about half the variance of the response.\n\nValues |> summarize(vresid = var(.resid))\n\n    vresid\n1 67850.62\n\n\nThe variance of the residuals is about 68-thousand square dollars. (The residuals always have the same units as the response variable.)\nTo show that the sum of the variances of the model output and residuals equals the variance of the response variable, just add them up and compare:\n\n66352.26 + 67850.62\n\n[1] 134202.9\n\n\nThe result exactly matches the variance of the price variable (calculated above).\n\n\n\nUse R2() to summarize the model you constructed in (2). Demonstrate arithmetically the relationship between R2 and variances of the response variable and the model .output.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nmod1 |> R2()\n\n   n k  Rsquared       F     adjR2            p df.num df.denom\n1 32 1 0.4944176 29.3375 0.4775648 5.914169e-06      1       30\n\n\nR2 is 0.49. This exactly matches the quotient of the variance of the model output divided by the variance of the response variable:\n\nValues |> summarize(ratio = var(.output) / var(.response))\n\n      ratio\n1 0.4944176\n\n\n\n\n\nThe quantity 1 - R2 describes the amount of noise. Arithmetically, how does 1 - R2 correspond to the variance of the .resid from part (3)?\n\n\n\n\n\n\n\nANSWER\n\n\n\nFirst, the value of 1 - R2, then the ratio of the variance of the residuals to the variance of the response variable:\n\n1 - 0.4944176\n\n[1] 0.5055824\n\nValues |> summarize(ratio = var(.resid) / var(.response))\n\n      ratio\n1 0.5055824"
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#part-3-r2",
    "href": "Worksheets/Worksheet-21.html#part-3-r2",
    "title": "Lesson 21: Worksheet",
    "section": "Part 3: R2",
    "text": "Part 3: R2\ndag10 has a simple structure, with nodes a through f each contributing to the value of y. Use sample() to generate a sample of size 1000. Using your sample, construct several models and calculate the R2 statistic.\n\ny ~ 1.\ny ~ a\ny ~ b\ny ~ a + b\nand so on.\n\n\nWhich of the models gives the smallest value of R2? Explain why that particular model gives such a small R2.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nOur_sample <- sample(dag10, size=1000) \nlm(y ~ 1, data=Our_sample) |> R2()\n\n     n k Rsquared   F adjR2   p df.num df.denom\n1 1000 0        0 NaN     0 NaN      0      999\n\nlm(y ~ a, data=Our_sample) |> R2()\n\n     n k  Rsquared        F     adjR2 p df.num df.denom\n1 1000 1 0.1370083 158.4421 0.1361435 0      1      998\n\nlm(y ~ b, data=Our_sample) |> R2()\n\n     n k  Rsquared        F     adjR2 p df.num df.denom\n1 1000 1 0.3093868 447.0925 0.3086948 0      1      998\n\nlm(y ~ a + b, data=Our_sample) |> R2()\n\n     n k  Rsquared        F     adjR2 p df.num df.denom\n1 1000 2 0.4159078 354.9612 0.4147361 0      2      997\n\n\nThe model y ~ 1 has R2=0 because the pseudo-variable 1 has zero variance and cannot “explain” any of the variance in the response variable y.\n\n\n\nAs you add more terms to the model specification, does R2 ever go down?\n\n\n\n\n\n\n\nANSWER\n\n\n\nModel specifications like y ~ a are actually shorthand for y ~ 1 + a. So y ~ a has an additional explanatory variable in addition to the pseudo-variable 1. Whenever you add a new explanatory variable to an existing model specification, the R2 will increase (or, more precisely, cannot decrease).\n\n\n\nWhat effect does the order of terms in the model have on R2? (For instance, y ~ a + b + c versus y ~ c + a + b.)\n\n\n\n\n\n\n\nANSWER\n\n\n\nCompare, for instance, y ~ a + b + c to y ~ c + a + b\n\nlm(y ~ a + b + c, data=Our_sample) |> R2()\n\n     n k Rsquared        F   adjR2 p df.num df.denom\n1 1000 3 0.446557 267.8811 0.44489 0      3      996\n\nlm(y ~ c + a + b, data=Our_sample) |> R2()\n\n     n k Rsquared        F   adjR2 p df.num df.denom\n1 1000 3 0.446557 267.8811 0.44489 0      3      996\n\n\nThe order of explanatory variables does not matter at all. It’s the collection that matters."
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#part-4-concept-check",
    "href": "Worksheets/Worksheet-21.html#part-4-concept-check",
    "title": "Lesson 21: Worksheet",
    "section": "Part 4: Concept check",
    "text": "Part 4: Concept check\nWrite a sentence or two explaining what each of the following terms refers to.\n\n“Levels of a categorical variable”\n“Zero-one transformation”\n“Model specification”\n“Tilde expression”\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nLevels of a categorical variable. The values of a categorical variable are named. For instance, a household_pets variable would take on values like “cat,” “dog,” “turtle,” “parakeet,” …. The set of possible values for the categorical variable is called the “levels” of the variable.\nZero-one transformation. A means to translate a categorical variable with two levels into a quantitative variable. One of the levels is translated to the numerical value 1, the other to 0. The advantage of this particular scheme is that means or models where the zero-one variable is used for the response variable will have model outputs that can be interpreted as probabilities.\nModel specification. When constructing a regression model, the modeler has to provide two different kinds of inputs: (1) a data frame for training the model, (2) a statement about which variable from the data frame to use as the response variable and which other variables to use as explanatory variables. This statement (2) is called the “model specification.”\nTilde expression. Tilde expressions are an element of the syntax (or “grammar”) of R. They always involve the tilde character (~) which has no other legitimate use in R. Any valid R expression can be used on the right-side of tilde. The left side (if present, as will be the case when used with lm()) can also be any valid R expression. The most prominant role for tilde expressions in Math 300Z is to hold the model specification for use by lm(). In this use, the response variable’s name always goes on the left side of the tilde. Explanatory variable names go on the right side, usually separated by + as punctuation.\nFor the computer-science oriented …. Tilde expressions are a way to represent symbolic expressions such as fragments of code. In ordinary use, R tries to evaluate every code fragment, replacing names with their values and invoking any functions used. Symbolic expressions are taken literally as a code fragment, without any evaluation. This is valuable as a means to pass code fragments to a function which can then parse or otherwise evaluate the fragment in a particular context."
  },
  {
    "objectID": "Worksheets/Worksheet-21.html#part-5-curvy-models",
    "href": "Worksheets/Worksheet-21.html#part-5-curvy-models",
    "title": "Lesson 21: Worksheet",
    "section": "Part 5: Curvy models",
    "text": "Part 5: Curvy models\nHere’s a model of human height versus age based on the NHANES::NHANES data frame. (The package NHANES has the data frame which itself is called NHANES, so the full name is NHANES::NHANES.)\n\nmod1 <- lm(Height ~ Age, data = NHANES::NHANES)\nmodel_plot(mod1, data_alpha=0.05)\n\nWarning: Removed 353 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nDo you think the model gives a good description of the relationship between Age and Height? Explain using simple biological terms what the problem is with the straight-line model.\n\n\n\n\n\n\n\nANSWER\n\n\n\nHumans and other animals grow in a non-linear manner: rapid growth during gestation, infancy, and youth and comparative stasis later in life. With a model specification like Height ~ Age, lm() will look for a purely linear function, as in the straight line in the above graphic. The linear function doesn’t capture the age-dependent growth rate (fast during youth, slow or nil in adulthood), since a straight line has the same slope at all values of the explanatory variable.\nOne of the signs of the ill-fit of a linear model is that the response values tend to be cluster mostly below or mostly above the line for different regions of the explanatory variable. For instance, in the graph above, for ages younger than 10, the height values are systematically below the straight-line function.\n\n\nThere are several modeling techniques for constructing models that are more flexible than a straight line. We won’t be using them in Math 300, but we want to point out that they exist. Try this one:\n\nmod2 <- lm(Height ~ splines::ns(Age,5) * Gender, data = NHANES::NHANES)\nmodel_plot(mod2, data_alpha=0.05)\n\nWarning: Ignoring unknown aesthetics: fill\n\n\nWarning: Removed 353 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nCalculate R2 for the straight-line model and for the curvy model.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nmod1 |> R2()\n\n     n k  Rsquared        F     adjR2 p df.num df.denom\n1 9647 1 0.2117647 2591.193 0.2116829 0      1     9645\n\nmod2 |> R2()\n\n     n  k  Rsquared        F    adjR2 p df.num df.denom\n1 9647 11 0.8720171 5968.044 0.871871 0     11     9635\n\n\nThe R2 for the rigid, straight-line model is substantially lower than for the more flexible, curvy model. Another way of saying this is that the curvy model stays closer (on average) to the data than the straight-line model.\nAn important theoretical question in statistical modeling is when to prefer a curvy model to a straight-line model. We haven’t yet encountered the statistical concepts that address this question."
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "",
    "text": "We think about data with multiple variables as depicting a system: an interconnected network of components. Some components appear as variables in the data frame; other components may be unmeasured but given a name for reference.\nUse “directed acyclic graphs” (DAGs) to draw a picture of the system. Each system component is a node of the DAG. When one component has a causal connection with another, an arrow is drawn between those nodes.\nBy analysis of the DAG—using techniques we haven’t covered yet—you can figure out which variables to include in your model.\nMany DAGs are provided with the {math300} package, with names like dag01 through dag12. Here’s an example:\n\n\nprint(dag03)\n\ng ~ exo()\nx ~ 1 * g + exo()\ny ~ 1 * g + exo()\n\ndag_draw(dag03)\n\n\n\n\nNotice that there is no direct flow between nodes x and y. Still, there is an indirect connection: node g influences both x and y.\n\nWe can collect a sample from a DAG, for instance:\n\n\nMy_data <- sample(dag03, size=10000)\nMy_data |> head(3)\n\n\n\n \n  \n    g \n    x \n    y \n  \n \n\n  \n    0.0029971 \n    1.5327673 \n    0.0231254 \n  \n  \n    -0.1386110 \n    -0.4274596 \n    3.5090740 \n  \n  \n    -0.1543428 \n    1.0009144 \n    0.3116392 \n  \n\n\n\n\n\nDepending on the structure of the DAG, different model specifications will reveal different aspects of the DAG. For instance,\n\n\nmod1 <- lm(y ~ x, data=My_data)\nmod1 |> conf_interval()\n\n\n\n \n  \n    term \n    .lwr \n    .coef \n    .upr \n  \n \n\n  \n    (Intercept) \n    -0.0431319 \n    -0.0194309 \n    0.0042701 \n  \n  \n    x \n    0.4715121 \n    0.4883234 \n    0.5051348 \n  \n\n\n\n\nwill show if there is any kind of connection between x and y. But another specification will, in this case, show that the connection from x to y is via the connection provided by node g.\n\nmod2 <- lm(y ~ x + g, data=My_data)\nmod2 |> conf_interval()\n\n\n\n \n  \n    term \n    .lwr \n    .coef \n    .upr \n  \n \n\n  \n    (Intercept) \n    -0.0386313 \n    -0.0193601 \n    -0.0000888 \n  \n  \n    x \n    -0.0257069 \n    -0.0064618 \n    0.0127834 \n  \n  \n    g \n    0.9838257 \n    1.0115210 \n    1.0392163 \n  \n\n\n\n\nWe can look at the coefficients to see that in mod1 there is a non-zero connection between y and x, but in mod2 there is no non-zero connection of x on y.\n\nmod1 |> conf_interval()\n\n\n\n \n  \n    term \n    .lwr \n    .coef \n    .upr \n  \n \n\n  \n    (Intercept) \n    -0.0431 \n    -0.0194 \n    0.00427 \n  \n  \n    x \n    0.4720 \n    0.4880 \n    0.50500 \n  \n\n\n\nmod2 |> conf_interval()\n\n\n\n \n  \n    term \n    .lwr \n    .coef \n    .upr \n  \n \n\n  \n    (Intercept) \n    -0.0386 \n    -0.01940 \n    -8.88e-05 \n  \n  \n    x \n    -0.0257 \n    -0.00646 \n    1.28e-02 \n  \n  \n    g \n    0.9840 \n    1.01000 \n    1.04e+00 \n  \n\n\n\n\nOne way we will use DAGs to help us learn statistics is to compare the coefficients of models to the (known) mechanism of the DAG. We can see, for instance, that the g coefficient on y is 1 and the x coefficient is zero. Only mod2 reveals this.\n\nThe sampling and analysis in points (4) and (5) are an example of a “random trial” or “simulation.” We will use random trials to look at the properties of models fit to samples, especially with an eye to understanding the role of the sample size \\(n\\)."
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html#mathematical-functions-through-data",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html#mathematical-functions-through-data",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "Mathematical functions through data",
    "text": "Mathematical functions through data\nLet’s collect a small (\\(n=10\\)) sample from dag01:\n\nset.seed(103)\nSmall <- sample(dag01, size=10)\nhead(Small, 3)\n\n\n\n \n  \n    x \n    y \n  \n \n\n  \n    -0.7860 \n    1.89 \n  \n  \n    0.0547 \n    4.12 \n  \n  \n    -1.1700 \n    2.36 \n  \n\n\n\n\nWe can easily plot the data points. Less obviously, we can find any number of mathematical functions that are consistent with the data.\n\n\n\n\n\nFigure 1: Three of the infinite number of functions that can be drawn through the data ?@tbl-small-dag01.\n\n\n\n\n\nWhat don’t you like about these functions? Why do they insult your intuition?\n\nThey show details that are in no way suggested by the data.\nIf we were to collect more data, the function shapes could be entirely different. (Go back and change the random seed used for sampling from dag01.)"
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html#close-but-not-on-the-data",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html#close-but-not-on-the-data",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "“Close” but not “on” the data",
    "text": "“Close” but not “on” the data\nIn general, we don’t insist that model functions go exactly through the data points. Instead, we imagine that the response variable involves some random noise that we don’t need to “capture” with our model. Doing things this way lets us fit model functions that are much simpler in shape, like this one:\n\n\n\n\n\nFigure 2: The straight-line function (blue) that goes through the data points as closely as possible. The noise is estimated as the difference (red for negative noise, black for positive noise) between the actual data points and the function.\n\n\n\n\nConstructing such a model divides the “explanation” of the response variable values into two parts:\n\nModel values, that is, the output of the model function (blue) at each of the values of the explanatory variable(s).\nWhat’s left over, the residuals, the vertical deviation of the actual response value from the model value.\n\nThe signal is the model values. The noise is the residuals.\nWhen we “fit” (or, “train”) a model, we take an aggressive stance. We look for the particular function of the shape implied by the model specification that will produce the smallest residuals. As usual, we measure the size of a residual by its square."
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html#measuring-signal-and-noise",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html#measuring-signal-and-noise",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "Measuring signal and noise",
    "text": "Measuring signal and noise\nWe depict the “size” of the signal as the amount of variability in the model values. As always, we measure variability using the variance.\nSimilarly, the “size” of the noise is the amount of variability in the residuals.\nThe model_eval() function is convenient for figuring out the model value and the residual for each row in the training data.\n\n\nThe training data\n\nSmall\n\n\n\n \n  \n    x \n    y \n  \n \n\n  \n    -0.790 \n    1.90 \n  \n  \n    0.055 \n    4.10 \n  \n  \n    -1.200 \n    2.40 \n  \n  \n    -0.170 \n    6.30 \n  \n  \n    -1.900 \n    0.93 \n  \n  \n    -0.120 \n    2.90 \n  \n  \n    0.830 \n    5.70 \n  \n  \n    1.200 \n    5.90 \n  \n  \n    -1.100 \n    2.10 \n  \n  \n    -0.380 \n    4.20 \n  \n\n\n\n\n\n\n\n\n\nOutput of model_eval()\n\nPts <- model_eval(mod)\n\n\n\n\n\n \n  \n    .response \n    x \n    .output \n    .resid \n    .lwr \n    .upr \n  \n \n\n  \n    1.90 \n    -0.790 \n    2.9 \n    -1.0000 \n    0.37 \n    5.4 \n  \n  \n    4.10 \n    0.055 \n    4.4 \n    -0.2400 \n    1.80 \n    6.9 \n  \n  \n    2.40 \n    -1.200 \n    2.2 \n    0.1400 \n    -0.38 \n    4.8 \n  \n  \n    6.30 \n    -0.170 \n    4.0 \n    2.4000 \n    1.50 \n    6.5 \n  \n  \n    0.93 \n    -1.900 \n    1.0 \n    -0.0810 \n    -1.80 \n    3.8 \n  \n  \n    2.90 \n    -0.120 \n    4.1 \n    -1.1000 \n    1.50 \n    6.6 \n  \n  \n    5.70 \n    0.830 \n    5.7 \n    -0.0033 \n    3.00 \n    8.4 \n  \n  \n    5.90 \n    1.200 \n    6.3 \n    -0.4400 \n    3.50 \n    9.2 \n  \n  \n    2.10 \n    -1.100 \n    2.4 \n    -0.2300 \n    -0.22 \n    4.9 \n  \n  \n    4.20 \n    -0.380 \n    3.6 \n    0.6200 \n    1.10 \n    6.1 \n  \n\n\n\n\n\n\nHow big is …\n\nThe response variable.\nThe signal.\nThe noise.\n\n\nPts |> summarize(i. = var(.response),\n                 ii. = var(.output),\n                 iii. = var(.resid)) \n\n\n\n \n  \n    i. \n    ii. \n    iii. \n  \n \n\n  \n    3.55 \n    2.6 \n    0.949 \n  \n\n\n\n\n\n\n\n\n\n\nSomething special about the variance\n\n\n\nFor every lm() model you build, the variance of the response variable is exactly equal to the sum of the variance of the model values and the variance of the residuals.\nIn other words, lm() splits the response variable into two parts: the sum of those parts equals the whole.\nR2 is the variance of the model values divided by the variance of the response variable.\n\nmod |> R2()\n\n\n\n \n  \n    n \n    k \n    Rsquared \n    F \n    adjR2 \n    p \n    df.num \n    df.denom \n  \n \n\n  \n    10 \n    1 \n    0.733 \n    21.9 \n    0.699 \n    0.000863 \n    1 \n    8 \n  \n\n\n\nPts |> \n  summarize(i. = var(.response),\n            ii. = var(.output)) |>\n  mutate(R2 = ii. / i. )\n\n\n\n \n  \n    i. \n    ii. \n    R2 \n  \n \n\n  \n    3.55 \n    2.6 \n    0.733"
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html#activity-identifying-signal",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html#activity-identifying-signal",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "Activity: Identifying signal",
    "text": "Activity: Identifying signal"
  },
  {
    "objectID": "Day-by-day/Lesson-21/Teaching-notes-21.html#five-six-simple-models",
    "href": "Day-by-day/Lesson-21/Teaching-notes-21.html#five-six-simple-models",
    "title": "Instructor Teaching Notes for Lesson 21",
    "section": "Five Six simple models",
    "text": "Five Six simple models\nModels can have any number of explanatory variables. In Math 300, we will be mainly concerned with models with a single explanatory variable or with two explanatory variable. Since an explanatory variable can be either categorical or quantitative, there are six “shapes” of models:\nSingle explanatory variable\n\nCategorical explanatory variable.\nQuantitative explanatory variable.\n\nTwo explanatory variables\n\nCategorical & Categorical\nCategorical & Quantitative\nQuantitative & Quantitative\n\nSometimes, we will use models with Zero explanatory variables\n\nNo explanatory variables.\n\nGraphs of (i) through (v), with (iv) shown in two different modes."
  },
  {
    "objectID": "Day-by-day/Lesson-22/counts-and-waiting-times.html",
    "href": "Day-by-day/Lesson-22/counts-and-waiting-times.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "Measurements are a combination of signal and noise. This activity aims to help understand how much data is needed to reduce the noise to an acceptable level.\n\n\nOften, measurements are made of how many random events of a particular type happen in a fixed interval of time or a given area of space. Examples:\n\nHow many inches of snow fall per year in a given location?\nHow many traffic accidents happen per year at a particular intersection?\n\nMaking such measurements can be straightforward. The challenge comes in interpreting them. For instance, how different do the measurements of snowfall in two different areas need to be to support a claim that one area is snowier than the other? Similarly, how many years of observation are required to know if one intersection is more dangerous than another?\nCommon sense tells us that one region can be snowier than another or that one intersection can be more dangerous than another. Yet the individual events—a snow storm of a given magnitude or a pedestrian hit by an automobile—are random. That is, there is both signal and noise in the measurements.\nThis activity is about how much data we should collect in order to reduce the noise sufficiently that signals can be read clearly.\n\n\n\n\nEach of the people in your group will create his or her own signal, that is, a single number specifying the rate at which events happen.\n\n\nDo not look at your signal until directed to.\nGenerate your signal with this command:\n\n\nsignal <- 50*(5 + runif(1)) # Don't peek\n\nOnce all of your group members have their own signal, you are going to start to generate noisy data. The idea is to compare the observations you make to those from the other group members to decide the extent to which the signals differ from one another.\n\nGenerate a single (\\(n=1\\)) measurement this way:\n\n\nrpois(n=1, lambda=signal)\n\nCompare your measurement to those of each of the other members of the group. For each of those members, decide among these choices, making sure not to look at the numerical value of signal.\n\nMy signal is certainly higher.\nMy signal is likely to be higher.\nCan’t tell whether my signal is different than the other person’s.\nMy signal is likely to be lower.\nMy signal is certainly lower.\n\nRecord your conclusion for each of your group partners.\n\nRepeat the process in (2), but generate \\(n=2\\) observations. You will have two numbers, which you will compare to the other person’s two numbers. You’ll have to decide how you want to do this.\n\nMake a note of the method you choose do the comparison and record your conclusion (i)-(v) for each of your group partners.\n\nRepeat (3), but this time with \\(n=4\\).\n\nAre you still happy with the method you chose in (3)? If not, figure out a new method that can handle the comparison of 4 numbers to another set of 4 numbers.\nOnce again, record your conclusion (i)-(v) of your data against each of your group partners.\n\nRepeat the following for each of your partners separately. Try higher values of \\(n\\) until the two of you agree that your signals are certainly different.\n\n\n\n\nStarting in June 1944, the Germans engaged in missile attacks against London. At first, the V-1 cruise missile was used. Later, the V-2 ballistic missile was added to the attack.\nThe London City Council kept records of V-1 impact sites within their jurisdiction. Figure 1 shows the locations.\n\n\n\n\n\nFigure 1: Map showing impact sites of V-1 missiles in the area administered by the London City Council. The Thames river is shown in blue. The map does not show impacts outside the LCC region.\n\n\n\n\nAn analysis published in 1946 looked at 537 V-1 impacts within the area outlined in red: a region of 144 km2. The area was divided into 576 boxes each of area 0.25 km2. Five-hundred thirty-seven V-1 impacts fell within the rectangle; suggesting that there might be about 1 impact per box.\nTo be more precise, the signal is 537 / 576 = 0.93 impact per box.\nThere is a mathematical theory of how the measured number of impacts will vary from one box to another. The theory is called the Poisson distribution. In the activity, when you used rpois(n=1, lambda=signal) the computer was using this theory to generate the measurement, that is, signal plus noise.\nThese are the results of comparing the theory to the actual observations of how many boxes had no impact, 1 impact, 2 impacts, and so on.\n\n\n\n\n\nFigure 2: The number of boxes (out of 576, total) with different numbers of impacts. The Poisson theory result is in the middle column. (Copied from the 1946 analysis paper.\n\n\n\n\nThis article gives a more detailed account."
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#motivating-problem-1-dags",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#motivating-problem-1-dags",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Motivating problem 1: DAGs",
    "text": "Motivating problem 1: DAGs\nYou propose a DAG to describe a specific situation and want to see how well it matches the available data.\nCommon sense suggests that two variables y and x may not have any causal connection between them.\nIn such a case, we anticipate that the model y ~ x + ... will have a coefficient of zero on x. (The + ... stands for other possible explanatory variables, which we call “covariates.”)\nThis lesson is about two closely related things:\n\nWhen is a coefficient small enough that we can regard it as zero?\nWhen we have a coefficient generated by fitting a model to data, how do we describe how precisely we know it?"
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#motivating-problem-2-sustainable-fisheries",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#motivating-problem-2-sustainable-fisheries",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Motivating problem 2: Sustainable fisheries",
    "text": "Motivating problem 2: Sustainable fisheries\nDesigning an enforcement regime for limits on scallop fisheries.\n\n\n\n\n\nFigure 1: Life cycle of a scallop\n\n\n\n\nFisheries are regulated by states and the Federal government in order to avoid collapse due to over-fishing. Often, the regulations attempt to protect juveniles—animals that have not yet reached reproductive age. If the juveniles are harvested, their potential progeny are annihilated. There are various ways to do this, for instance restricting fishing to months where adults are most prevalent, closing fisheries to provide an opportunity for the reproductive stock to recover, and so on.\nIn the 1990s, one of the ways the Federal government regulated scallop fisheries was by setting a minimum acceptable size for harvested scallops. For practical reasons, rather than monitoring individual scallops, the government monitored the average per-scallop weight of each boat’s catch. For the sake of the example, imagine that the minimum acceptable weight is 1/30 pound.\nA fishing boat might have 10,000 or more bags of scallops, which can be handled individually: weigh the bag, then count the number of scallops to get the average weight per scallop.\nDiscussion questions:\n\nHow many bags should be sampled? Should this depend on the number of bags in the cargo. For instance, should a cargo of 1000 bags be sampled differently than a cargo of 10,000 bags.\nWhat should be the threshold for declaring the whole cargo below minimum size? (The whole catch is confiscated in such a case.)\n\nIn this section of the course, you’ll learn some statistical concepts and methods that allow the above questions to be answered to produce a regulation that is protective and fair to the fishermen.\nOne idea is very simple: sampling variation. This is about how much the average per-scallop weight will vary from one bag to another.\nAnother idea is very subtle: What you can say about the whole cargo based on a sample of \\(n\\) bags."
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#vocabulary-sample-vs-sampling",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#vocabulary-sample-vs-sampling",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Vocabulary: “Sample” vs “sampling”",
    "text": "Vocabulary: “Sample” vs “sampling”\nThe vocabulary here can be confusing, because similar sounding terms refer to different things.\nA sample is a collection, just as a data frame is a collection of rows. The individual items in the collection—the individual rows—are “specimens,” or “cases,” or “rows,” or “units of observation,” or “observations,” or even “tuples.”\n“Sampling” is the process of collecting a sample.\nStatisticians use the phrase “sample statistic” to refer to a summary calculated from a sample. For instance, if your summary is the variance of a variable, this could properly be called the “sample variance.”\nThe terms “sampling variation” and “sampling variance.” “Sampling variation” is a theoretical concept: how much a model coefficient or other sample statistic would vary from one randomly collected sample to another. Our measurement of sampling variance is often accomplished with our usual tool for measuring variation: the variance.\nYou can’t directly see sampling variation in a single sample; however, we can use the theory of sampling variation to estimate from a single sample how much other samples might differ from the sample at hand. In this Lesson, we will simulate sampling variation in order to understand its properties, particularly how it depends on the sample size \\(n\\).\nTechnical vocabulary:\n\n“Confidence interval” (or “CI”) a range indicating the sampling variation of a sample statistic. Example: [19.1, 21.5]. Every model coefficient comes with a confidence interval. The conf_interval() model summary calculates the CI. Example:\n\n\nlm(mpg ~ hp, data=mtcars) |> conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) 26.8    30.1    33.4   \n2 hp          -0.0889 -0.0682 -0.0476\n\n\n\n“Standard error”: the square-root of the “sampling variance.” It might make more sense to use “sampling standard deviation” for the square root of the “sampling variance.”\n\n“Margin of error” is the plus-or-minus part \\(20.3 \\pm 1.2\\) of another format for writing the CI.\n“Confidence level” is a number between 0 and 1. Almost always this is set to be 95%, which is what we will use. It is used to calculate the margin of error, which is a multiple of the standard error. For 95%, the multiplier is about 2. (If you took AP statistics, you may remember the number 1.96, which is their way of saying “two.”)"
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#class-activity",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#class-activity",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Class Activity",
    "text": "Class Activity\nPoisson data"
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#digression",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#digression",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Digression",
    "text": "Digression\nIs process of fitting like the process of learning in animals? Here’s a report from The Economist:\n\nNever before … has the whole brain of such a complex organism—spanning some 548,000 connections between 3,016 neurons in the case of the fruit-fly larva—been mapped.\n\n\nThe latest work, published in Science, marks the culmination of over a decade’s worth of effort ….\n\n\nThe connectome of the fruit-fly larva has already provided insights. For example, regions of the creature’s brain associated with learning had more loops in their circuitry, with downstream neurons connecting back to those close behind them, than other regions of the brain. This suggested some repeat processing of signals. One proposed explanation is that such loops encode predictions, and that the creatures learn by comparing these with actual experiences.\n\n\nInformation about the taste of a leaf, for example, might enter a neuron simultaneously with a prediction based on previous meals. If the taste differs from prediction, the neuron may secrete dopamine, a chemical capable of rewiring the circuitry to create a new memory."
  },
  {
    "objectID": "Worksheets/Worksheet-22.html",
    "href": "Worksheets/Worksheet-22.html",
    "title": "Lesson 22: Worksheet",
    "section": "",
    "text": "22.1 Describe the logical origin of sampling variation as the variation between multiple samples from the same source.\n22.2 Recognize the several formats in which we describe sampling variation—sampling variance, standard error, margin of error, confidence interval—and show how they are related.\n22.3 Using repeated sampling trials, observe how sampling variance scales with sample size \\(n\\)."
  },
  {
    "objectID": "Worksheets/Worksheet-22.html#overview",
    "href": "Worksheets/Worksheet-22.html#overview",
    "title": "Lesson 22: Worksheet",
    "section": "Overview",
    "text": "Overview\nIt is critical to keep in mind that a sample is a collection, just as a data frame is a collection of rows. The variation we account for by regression models is row-by-row variation in the training data frame.\n“Sampling variation” is a theoretical concept: how much a model coefficient or other sample statistic would vary from one randomly collected sample to another.\nYou can’t directly see sampling variation in a single sample; however, we can use the theory of sampling variation to estimate from a single sample how much other samples might differ from the sample at hand. In this Lesson, we will simulate sampling variation in order to understand its properties, particularly how it depends on the sample size \\(n\\)."
  },
  {
    "objectID": "Worksheets/Worksheet-22.html#part-1",
    "href": "Worksheets/Worksheet-22.html#part-1",
    "title": "Lesson 22: Worksheet",
    "section": "Part 1",
    "text": "Part 1\nUsing dag02, obtain a sample of size 25 and show the values of y.\n\ndag02sample = sample(dag02, size=25)\n\ndag02sample%>%\n  select(y)\n\n# A tibble: 25 × 1\n         y\n     <dbl>\n 1  6.06  \n 2  3.71  \n 3  3.01  \n 4  1.28  \n 5  0.440 \n 6 11.0   \n 7  7.24  \n 8  6.74  \n 9  7.81  \n10 -0.0512\n# … with 15 more rows\n\n\nCompute the mean those 25 values of y in two different, but entirely equivalent ways. (1) Use data wrangling. (2) Construct a model y ~ 1 report the intercept coefficient. Show that these give the same answer.\n\n\n\n\n\n\nANSWER\n\n\n\n\ndag02sample%>%\n  summarize(mean(y))\n\n# A tibble: 1 × 1\n  `mean(y)`\n      <dbl>\n1      4.76\n\ndag02sample %>% \n  lm(y~1,data=.)%>%\n  conf_interval()\n\n# A tibble: 1 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept)  3.32  4.76  6.20"
  },
  {
    "objectID": "Worksheets/Worksheet-22.html#part-2",
    "href": "Worksheets/Worksheet-22.html#part-2",
    "title": "Lesson 22: Worksheet",
    "section": "Part 2",
    "text": "Part 2\nCreate a new chunk that repeats the generation of a sample from dag02 the the two methods for calculating the mean of the y values. Run the new chunk and observe that the calculated value of the mean differs somewhat from that you found in Part 1. Repeat running the chunk over and over again; the mean value will differ each time.\nTask 2.1. Each time you run the chunk, you are performing a new sampling trial. Run a dozen or so trials, observing the calculated value of the mean of y in order to get a sense for how much it varies from trial to trial. Then summarizing your observations by giving a rough interval for the range of the mean of y across the trials.\n\n\n\n\n\n\nANSWER\n\n\n\n\n\n\nWe are going to automate the process of performing sampling trials so that we can run hundreds of them.\nUsing the do operator, calculate the sampling variance for a set of trials from dag02. The following code chunk shows how to run 500 trials, in each of which the mean of y is calculated using the y ~ 1 method and reporting the intercept coefficient. These will be collected into a data frame named dag02trials25.\n\ndag02trials25 <- do(500) * {\n  sample(dag02, size=25) |> \n  lm(y ~ 1, data=_) |>\n  conf_interval()\n}\n\nTask 2.2. Run the chunk above to create dag02trials25. Then use data wrangling commands to compute three summaries of the trials: i. The mean of the coefficient across the trials. ii. The variance of the coefficient across the trials. iii. The standard deviation of the coefficient across the trials.\n\n\n\n\n\n\nANSWER\n\n\n\nThe coefficient for each of the 500 trials is stored in the .coef column of dag02trials25. Simple data wrangling provides the summary.\n\ndag02trials25%>%\n  summarize(mean_of_means = mean(.coef),\n            sampling_variance = var(.coef),\n            standard_error = sd(.coef))\n\n# A tibble: 1 × 3\n  mean_of_means sampling_variance standard_error\n          <dbl>             <dbl>          <dbl>\n1          5.01             0.443          0.665\n\n\nNotice that the names—sampling_variance and standard_error—we used for the different summaries correspond to the standard statistical nomenclature for these quantities.\n\n\nTask 2.3. Repeat (2) with four different sample sizes (try 50, 100, 200, and 400). Fill in the table below. What do you notice about the standard error as sample size increases?\n\n\n\nSample size\nSampling variance\nStandard error\n\n\n\n\nn=25\n0.439\n0.663\n\n\nn=50\n0.253\n0.503\n\n\nn=100\n0.129\n0.359\n\n\nn=200\n0.059\n0.243\n\n\nn=400\n0.032\n0.178\n\n\n\n\n\n\n\n\n\nANSWER\n\n\n\nThe sampling variance gets smaller as the sample size increases. Specifically, doubling the sample size tends to halve the sampling variance. The standard error—which is just the square-root of the sampling variance—also gets smaller as \\(n\\) increases. As in the nature of square roots, to halve the standard error, the sample size must be doubled twice."
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#essential-take-home-points",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#essential-take-home-points",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Essential take-home points",
    "text": "Essential take-home points\n\nThe sampling variance depends on the sample size. Larger n leads to smaller sampling variance. The dependence is simple: sampling variance goes as \\(1/n\\).\nThe width of the confidence interval depends on the square-root of the sampling variance. Consequently, the width of the confidence interval goes as \\(1/\\sqrt{n}\\).\n\nStated more simply: Under normal conditions, more data means shorter confidence intervals."
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#work-though-worksheet-22",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#work-though-worksheet-22",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Work though worksheet 22",
    "text": "Work though worksheet 22\nThis is a simulation demonstration of the essential take-home points listed above. In Lesson 23 we’ll see how it’s possible to do the calculations in real data."
  },
  {
    "objectID": "Day-by-day/Lesson-22/Teaching-notes-22.html#confidence-level",
    "href": "Day-by-day/Lesson-22/Teaching-notes-22.html#confidence-level",
    "title": "Instructor teaching notes: Lesson 22",
    "section": "Confidence level",
    "text": "Confidence level\nNot a big deal in our course. Use 0.95, which is the default for conf_interval().\nA lower confidence level produces a shorter CI, a higher confidence level produces a longer CI.\n\nlm(mpg ~ hp, data=mtcars) |> conf_interval(level=0.80) |> filter(term==\"hp\")\n\n# A tibble: 1 × 4\n  term     .lwr   .coef    .upr\n  <chr>   <dbl>   <dbl>   <dbl>\n1 hp    -0.0815 -0.0682 -0.0550\n\nlm(mpg ~ hp, data=mtcars) |> conf_interval(level=0.90) |> filter(term==\"hp\")\n\n# A tibble: 1 × 4\n  term     .lwr   .coef    .upr\n  <chr>   <dbl>   <dbl>   <dbl>\n1 hp    -0.0854 -0.0682 -0.0511\n\nlm(mpg ~ hp, data=mtcars) |> conf_interval(level=1.00) |> filter(term==\"hp\")\n\n# A tibble: 1 × 4\n  term   .lwr   .coef  .upr\n  <chr> <dbl>   <dbl> <dbl>\n1 hp     -Inf -0.0682   Inf"
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "",
    "text": "Basic procedure in statistical interpretation of data: collect data then calculate one or more sample statistics from those data. Example: Galton’s data on heights and an analysis of whether a child’s height is related to the parents’.\n\n\nlm(height ~ mother + father + sex, data=Galton) |> coefficients()\n\n(Intercept)      mother      father        sexM \n 15.3447600   0.3214951   0.4059780   5.2259513 \n\n\nQuestion: Are fathers more influential on the children’s height than mothers?\n\nBut statisticians don’t regard the sample statistics in (1) as completely informative because we know, in our hearts, that the particular sample we worked with is just one of many, many samples that we might have collected. Each of those hypothetical samples has its own sample statistic, which likely differs from the sample statistic we calculated in (1). This is what we mean by sampling variability.\nWe can say that sampling variability implies that our sample statistics are noisy, that they are not absolutely precise.\nWe describe the precision of a sample statistic via a confidence interval, which can be in either of two forms, e.g.:\n\n\\([56.3, 57.1]\\) or \\(56.7 \\pm 0.4\\)"
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html#lesson-23",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html#lesson-23",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "Lesson 23",
    "text": "Lesson 23\nThere are mathematical techniques that allow us to get a handle on the precision of a sample statistic using just the sample at hand. Here is the central mathematical fact:\n\nWidth of confidence interval is proportional to \\(1/\\sqrt{n}\\).\n\nLet’s demonstrate this using simulations (via DAGs).\n\nsample(dag06, size=400) |> \n  lm(d ~ c + a, data=_) |>\n  conf_interval() |>\n  mutate(width = .upr - .lwr) \n\n# A tibble: 3 × 5\n  term          .lwr   .coef   .upr width\n  <chr>        <dbl>   <dbl>  <dbl> <dbl>\n1 (Intercept) -0.119 -0.0144 0.0902 0.209\n2 c            0.916  0.987  1.06   0.142\n3 a            0.836  0.969  1.10   0.267\n\n\nHere, the width of each term is subject, like everything else, to sampling variation.\nWe can average over many trials to reduce the sampling variation.\n\n{do(500) * {\n  sample(dag06, size=100) |> \n  lm(d ~ c + a, data=_) |>\n  conf_interval() |>\n  mutate(width = .upr - .lwr)} \n  } |>\n  group_by(term) %>% \n  summarize(ave_width = mean(width))\n\n# A tibble: 3 × 2\n  term        ave_width\n  <chr>           <dbl>\n1 (Intercept)     0.401\n2 a               0.495\n3 c               0.285\n\n\nTry this for different sample sizes: 25, 100, 400.\n\nWhat will be the width of the confidence interval when the sample size is 1600?"
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html#how-to-find-the-confidence-interval-when-we-have-only-one-sample",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html#how-to-find-the-confidence-interval-when-we-have-only-one-sample",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "How to find the confidence interval when we have only one sample",
    "text": "How to find the confidence interval when we have only one sample\n\nConstruct many trials of subsamples, say 1/50th the size of the data.\n\n\nlm(height ~ mother + father + sex, data=sample(Galton, size=18)) |>\n  conf_interval() |>\n  select(term, .coef)\n\n# A tibble: 4 × 2\n  term         .coef\n  <chr>        <dbl>\n1 (Intercept) 36.3  \n2 mother       0.216\n3 father       0.193\n4 sexM         6.21 \n\n\n\n{do(500) * {\n  lm(height ~ mother + father + sex, data=sample(Galton, size=18)) |>\n  conf_interval() |>\n  select(term, .coef)\n}} |> \n  group_by(term) |>\n  summarize(var_coef = var(.coef))\n\n# A tibble: 4 × 2\n  term        var_coef\n  <chr>          <dbl>\n1 (Intercept) 560.    \n2 father        0.0644\n3 mother        0.0684\n4 sexM          1.19  \n\n\nWe can look at any of the coefficients. Let’s use sexM for the example.\nThe sampling variance of the sexM coefficient for a sample of size \\(n=18\\) is 1.14 inches2.\n\nThe “standard error” corresponding to this is \\(\\sqrt{1.14} = 1.07\\) inches.\nThe width of the confidence interval for a sample of size 18 will be four times the standard error—that’s part of the definition of the confidence interval, that is 4.28.\nFour the whole sample, \\(n=898\\), the width of the confidence interval will be \\(4.28 \\times \\sqrt{\\frac{18}{898}} = 0.606\\).\n\nCheck this against the calculation:\n\nlm(height ~ mother + father + sex, data=Galton) |>\n  conf_interval() %>%\n  mutate(width=.upr - .lwr)\n\n# A tibble: 4 × 5\n  term         .lwr  .coef   .upr  width\n  <chr>       <dbl>  <dbl>  <dbl>  <dbl>\n1 (Intercept) 9.95  15.3   20.7   10.8  \n2 mother      0.260  0.321  0.383  0.123\n3 father      0.349  0.406  0.463  0.115\n4 sexM        4.94   5.23   5.51   0.565\n\n\n\nWhat does this report tell you about whether fathers contribute more to children’s height than mothers? Compare the confidence interval on mother and father."
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html#activity",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html#activity",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "Activity",
    "text": "Activity\nGot you covered"
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html#precision-versus-accuracy",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html#precision-versus-accuracy",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "Precision versus accuracy",
    "text": "Precision versus accuracy\nIn the case of our model y ~ x + a on data simulated from dag02 we can compare the model coefficients to the formula for y in the DAG.\n\ndag_draw(dag06)\n\n\n\nprint(dag06)\n\na ~ exo()\nb ~ a + exo()\nc ~ b + exo()\nd ~ c + a + exo()\n\nsample(dag06, size=25) |> \n  lm(d ~ c + a, data=_) |>\n  conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.748 -0.327 0.0930\n2 c            0.677  0.981 1.28  \n3 a            0.673  1.28  1.88  \n\n\nThe coefficients are a close match to the DAG formula.\nIf I repeat this simulation many times, roughly one time in twenty the actual formula coefficient will be outside the confidence interval. (Do the trials.)\nMake the sample size very large so that we get a very narrow confidence interval to demonstrate the accuracy.\n\nFrom the above, predict what sample size is needed to get a confidence interval that is about 0.01 wide. (The CI on x for example, is has width about 1. To get 0.01 we need 1002 as much data.)\n\n\nsample(dag06, size=250000) |> \n  lm(d ~ c + a, data=_) |>\n  conf_interval()\n\n# A tibble: 3 × 4\n  term            .lwr     .coef    .upr\n  <chr>          <dbl>     <dbl>   <dbl>\n1 (Intercept) -0.00493 -0.000993 0.00295\n2 c            0.996    0.999    1.00   \n3 a            0.995    1.00     1.00   \n\n\nMore data buys better precision. But accuracy is a different matter altogether. The above model is both precise and accurate.\nHere is a model that is very precise, but not at all accurate:\n\nsample(dag06, size=250000) |> \n  lm(d ~ c, data=_) |>\n  conf_interval()\n\n# A tibble: 2 × 4\n  term            .lwr    .coef    .upr\n  <chr>          <dbl>    <dbl>   <dbl>\n1 (Intercept) -0.00454 0.000515 0.00557\n2 c            1.33    1.33     1.33   \n\n\n\nWhat is it that tells you the precision of the coefficients?\n\n\nWhat is it that tells you the coefficient on c is not accurate?"
  },
  {
    "objectID": "Day-by-day/Lesson-23/Teaching-notes-23.html#going-further",
    "href": "Day-by-day/Lesson-23/Teaching-notes-23.html#going-further",
    "title": "Instructor Teaching Notes for Lesson 23",
    "section": "Going further",
    "text": "Going further\nStatistics texts tend to feature simple models without covariates.\nObviously, the choice of covariates or other model terms is not an issue. Sample statistics are designed mathematically so that they are accurate. This is called being unbiased.\nBut in cases of actual interest, where we are interested in causal connections, we generally cannot know from our data whether the sample statistic is accurate.\nCollecting more data will not help us determine the accuracy; more data improves precision but not accuracy.\nLater, in Lesson 30, we can return to accuracy. There, we’ll look at accuracy with respect to a DAG, choosing covariates so that the model would be accurate if the data were indeed generated by a mechanism well represented by our DAG."
  },
  {
    "objectID": "Worksheets/Worksheet-23.html",
    "href": "Worksheets/Worksheet-23.html",
    "title": "Lesson 23: Worksheet",
    "section": "",
    "text": "You are going to work with data collected in the 1970s to examine the effects of smoking and exposure to second-hand smoke on pulmonary functions in youths. The data frame is FEV and is included in the {math300} package.\nThe response variable that we will study is also called FEV, standing for the “forced expiratory volume” measured in the participants in the study. In general, higher forced expiratory volume is considered a sign of better respiratory health."
  },
  {
    "objectID": "Worksheets/Worksheet-23.html#task-2",
    "href": "Worksheets/Worksheet-23.html#task-2",
    "title": "Lesson 23: Worksheet",
    "section": "Task 2",
    "text": "Task 2\n\nWhat is the width of the confidence interval on smokersmoker?\n\n\n\n\n\n\n\nANSWER\n\n\n\nYou can find the length of the confidence interval simply by subtracting the .lwr limit of the interval from the .upr limit. Here that’s 0.927 - 0.494 = 0.433.\n\n\n\nTask 3.\nJust for pedagogical purposes, we are going to explore how the width of the confidence interval would change if we had more or less data. You already have heard the theoretical relationship of the width of the confidence interval as a function of sample size \\(n\\).\n\nWhat is the size of the sample contained in FEV?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nnrow(FEV)\n\n[1] 654\n\n\n\n\n\nUsing the theoretical relationship with \\(n\\), what do you think the width of the confidence interval would be if only \\(n=150\\) rows of data were available?\n\n\n\n\n\n\n\nANSWER\n\n\n\n150 is about one-quarter the sample size of FEV. So a confidence interval calculated on a sample of \\(n=150\\) will be about \\(\\sqrt{4}\\) times larger. That is, the sample size 150 will lead to a confidence interval about twice as wide as the confidence interval from the full sample.\n\n\n\nWe can easily simulate working with a sample of \\(n=150\\). To do this, fit a model (and calculate the confidence interval on smokersmoker), but rather than using the argument data=FEV use this instead: data=sample(FEV, size=150). Compare the width of confidence interval you get in this way to your theoretical prediction in (2).\nThis will be surprising, but we can actually simulate what would happen if we had a larger sample size. (This is just a simulation, and just for pedagogical purposes. This is not a way to collect a genuine sample of a larger size.)\n\nTo create a (simulated) sample of size, say, \\(n=2500\\) set the data argument to lm() this way: data=resample(FEV, size=2500). (NOTE: The function being used here is not sample() but the closely related resample(), with an re in front.)\nCalculate the width of the (simulated) confidence interval on smokersmoker for the sample size of 2500.\n\n\n\n\n\n\nANSWER\n\n\n\n\nlm(FEV ~ smoker, data=resample(FEV, size=2500)) |> conf_interval()\n\n# A tibble: 2 × 4\n  term          .lwr .coef  .upr\n  <chr>        <dbl> <dbl> <dbl>\n1 (Intercept)  2.52  2.56  2.59 \n2 smokersmoker 0.586 0.692 0.798\n\n\nThe width of the confidence interval on `smokersmoker is about 0.20.\n\n\n\n\nTask 3\nWere you surprised to see in Task 1 that smoking is associated with a higher FEV than non-smoking? Since a higher FEV is considered healthier, does this mean that smoking is healthy? The answer is “no,” but let’s consider it from the perspective of accuracy versus precision.\nThe confidence interval on smokersmoker in the model FEV ~ smoker was 0.50 to 0.93 liters. This precision is good enough to rightfully claim that the smokersmoker coefficient is not zero or negative.\nBut precision is different from accuracy. One of the major potential determinants of FEV is age.\n\nBuild a model FEV ~ age and construct the confidence interval on age. Explain whether your model is consistent or not with the idea that FEV depends on age.\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nlm(FEV ~ age, data=FEV) |> conf_interval()\n\n# A tibble: 2 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept) 0.279 0.432 0.585\n2 age         0.207 0.222 0.237\n\n\nThe age coefficient is about 0.2 liters per year. In other words, FEV increases with age.\n\n\n\nIt also happens that smoking is associated with age. The younger kids don’t smoke. We can demonstrate this with a model of smoker ~ age. Since smoker is a categorical variable, we need to convert it to a zero-one variable before fitting the model. Here’s a chunk to do so, assigning the smokers to have a value of 1:\n\n\nFEV |> \n  mutate(smoke = zero_one(smoker, one=\"smoker\")) |>\n  lm(smoke ~ age, data = _) |>\n  conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) -0.381  -0.308  -0.234 \n2 age          0.0338  0.0410  0.0481\n\n\nInterpret the coefficient as a rate of probability: how the probability that a participant smokes changes per year of age.\n\nIs the age coefficient consistent with the idea that older kids are more likely to smoke?\nNow the point about accuracy and precision being different things. FEV increases with age and so does the probability of being a smoker. That means that smoker is also related to age. In fact, to some extent smoker is a proxy for age. As an exercise, draw on paper a DAG where age influences FEV, and age influences smoking status, and also smoking status influences FEV.\n\nFor the DAG just described, an accurate model to estimate the direct effect of smoking on FEV is FEV ~ age + smoker. Fit this model and use the confidence interval on smoker to make an accurate statement about smoking and FEV.\n\n\n\n\n\n\nANSWER\n\n\n\n\nlm(FEV ~ age + smoker, data = FEV) |>\n  conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr  .coef    .upr\n  <chr>         <dbl>  <dbl>   <dbl>\n1 (Intercept)   0.207  0.367  0.527 \n2 age           0.215  0.231  0.247 \n3 smokersmoker -0.368 -0.209 -0.0504\n\n\nThe confidence interval on smokersmoker is entirely negative. Negative means that smoking is associated with smaller FEV. This sort of thing would be summarized as, “After adjusting for age, smoking is associated with smaller FEV.”"
  },
  {
    "objectID": "Day-by-day/Lesson-24/Teaching-notes-24.html#why-so-much-interest-in-coefficients",
    "href": "Day-by-day/Lesson-24/Teaching-notes-24.html#why-so-much-interest-in-coefficients",
    "title": "Teaching notes, Lesson 24",
    "section": "Why so much interest in coefficients?",
    "text": "Why so much interest in coefficients?\n\nAn important statistical task (in some situations) is to detect whether there is some connection between an explanatory variable and the response variable. This often amounts to asking whether a coefficient is zero. More precisely, asking whether the confidence interval includes zero.\nMathematical tradition. There are other ways to present the same information. But people with a good head for mathematics find the coefficients easy to interpret … until the models become complicated.\nHere’s a way to plot out the Galton model:\n\n\ngmodel <- Galton |> \n  model_train(height ~ mother + father + sex)\nmodel_plot(gmodel)\n\n\n\n\n\nWe can also show sampling variability graphically, although the plots can be hard to interpret.\n\n\nmodel_plot(gmodel, interval=\"confidence\")\n\n\n\n\n\nAnother important type of statistical questions involves intervention: If we change the value of an input to the model, how much will the output change?\n\n\nmodel_eval(gmodel, mother=c(60,65), father=65, sex=\"F\")\n\n  mother father sex  .output     .lwr     .upr\n1     60     65   F 61.02304 56.77622 65.26986\n2     65     65   F 62.63052 58.38981 66.87122\n\n\nThis is called an “effect size.” From the above table, we can calculate the effect size with respect to mother."
  },
  {
    "objectID": "Day-by-day/Lesson-24/Teaching-notes-24.html#effect-size",
    "href": "Day-by-day/Lesson-24/Teaching-notes-24.html#effect-size",
    "title": "Teaching notes, Lesson 24",
    "section": "Effect size",
    "text": "Effect size\n\nAn effect size (for numerical variables) is a partial derivative of the model function.\nAn effect size (for categorical variables) is a partial difference.\nWhether a model’s effect size says what would happen in the real world if we changed a model input depends on whether we have captured causal connections properly with our model.\n\nWe can’t change the explanatory variables in a meaningful way in human height, but suppose the experiment were to make kindergarten class sizes smaller and look for the effect on later student achievement.\n\nCalculate an effect size: use model_eval() changing one variable at a time.\nCalculating confidence interval on effect size: Involves a lot of accounting, except in the simplest cases.\nUnits of effect size.\n\nQuantitative variable: [response]/[explanatory] a rate (a.k.a slope)\nCategorical variable: [response]"
  },
  {
    "objectID": "Day-by-day/Lesson-24/Teaching-notes-24.html#why-always-in-model-specifications",
    "href": "Day-by-day/Lesson-24/Teaching-notes-24.html#why-always-in-model-specifications",
    "title": "Teaching notes, Lesson 24",
    "section": "Why always + in model specifications",
    "text": "Why always + in model specifications\nThis is just for us, to make model interpretation easier.\nWith + models, the coefficient is always the same as the effect size.\nBut not generally. Examples with Galton data\n\nmod1 <- lm(height ~ mother*father*sex, data=Galton)\nmodel_plot(mod1)\n\nWarning: Ignoring unknown aesthetics: fill\n\n\n\n\n\nNotice that the lines aren’t parallel. We can also do curvy functions.\n\nlibrary(splines)\nmod2 <- lm(height ~ ns(mother,2)*ns(father,2)*sex, data=Galton)\nmodel_plot(mod2)\n\nWarning: Ignoring unknown aesthetics: fill\n\n\n\n\n\nMight the curviness or non-parallel nature of the lines just be a matter of sampling variation?\n\nmodel_plot(mod1, interval=\"confidence\")\n\n\n\nmodel_plot(mod2, interval=\"confidence\")\n\n\n\n\nAll the information for the confidence bands is contained in the coefficients (and residuals), but good luck figuring it out!\n\nmod2 |> conf_interval()\n\n# A tibble: 18 × 4\n   term                                  .lwr   .coef  .upr\n   <chr>                                <dbl>   <dbl> <dbl>\n 1 (Intercept)                         50.1    55.4   60.7 \n 2 ns(mother, 2)1                       1.01   10.7   20.5 \n 3 ns(mother, 2)2                     -13.0    -4.36   4.31\n 4 ns(father, 2)1                       4.97   15.4   25.9 \n 5 ns(father, 2)2                      -0.486   4.98  10.5 \n 6 sexM                                -1.19    6.00  13.2 \n 7 ns(mother, 2)1:ns(father, 2)1      -32.1   -12.8    6.55\n 8 ns(mother, 2)2:ns(father, 2)1       -1.03   15.1   31.3 \n 9 ns(mother, 2)1:ns(father, 2)2       -8.41    2.27  12.9 \n10 ns(mother, 2)2:ns(father, 2)2       -3.90    4.43  12.8 \n11 ns(mother, 2)1:sexM                -17.3    -3.92   9.43\n12 ns(mother, 2)2:sexM                -19.7    -6.97   5.72\n13 ns(father, 2)1:sexM                -15.0    -0.854 13.3 \n14 ns(father, 2)2:sexM                 -4.29    3.48  11.3 \n15 ns(mother, 2)1:ns(father, 2)1:sexM -20.2     6.10  32.4 \n16 ns(mother, 2)2:ns(father, 2)1:sexM -10.1    13.2   36.5 \n17 ns(mother, 2)1:ns(father, 2)2:sexM -23.4    -8.08   7.25\n18 ns(mother, 2)2:ns(father, 2)2:sexM -15.8    -2.90   9.97\n\n\nStatisticians keep in mind this folk wisdom:\n\nIf you try to capture too much detail in the relationship, you won’t capture anything.\n\nNotice that all but three of the terms have confidence intervals that include zero."
  },
  {
    "objectID": "Worksheets/Worksheet-24.html",
    "href": "Worksheets/Worksheet-24.html",
    "title": "Lesson 24: Worksheet",
    "section": "",
    "text": "The data frame Clock_auction gives the sales price at auction of antique grandfathers’ clocks. Both the age of the clock and the number of bidders for the clock are presumed to affect the price.\nBuild a linear model price ~ age + bidders.\nFind the effect sizes (i) with respect to price and (ii) with respect to bidders.\n\nDoes age increase or decrease the price? Give units for the effect size.\n\n\n\n\n\n\n\nANSWER\n\n\n\nNote: These answers are more detailed than what’s expected from you.\nFirst, the model and the coefficients:\n\nprice_model <- lm(price ~ age + bidders, data=Clock_auction)\nconf_interval(price_model)\n\n# A tibble: 3 × 4\n  term            .lwr  .coef   .upr\n  <chr>          <dbl>  <dbl>  <dbl>\n1 (Intercept) -1451.   -922.  -392. \n2 age             8.33   11.1   13.8\n3 bidders        37.5    64.0   90.6\n\n\nThis is, as usual for Math 300Z, a model with only linear terms, so the effect size with respect to an explanatory variable is exactly the same as the coefficient.\nThe coefficient on age is 11.1. This is positive, so we know that price increases with age.\nThe units tell us “11.1 what?” For a quantitative explanatory variable like age, the coefficient is always a rate: one quantity divided by another and so the units always read like “____ per ____.” The first blank gets filled in with the units of the response variable. Here, that’s dollars. The second blank is filled in with the units of the explanatory variable. Here, that’s years.\nPutting everything together, the units of the age coefficient are dollars-per-year. 11.1 dollars-per-year means that, according to the model, increasing age by 1 year increases price by about 11.1 dollars.\n\n\n\nDoes bidders increase or decrease the price? Give units for the effect size.\n\n\n\n\n\n\n\nANSWER\n\n\n\nThe bidders coefficient is about 64 (with units). It is positive, so, according to the model, the more bidders the higher the price.\nAs before the units of the coefficient is the units of the response variable divided by the units of the explanatory variable: dollars per bidder.\nInterpretation: According to the model, for every additional bidder on a clock (that is, increased competition), the auction price will go up by about $64.\n\n\n\nWhat can you say about whether the age effect size or the bidders effect size is larger.\n\n\n\n\n\n\n\nANSWER\n\n\n\nThe two effect sizes have different units—dollars-per-year and dollars-per-bidder. There is no direct comparison to be made between quantities of with different units. (For example: Which is bigger? Two feet or a liter of water?)\n\n\n\nBuild a model with an interaction term: price ~ age + bidders and graph the model using model_plot(). Is the age/bidders interaction readily visible in the graph? Explain what you see that informs your answer.\n\n\n\n\n\n\n\nANSWER\n\n\n\nTo include an interaction term, use * instead of + to link the two explanatory variables involved.\n\nprice_model2 <- lm(price ~ age * bidders, data=Clock_auction)\nmodel_plot(price_model2)\n\n\n\n\nThe interaction shows up in the non-parallel slopes of the individual lines of price vs age. Each line corresponds to a different number of bidders. The interaction means that the effect size with respect to age depends on the number of bidders.\nAnother manifestation of the interaction is that the spacing in price between the model values for the different levels bidders (the vertical spacing between the lines) depends on age. The spacing is relatively small for ages near 100 yrs, and somewhat larger for ages near 200 yrs.\nA separate question concerns sampling variation. Because of sampling variation, even if the “social-economic” process behind the auction had no interaction, one might appear in the model because of sampling variation. We haven’t yet talked about how to judge this, but here is a demonstration of how it works, using the confidence intervals on the coefficients.\n\nconf_interval(price_model2)\n\n# A tibble: 4 × 4\n  term             .lwr    .coef   .upr\n  <chr>           <dbl>    <dbl>  <dbl>\n1 (Intercept) -1877.    -513.    851.  \n2 age            -1.23     8.17   17.6 \n3 bidders      -118.      19.9   158.  \n4 age:bidders    -0.662    0.320   1.30\n\n\nI’m looking at the confidence interval on the coefficient of the interaction term (labeled as age:bidders). That interval includes zero, so there is no basis in these data to claim that the interaction is not zero.\nNote also that adding the age:bidders term has caused all the confidence intervals to change, and all of them now include zero. This is an illustration of a general phenomenon: If you try to extract details from data, you sometimes end up with nothing.\nFor those who are concerned that this can happen, I’ll explain what’s going on in this particular case but warn you that this sort of reasoning is not part of what’s expected from you in Math 300Z. The new term, age:bidders, is strongly correlated with the ordinary bidders term.\n\nlm(I(age*bidders) ~ bidders, data = Clock_auction) |> R2()\n\n   n k  Rsquared        F     adjR2            p df.num df.denom\n1 32 1 0.6266754 50.35902 0.6142312 4.742657e-08      1       30\n\n\nThus, the new term and bidders serve as proxies for one another. It becomes highly susceptible to sampling variation how to allocate “credit” to the individual terms: it can be done in any manner of ways giving almost equivalent results. This is a phenomenon called “multi-collinearity.”\nLooking at the model and the confidence bands graphically shows the amount of sampling variability graphically.\n\nmodel_plot(price_model2, interval=\"confidence\")\n\n\n\n\nIt’s possible to place three parallel lines within each of the confidence bands, meaning that the data does not rule out the possibility that the lines are parallel."
  },
  {
    "objectID": "Worksheets/Worksheet-24.html#part-2",
    "href": "Worksheets/Worksheet-24.html#part-2",
    "title": "Lesson 24: Worksheet",
    "section": "Part 2",
    "text": "Part 2\nThe Professional Golfers Association has an “index” used to rank golfers on the basis of the accuracy and distance of their drives. For a statistician, data on this provides an opportunity to “reverse engineer” the index. We can do this by modeling the relationship.\n\ngolf_mod <- lm(index ~ accuracy + dist, PGA_index)\n\nThe following table refers to a model with explanatory variables dist and accuracy. The table shows the .output of the model for each of four combinations of the explanatory variables.\n\nmodel_eval(golf_mod, \n           dist=c(100,200), accuracy = c(50,60)) |> \n  select(-.lwr, -.upr)\n\n  dist accuracy   .output\n1  100       50 -42.14096\n2  200       50 -21.52042\n3  100       60 -39.59864\n4  200       60 -18.97810\n\n\nA. At an accuracy of 50, what is the effect size of the .output with respect to dist? (Be sure to take into account both the difference in .output and the difference in dist.)\n\n\n\n\n\n\nANSWER\n\n\n\nLooking at the two rows with accuracy equal to 50 pts, going from distance 100 to distance 200 increases the output by about 20 index pts. Thus, the effect size with respect to accuracy is $\\(\\frac{-42.1 - 21.5}{100-200} = \\frac{20.4}{100} = 0.20\\) with units of “index pts per yard”. [Thanks to Ruby H. for pointing out my mistake in an earlier edition of this solution.]\n\n\nB. At a distance of 100, what is the effect size of the .output with respect to accuracy?\n\n\n\n\n\n\nANSWER\n\n\n\nLooking at the two rows with distance 100, an increase in accuracy from 50 to 60 corresponds to a change in output of -42.1 to -39.6, a difference of +2.5. The effect size is\n\\[\\frac{-42.1 - 39.6}{50 - 60} = \\frac{-81.7}{10} = -8.2\\] with units index-point per accuracy-point."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "",
    "text": "Update your version of the {math300} package.\n\n\nremotes::install_github(\"dtkaplan/math300\")\n\nNow you can get_teaching_notes(24) to get the sources for the teaching notes. Here you can see all the code in an executable format. BUT … often the code goes well beyond the programming expected for Math 300 students. An example is below, where I use information published by the College Board to reconstruct/simulate SAT scores for individuals.\n\nI made a mistake in calculating the regression using Excel. It’s easy to make such mistakes. But if I had done things correctly, Excel would have given the right answer.\n\n\n# Reconstructing the math scores from College Board percentile data\n# Math 300Z students are NOT expected to understand this code\nMath_scores <- tibble::tribble(\n  ~ female, ~ male, ~score,\n  99.5, 99, 800,\n  98, 95, 750,\n  94, 90, 700,\n  88, 81, 650,\n  79, 71, 600,\n  65, 56, 550,\n  43, 37, 500,\n  27, 23, 450,\n  13, 12, 400,\n  4, 4, 350,\n  1, 1, 300, \n  0, 0, 250,\n) %>%\n  mutate(fweights = -diff(c(100, female))) %>%\n  mutate(mweights = -diff(c(100, male)))\n\nN = 10000\nFemales <- Math_scores[-nrow(Math_scores),] %>% \n  dplyr::select(-male) %>% \n  sample_n(size = N, weight = fweights, replace = TRUE) %>% dplyr::select(score) %>% mutate(sex = \"female\")\nMales <- Math_scores[-nrow(Math_scores), ] %>% \n  dplyr::select(-female) %>% \n  sample_n(size = N, weight = mweights, replace = TRUE) %>% dplyr::select(score) %>% mutate(sex = \"male\")\nMath_scores <- rbind(Females, Males) %>% \n  mutate(score = ifelse(score == 800, 800, \n                        score - #runif(nrow(.), min = 0, max = 49) +\n                          rnorm(nrow(.), sd = 20)))"
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#proper-form-for-a-prediction",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#proper-form-for-a-prediction",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Proper form for a prediction",
    "text": "Proper form for a prediction\nAssign a probability to every possible outcome.\n\nggplot(Values, aes(x=\" \", y=.resid)) + geom_violin(alpha=0.4, fill=\"blue\") +\n  geom_jitter(alpha=0.2, width=.15) + xlab(\"Residual\") + ylab(\"\") +\n  geom_hline(yintercept=c(-4.13, 4.04), color=\"red\", alpha=0.5)\n\n\n\nValues |> summarize(m = mean(.resid), sd=sd(.resid), \n                    q2.5=quantile(.resid, 0.025),\n                    q97.5 = quantile(.resid, 0.975))\n\n              m       sd      q2.5    q97.5\n1 -2.882542e-14 2.150721 -4.129319 4.043707"
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#realistic-predictioç",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#realistic-predictioç",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Realistic predictioç",
    "text": "Realistic predictioç\nPrecipitation runoff: It rains. Some of the water is absorbed, some runs off and ends up in a nearby river. The runoff is measured as the depth of water over the entire catchment basin that ends up in the river. Give a forecast of a storm, we might want to know if a flood is likely.\nData for the Monocacy River in Maryland, close to where I grew up.\nRESULT FOR THE BIGGEST RAINFALL DEPENDS ON how logarithms are used.\n\nggplot(Monocacy_river |> filter(precip > 2), aes(x=log(precip), y=log(runoff))) +\n  geom_point() +\n  geom_lm(interval=\"prediction\") +\n  geom_lm(interval=\"confidence\", fill=\"blue\") # +\n\nWarning: Using the `size` aesthietic with geom_ribbon was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\nWarning: Using the `size` aesthietic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n # geom_abline(slope=1.08, intercept=-1.07)"
  },
  {
    "objectID": "Worksheets/Worksheet-25.html",
    "href": "Worksheets/Worksheet-25.html",
    "title": "Lesson 25: Worksheet",
    "section": "",
    "text": "We are using two different kinds of “intervals” for very different kinds of purposes:\n\nConfidence intervals are used to represent the precision of our estimates of coefficients. This always involves averaging over multiple data points.\nPrediction intervals are used to indicate the range of likely values of the response variable when specifying the explanatory variables.\n\nAlmost always, such intervals are constructed at the “95% level.” Because of this we don’t always mention the level. But other “levels” can be used: 80%, 90%, 99%, and so on.\nIt’s hard to tell from a graph of a confidence interval (or band) what the confidence level is. On the other hand, it’s often straightforward to estimate the “level” for a prediction interval or band. For a 95% prediction level, for instance, about 5% of the data points will be outside the prediction interval, while for a 99% level only about 1% of the data points will be outside the prediction interval.\nHere are graphs of some confidence bands and some prediction bands. For each graph, the sample size \\(n\\) is either 100 or 200. For each graph, say what the sample size is and whether it displays a prediction or a confidence band. If it’s a prediction band, estimate the prediction level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANSWER\n\n\n\nA. These are prediction intervals. Notice that they cover most of the data. There are 200 points and about 40 are outside of the intervals, so the prediction level is (200-40)/200 = 80%.\nB. A confidence band.\nC. Same data as in (B), but the band covers almost all the data. There are about 200 points, of which about 20 are outside the band, so the prediction level is (200-20)/200 = 90%.\nD. A confidence band.\nE. A prediction band. There are about 200 points, with about 2 outside the band, so the prediction level is (200-2)/200 = 1%.\nF. This is a tricky one. It looks like about 80% of the data are outside of the band, so if it’s a prediction band then the level is 80%. Could it be a confidence interval with a very high level (say, 99.99%)? Figure (D) shows the same data with a confidence band. Note the hour-glass shaped band. This is typical of a confidence band, but not of a prediction band.\nG. Confidence intervals.\nH. Prediction band. About 200 points altogether, of which about 20 are outside the band. (You need to look at the intensity of the dots to see the multiple data points being overplotted.) So a prediction level of about 90%."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#case-study-test-scores",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#case-study-test-scores",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Case study: Test scores",
    "text": "Case study: Test scores\nThere are certain tasks where a confidence interval is appropriate and others where it is utterly misleading. It’s important to distinguish between the two.\nHere’s an example: a headline about SAT scores:\n\n“2016 SAT test results confirm pattern that’s persisted for 50 years — high school boys are better at math than girls”— source\n\nThis is the graph supporting the claim:\n\nUsing the simulated data, we can get a confidence interval on the difference between scores for females and males.\nWhat does the above graph show?\n\nWhy do the lines follow the same up-and-down path? Is this random variation?\nWhat covariates might be at work here?\n\nWho takes math in high-school\n\nfewer boys took low-level math at any time, more boys take physics\n\nNumber taking the exam? about 91M/100F\n“Natural sex ratio” is about 105 M / 100 F. in US Ratio of fraction of population taking the SAT 87 M/100 F."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#estimating-the-confidence-interval-on-the-means",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#estimating-the-confidence-interval-on-the-means",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Estimating the confidence interval on the means",
    "text": "Estimating the confidence interval on the means\n\n\n\n\n\nFigure 1: The distribution of scores on the SAT mathematics test, reconstructed from summary data published by the College Board.\n\n\n\n\n\nFind the center of the distribution.\n\nFind an interval that includes “almost all” of the data: about 95%.\nFind an interval that includes about 2/3 of the data: 66%.\nThe data’s standard deviation, \\(s\\), will be somewhere in the range from\n\none-half of (3)\none-quarter of (2)\n\nThe margin of error will be \\(2 s/\\sqrt{n}\\). Here, \\(n\\) is roughly 1M.\nAs always, the confidence interval will be “center \\(\\pm\\) margin-of-error.”\n\nAs a computation, here it is for sample size \\(n=20,000\\).\n\nlm(score ~ 1, data=Math_scores) |> conf_interval()\n\n# A tibble: 1 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept)  506.  507.  509.\n\n\nThe actual size of the data is about \\(n=1,000,000\\), 50 times greater. So the confidence interval on the mean of the actual data will be about 1/7 of the one in the calculation: 1.5/7 = 0.2.\nWe can also look at the confidence interval on the difference in scores between the sexes:\n\nlm(score ~ sex, data=Math_scores) |> conf_interval()\n\n# A tibble: 2 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept) 493.  495.  497. \n2 sexmale      21.9  24.9  28.0\n\n\nWith the full data set, the margin of error is 3/7 = 0.4."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#explaining-the-difference",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#explaining-the-difference",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Explaining the difference?",
    "text": "Explaining the difference?\nLooking at average SAT from state to state as a function of expenditures and fraction.\n\nsat_model <- lm(math ~ frac + expend, data = SAT)\nmodel_plot(sat_model)\n\n\n\nconf_interval(sat_model)\n\n# A tibble: 3 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 493.   518.   543.  \n2 frac         -1.78  -1.53  -1.29\n3 expend        2.71   7.54  12.4 \n\n\nThe standard deviation of SAT math scores across individuals is about 110 points. The numbers taking the test are so large (about 800,000 F, 700,000 M) that the standard error for each group is \\[\\frac{110}{\\sqrt{750,000}} = 0.13\\ \\text{points}\\]\nThe issue I want to focus on, ignoring the covariates, is the extent to which you can figure out a student’s math aptitude by knowing the student’s sex.\nGiven a female, what’s the predicted test score? For a male?\nHow do you describe a prediction.\n\nIdeally: as a probability for each possible outcome: a probability distribution.\nHorribly: as the mean.\nConventionally: as an interval."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#prediction-interval",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#prediction-interval",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Prediction interval",
    "text": "Prediction interval\nFormally …\n\nlm(score ~ sex, data=Math_scores) |>\n  model_eval(skeleton = TRUE, interval=\"prediction\")\n\n     sex  .output     .lwr     .upr\n1 female 494.9550 277.6127 712.2974\n2   male 519.8865 302.5442 737.2288\n\n\nInformally … Cover almost all (say, 95%) of the data."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#assigning-a-probability",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#assigning-a-probability",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Assigning a probability",
    "text": "Assigning a probability\nAn interval is a convenient summary of a prediction. In the next class, we’ll see how to approximately translate an interval into a probability distribution.\n\nOrings <- Sleuth3::ex2011\nOrings <- Orings %>% mutate(fail = zero_one(Failure, one=\"Yes\"))\nmod_oring <- glm(fail ~ Temperature, data=Orings, family=\"binomial\")\nmodel_plot(mod_oring)\n\n\n\nmodel_eval(mod_oring, Temperature=28, interval=\"confidence\", level=.95)\n\n  Temperature   .output      .lwr     .upr\n1          28 0.9977133 0.3653965 0.999997"
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#converting-to-an-interval",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#converting-to-an-interval",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Converting to an interval",
    "text": "Converting to an interval"
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#watch-out-for-the-extremes",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#watch-out-for-the-extremes",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Watch out for the extremes",
    "text": "Watch out for the extremes\nIn designing infrastructure, it doesn’t matter so much what is the 97.5% max wind velocity per day. What matters is the 99.995% velocity: the biggest in, say, 50 years."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#review-of-lesson-24",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#review-of-lesson-24",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Review of Lesson 24",
    "text": "Review of Lesson 24\nTHIS IS VERY DRAFTY.\nIn the last lesson, we considered effect size, a way to summarize a model to indicate the strength and direction of the influence of an explanatory variable with respect to a response variable. (As always, sample statistics such as the effect size are according to the model. A different model may give you different results, so the choice of model specification is important and should be carefully considered.)\nHere’s a possible DAG for the height of a child.\n\nheight_dag <- dag_make(\n  mother_genetics ~ exo(),\n  father_genetics ~ exo(),\n  exo_dad ~ exo(),\n  exo_mom ~ exo(),\n  mother_height ~ mother_genetics + exo_mom + exo(),\n  father_height ~ father_genetics + exo_dad + exo(),\n  health ~ exo(),\n  nutrition ~ exo(),\n  child_sex ~ exo(),\n  child_height ~ mother_genetics + father_genetics + child_sex + nutrition + health + exo()\n)\nset.seed(106); dag_draw(height_dag, vertex.size = 13,\n                        vertex.label.cex=0.75, \n                        edge.arrow.size=.25 )\n\n\n\n\nWe talk casually about the effect size of child’s height with respect to mother’s height, but there is no causal flow between mother’s height and child’s height. What we mean is the effect of a change in the mother’s genetics that leads to a 1 inch change in mother’s height and a corresponding change in child’s height.\nThe concept of an effect size is that all the other nodes are held constant when we change the mother’s genetics, including health, nutrition, sex, and father’s genetics.\nThere’s no way to do this; there aren’t two identical mothers to compare who differ only in their height-related genetics and can produce children who have exactly the same father’s genetics.\nInstead, what we think about is comparing two children from two similar mothers (differing only in height genetics) with similar father genetic contribution, nutrition, health, ….\nThe model specification height ~ mother + father + sex does this comparison of similars in a mathematical way. But the model output is not the only thing that changes when we generate this mathematical child’s height from two different height mothers.\nThe residuals from the model indicate the magnitude of all the other influences that we haven’t been able to hold constant.\n\nheight_mod <- lm(height ~ mother + father + sex, data=Galton)\nValues <- model_eval(height_mod)\n\nUsing training data as input to model_eval().\n\nggplot(Values, aes(x=mother, y=.resid)) + geom_jitter(alpha=0.5)\n\n\n\n\n\nIs there any clear pattern to the residuals?\nIf we were making a prediction of a daughter’s height, should we just look at the model value based on the parents’ heights, or should we take into account the residuals."
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#realistic-predictions",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#realistic-predictions",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Realistic predictions",
    "text": "Realistic predictions\nPrecipitation runoff: It rains. Some of the water is absorbed, some runs off and ends up in a nearby river. The runoff is measured as the depth of water over the entire catchment basin that ends up in the river. Give a forecast of a storm, we might want to know if a flood is likely.\nData for the Monocacy River in Maryland, close to where I grew up.\nRESULT FOR THE BIGGEST RAINFALL DEPENDS ON how logarithms are used.\n\nggplot(Monocacy_river |> filter(precip > 2), aes(x=log(precip), y=log(runoff))) +\n  geom_point() +\n  geom_lm(interval=\"prediction\") +\n  geom_lm(interval=\"confidence\", fill=\"blue\") # +\n\nWarning: Using the `size` aesthietic with geom_ribbon was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\nWarning: Using the `size` aesthietic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n # geom_abline(slope=1.08, intercept=-1.07)"
  },
  {
    "objectID": "Day-by-day/Lesson-25/Teaching-notes-25.html#prediction",
    "href": "Day-by-day/Lesson-25/Teaching-notes-25.html#prediction",
    "title": "Instructor Teaching Notes for Lesson 25",
    "section": "Prediction",
    "text": "Prediction\nConfidence intervals are impressive because we have poor intuition about the effects of averaging. (For instance, the \\(1/\\sqrt{n}\\) width of confidence intervals is not obvious.)\n\nmod <- lm(height ~ mother*sex, data=Galton)\nmodel_plot(mod, interval=\"confidence\") +\n  facet_wrap(~ sex)\n\n\n\n\nPrediction intervals are unimpressive because it’s easy for us to draw the boundaries of the raw data.\n\nmodel_plot(mod, interval=\"prediction\") +\n  facet_wrap(~ sex)\n\n\n\n\nThe reasons it’s worthwhile to study prediction are:\n\nTo know when to use prediction and when to use estimation of effect size.\nTo know the proper form of a prediction, which is not the same thing as the proper form of a confidence interval.\n\nPrediction: List the possible outcomes, assign a probability (or prob. density, i.e. a relative probability) to each possible outcome.\n\nTo understand when it’s important to predict extremes rather than “central” values.\nAs a case study in updating probabilities as new information comes in.\n\nMarch Madness brackets."
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "",
    "text": "We’re going to be talking about probability today.\nBasketball feat, solar system trajectories, terminal guidance\nDrone video\n360 hospitals, each with a 1% chance of needing a medicine/blood/etc in the interval before it expires."
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#reverse-engineering-the-prediction-interval",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#reverse-engineering-the-prediction-interval",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "Reverse engineering the prediction interval",
    "text": "Reverse engineering the prediction interval\nA prediction interval has a form like [15, 23] or, equivalently, 19 \\(\\pm\\) 4. This is not a probability distribution.\nHOWEVER, it is a shorthand for a distribution: called variously the normal or gaussian or bell-shaped distribution. - This distribution has two parameters: the mean and the standard deviation. - For the 19 \\(\\pm\\) 4 prediction interval, the mean is 19 and the standard deviation is 4/2.\n\n\n\n\n\nThe prediction interval covers the central 95% of the probability.\nEvents at the center are about 7 times more likely than at the ends of the prediction interval. About 2/3 of the probability is within \\(\\pm 1\\) standard deviation."
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#the-contest",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#the-contest",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "The contest",
    "text": "The contest\n\n\n[1] 0.3396823 0.6603177"
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#updating-a-probability-distribution",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#updating-a-probability-distribution",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "Updating a probability distribution",
    "text": "Updating a probability distribution\nAs interest rates climbed from 2.5%, SVB ought to have revised its prediction of future interest rate and reduced the risk of catastrophic failure by selling off the troubled assets.\nBut how to update?\nThe correct procedure is called Bayesian updating. Here’s an example:\n See this Math 300Z blog entry"
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#review-of-lesson-25",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#review-of-lesson-25",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "Review of Lesson 25",
    "text": "Review of Lesson 25"
  },
  {
    "objectID": "Day-by-day/Lesson-26/Intervals-by-eye.html#intervals-by-eye",
    "href": "Day-by-day/Lesson-26/Intervals-by-eye.html#intervals-by-eye",
    "title": "Spring 2023 Math 300Z",
    "section": "Intervals by eye",
    "text": "Intervals by eye\n\nIn this activity, you are given some point plots of data: y vs x. Your job is to\n\nsketch in an appropriate model fitted (by eye) to the data.\nadd a prediction band showing for each value of x what is the prediction interval\ntransform the prediction band into a confidence band.\n\nTIPS:\n\nThe fitted model will be a line or curve, or in the case of Model 3, two lines.\nThe bounds of the prediction band will be more-or-less parallel to the fitted model, but should include roughly 95% of the \\(n\\) points in the plot.\nThe confidence band is narrower than the prediction band by a factor of \\(1/\\sqrt{n}\\).\n\n\n\n\n\nModel 1: A straight-line model y ~ x\n\n\n\n\n\n\n\n\nModel 2: A sine-wave model, y ~ sin(x)\n\n\n\n\n\n\n\n\n\nModel 3: A function of two variables, y ~ x + group"
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#why-a-probability-distribution-for-prediction",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#why-a-probability-distribution-for-prediction",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "Why a probability distribution for prediction?",
    "text": "Why a probability distribution for prediction?\nTo help in making decisions. Example: Silicon Valley Bank is trying to decide what fraction of its assets to put in long-term government bonds.\nIf the interest rate is 2.5%, then a bond paying $1000 in 10-years time, if it is to be worthwhile should cost less: $780.\n\nIf the interest rate falls to 1.5%, then the bond is worth more: $860.\nIf the interest rate increases to 4.5%, then the bond is worth less: $644\n\nSVB made a bet on interest rates. This is closely related to prediction.\nBanks hire economists and other specialists to make predictions about things like interest rates. They use these predictions to estimate risk. For instance, if the bank’s assets fall in value by 15%, the bank will not have enough money on hand to pay depositors, leading to a run on the bank, ….\nImagine this prediction about interest rates one year after buying the government bonds at $780. (We aren’t going to worry about where such predictions come from. The point for us is to illustrate how the probability form of prediction helps in making decisions.)\n\n\n\n\n\n\n\n\n\n\nAccording to prediction model, the probability of the interest rate leading to a 80% decline (or more) is 1.9%."
  },
  {
    "objectID": "Day-by-day/Lesson-26/Teaching-notes-26.html#review-from-lesson-25",
    "href": "Day-by-day/Lesson-26/Teaching-notes-26.html#review-from-lesson-25",
    "title": "Instructor Teaching Notes for Lesson 26",
    "section": "Review from Lesson 25",
    "text": "Review from Lesson 25\n\nThe proper form for a prediction is a list of possible outcomes, each assigned a probability. Over the whole list, the probabilities must add up to 1. We call this list a probability distribution.\n\nFederal reserve forecasts\n\nThe modeling software produces a prediction interval, which is much wider than a confidence interval. Confidence interval length goes to zero as \\(n\\rightarrow\\infty\\), but prediction interval stays pretty much the same.\nFor confidence intervals, use 95% (the convention)."
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "",
    "text": "Critical thinking\nTwo crucial words will be introduced an elaborated upon this week (Lessons 28-30).\nYou already know what a covariate is, even if not formally.\nPolitical spending\nComparative health in Mexico and US\nComparing hospitals"
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#review-of-lesson-27",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#review-of-lesson-27",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "Review of Lesson 27",
    "text": "Review of Lesson 27"
  },
  {
    "objectID": "Day-by-day/Lesson-28/covariate-confusion.html",
    "href": "Day-by-day/Lesson-28/covariate-confusion.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "This activity is to investigate how adding a covariate to a model can change the coefficient on another explanatory variable. The basic logic of the activity is to construct a series of pairs of nested models and examine the confidence interval on the coefficient of an explanatory variable.\nYou will use the Anthro_F data frame, which records measurements made on 184 women of body shape: knee circumference, ankle circumference, and so on. Since people have similar body shapes, regardless of size, these measurements tend to be correlated with one another.\nThe models you will build will have as BFat as the response variable. BFat is the measured proportion of body weight that is fat tissue. As an example of a nested pair of models, consider:\n\nBFat ~ Knee\nBFat ~ Knee + Ankle\n\nModel (i) is “nested” in model (ii) because model (ii) includes all the variables in model (i). (Nested models always have the same response variable.)\nYour analysis of each pair will compare the confidence interval on the explanatory variable in the smaller model to that same variable in the larger model, e.g.\n\nlm(Height ~ Knee, data=Anthro_F) |> conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) 1.31    1.44    1.57   \n2 Knee        0.00275 0.00636 0.00996\n\nlm(Height ~ Knee + Ankle, data=Anthro_F) |> conf_interval()\n\n# A tibble: 3 × 4\n  term              .lwr   .coef    .upr\n  <chr>            <dbl>   <dbl>   <dbl>\n1 (Intercept)  1.25      1.40    1.55   \n2 Knee         0.0000406 0.00465 0.00925\n3 Ankle       -0.00325   0.00479 0.0128 \n\n\nWorking with your group partners, try to find pairs of explanatory variables such that the coefficient on one variable changes greatly when the covariate is added to the model.\nTo help, here is the correlation between many pairs of variables presented in the form of an angle in degrees. (See background section below.) Every variable has a angle 0 with itself. Small angles mean the two variables are closely aligned, large angles mean they are not.\n\n\n\nCode\ncorrs <- Anthro_F |>\n  select(Neck, Chest, Calf, Biceps, Hips, Waist, PThigh, MThigh, DThigh, Forearm, Wrist, Knee, Elbow, Ankle, Age) |>\n  cor() \nround(180*acos(corrs)/pi) \n\n\n        Neck Chest Calf Biceps Hips Waist PThigh MThigh DThigh Forearm Wrist Knee Elbow Ankle Age\nNeck       0    53   63     49   52    47     51     53     58      47    51   60    53    58  95\nChest     53     0   71     55   58    52     55     58     67      55    62   67    56    71  90\nCalf      63    71    0     65   63    64     60     59     60      58    63   62    63    58  89\nBiceps    49    55   65      0   45    41     42     43     52      34    45   54    43    60  93\nHips      52    58   63     45    0    40     24     38     48      44    51   42    46    50  90\nWaist     47    52   64     41   40     0     40     48     57      44    49   52    46    58  95\nPThigh    51    55   60     42   24    40      0     27     43      42    49   40    45    50  92\nMThigh    53    58   59     43   38    48     27      0     43      43    47   48    47    50  92\nDThigh    58    67   60     52   48    57     43     43      0      50    55   49    55    53  92\nForearm   47    55   58     34   44    44     42     43     50       0    34   50    39    49  93\nWrist     51    62   63     45   51    49     49     47     55      34     0   54    45    48  94\nKnee      60    67   62     54   42    52     40     48     49      50    54    0    54    51  97\nElbow     53    56   63     43   46    46     45     47     55      39    45   54     0    52  95\nAnkle     58    71   58     60   50    58     50     50     53      49    48   51    52     0  96\nAge       95    90   89     93   90    95     92     92     92      93    94   97    95    96   0\n\n\n\nTASK: Pick several pairs of variables, some related by small angles and some with large angles. For each pair, compare the first variable’s coefficient between the nested models.\nAs a group, find the biggest change you observed in the coefficient when adding the covariate to the model? (You’ll have to agree on a way to measure change in the coefficient.) Do large or small angles tend to produce bigger changes?"
  },
  {
    "objectID": "Day-by-day/Lesson-28/covariate-confusion.html#background-r-r2-and-the-angle-between-variables",
    "href": "Day-by-day/Lesson-28/covariate-confusion.html#background-r-r2-and-the-angle-between-variables",
    "title": "Spring 2023 Math 300Z",
    "section": "Background: r, R2, and the “Angle” between variables",
    "text": "Background: r, R2, and the “Angle” between variables\nSince Francis Galton’s invention/discovery of the correlation coefficient in 1888, it has been the standard introduction to measuring the relationship between two quantitative variables. It has even entered the vocabulary of everyday English as “a mutual relationship or connection between two or more things.” (Oxford Dictionaries)\nAlso in 1888, the phenomenon of electromagnetic waves was discovered by physicist Heinrich Hertz. These had been theoretically predicted in 1865 by James Clerk Maxwell. The mathematics of Maxwell’s representation of electromagnetism was very difficult. Consequently, physicists and mathematicians worked to create a simpler formalism. This eventually emerged in the university-level curriculum as two courses: vector calculus (usually called Calc III) and linear algebra. Naturally, in 1888, Galton was unaware of these developments. Nonetheless, vectors and linear algebra provide a great simplification of the concept of correlation.\nAny quantitative variable—a series of numbers—is also consequently a “vector,” which you can think of as an arrow pointing in a particular direction. The correlation coefficient between two variables amounts to the cosine of the angle between the two vectors. When the angle is very small, the variables are strongly aligned. When the angle is near 90\\(^\\circ\\), the two variables are not at all aligned.\nIn R, a standard way of calculating the correlation coefficient uses cor() as in this example:\n\nGalton |> summarize(correlation = cor(height, mother))\n\n  correlation\n1   0.2016549\n\n\nThe translation of the correlation coefficient into an angle (in degrees) involves some trigonometry (which is not a topic of Math 300):\n\nacos(0.202)*180/pi\n\n[1] 78.34606\n\n\n78 degrees is pretty close to a right angle, meaning that height and mother are barely aligned.\n\n\n\n\n\n\nAside: R2 and r\n\n\n\nWe have not emphasized the correlation coefficient r in Math 300 because r is descriptive only of the (linear) relationship between two variables. In Math 300, we are often using multiple explanatory variables and r does not apply. Instead, we use R2: a much more general description of the relationship between a response variable and explanatory variables.\nIn the case where a model has only one explanatory variable, e.g., height ~ mother, R2 has a simple relationship to r, namely, r2 = R2. This use of lower-case (r) and upper-case (R) can be confusing, so we are not using r much in Math 300.\nTo demonstrate the relationship between r and R2, consider:\n\nlm(height ~ mother, data=Galton) |> R2()\n\n    n k  Rsquared        F      adjR2            p df.num df.denom\n1 898 1 0.0406647 37.98001 0.03959401 1.078142e-09      1      896\n\n\nSince r between height and mother was 0.2016, you can confirm that R2 from the model is exactly r2."
  },
  {
    "objectID": "Worksheets/Basic-questions.html",
    "href": "Worksheets/Basic-questions.html",
    "title": "Spring 2023 Math 300Z",
    "section": "",
    "text": "What are the two main types of content in variables?\nWhat are the two main roles of variables in constructing a regression model?\nIn regression modeling, what is the restriction on the kind of variable that can be used for the response variable?\nDescribe the fundamental framework for modeling.\nIn terms of a model specification, where does a “covariate” fit in?\nWhat does “sample statistic” mean?\nWhat does “sampling variation” mean and how is it related to “sampling variance?”\nWhat is the difference between a confidence interval and a prediction interval?"
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#background-review",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#background-review",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "Background review",
    "text": "Background review\nThe fundamental framework that we use over and over again in this course involves:\n\nA data frame holding variables of interest.\nA model specification which\n\na response variable (always quantitative) which we’ll write generically as y\nzero or more explanatory variables\n\ny ~ 1\ny ~ 1 + x (usually written as the shorthand y ~ x)\ny ~ 1 + x + z (with potentially more explanatory variables)\n\n\nTraining the model (also called fitting) to produce coefficients.\n\nFor the “intercept” (that is, the 1 term) there is one coefficient.\nFor each quantitative explanatory variable there is one coefficient.\nFor any categorical explanatory variable with k levels, there are k-1 coefficients.\nWhen a model includes “interactions” (as signified by using * rather than + in the model specification), there are additional coefficients. But we are not emphasizing such models in Math 300."
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#example-life-expectancy",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#example-life-expectancy",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "Example: Life expectancy",
    "text": "Example: Life expectancy\nUsing the gapminder::gapminder data.\n\n\n\nAre life-expectancy (at birth) and wealth (measured by GDP) related?\n\nggplot(gapminder, aes(x=gdp, y=lifeExp)) + \n  geom_point() \n\n\n\n\nWhat do you like or dislike about the above graph?\n\nggplot(gapminder, aes(x=gdp, y=lifeExp)) + \n  geom_point() +\n  scale_x_log10()\n\n\n\n\nCompare these two models:\n\nlm(lifeExp ~ gdp, data=gapminder) |> R2()\n\n     n k  Rsquared        F      adjR2 p df.num df.denom\n1 1704 1 0.0667536 121.7413 0.06620528 0      1     1702\n\nlm(lifeExp ~ gdp + year, data=gapminder) |> R2()\n\n     n k  Rsquared        F     adjR2 p df.num df.denom\n1 1704 2 0.2279324 251.0875 0.2270246 0      2     1701\n\n\nyear is a covariate. We want to do the comparison holding year constant.\n\nlm(lifeExp ~ log(I(gdp/pop)), data=gapminder |> filter(year == 2007)) |> R2()\n\n    n k Rsquared        F     adjR2 p df.num df.denom\n1 142 1 0.654449 265.1501 0.6519808 0      1      140\n\n\nDiscuss whether gdp is the right variable to look at to measure wealth.\n\nlog(gdp) ?\nAdjusting for population size\n\n\n“Intensive” vs “extensive” variables\n\ntemperature (intensive)\npressure (intensive)\nmass (extensive)\nheat capacity (extensive)\nlife expectancy (intensive)\nGDP (extensive)\nPopulation (extensive)\n\nTake care when mixing together intensive and extensive variables in a model.\n\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=country)) + \n  geom_point() + \n  scale_x_log10() + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#covariates-can-change-coefficients",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#covariates-can-change-coefficients",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "Covariates can change coefficients",
    "text": "Covariates can change coefficients\nPredict when this will happen.\nCorrelation coefficient as angle."
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#in-class-activity",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#in-class-activity",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "In-class activity",
    "text": "In-class activity\nSee when adding a covariate changes the coefficients. 1. Look for maximally and minimally correlated variable pairs in Anthro_F 2. Fit two nested models for BFat, one with a single explanatory variable from the pair and the other with both variables from the pair. 3. Repeat using Height just to show that it’s the explanatory variables that are determining the shift.\n\nlm(BFat ~ Hips, data=Anthro_F) |> conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) -53.4   -44.0   -34.6  \n2 Hips          0.581   0.678   0.776\n\nlm(BFat ~ Hips + PThigh, data=Anthro_F) |> conf_interval() \n\n# A tibble: 3 × 4\n  term            .lwr   .coef    .upr\n  <chr>          <dbl>   <dbl>   <dbl>\n1 (Intercept) -49.8    -40.5   -31.1  \n2 Hips          0.0829   0.311   0.539\n3 PThigh        0.243    0.559   0.874\n\n\nAnthro_F |> summarize(cor(Wrist, Waist))\n# A tibble: 1 × 1\n  `cor(Wrist, Waist)`\n                <dbl>\n1               0.660\n> Anthro_F |> summarize(cor(Wrist, Biceps))\n# A tibble: 1 × 1\n  `cor(Wrist, Biceps)`\n                 <dbl>\n1                0.705\n> Anthro_F |> summarize(cor(Wrist, Age))\n# A tibble: 1 × 1\n  `cor(Wrist, Age)`\n              <dbl>\n1           -0.0748\n> lm(BFat ~ Wrist, data=Anthro_F) |> conf_interval()\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) -38.8  -26.4  -14.1 \n2 Wrist         2.29   3.08   3.87\n> lm(BFat ~ Wrist + Age, data=Anthro_F) |> conf_interval()\n# A tibble: 3 × 4\n  term           .lwr    .coef    .upr\n  <chr>         <dbl>    <dbl>   <dbl>\n1 (Intercept) -39.9   -25.1    -10.4  \n2 Wrist         2.28    3.07     3.86 \n3 Age          -0.408  -0.0575   0.293\n> lm(BFat ~ Wrist + Knee, data=Anthro_F) |> conf_interval()\n# A tibble: 3 × 4\n  term           .lwr  .coef   .upr\n  <chr>         <dbl>  <dbl>  <dbl>\n1 (Intercept) -54.8   -43.1  -31.3 \n2 Wrist         0.339   1.20   2.06\n3 Knee          0.943   1.29   1.64"
  },
  {
    "objectID": "Day-by-day/Lesson-28/Teaching-notes-28.html#simpsons-paradox",
    "href": "Day-by-day/Lesson-28/Teaching-notes-28.html#simpsons-paradox",
    "title": "Instructor Teaching Notes for Lesson 28",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\n\nlm(zero_one(admit, one=\"admitted\") ~ gender, data = UCB_applicants) |> conf_interval()\n\n# A tibble: 2 × 4\n  term         .lwr .coef  .upr\n  <chr>       <dbl> <dbl> <dbl>\n1 (Intercept) 0.281 0.304 0.326\n2 gendermale  0.113 0.142 0.170\n\nlm(zero_one(admit, one=\"admitted\") ~ gender + dept, data = UCB_applicants) |>\n  conf_interval()\n\n# A tibble: 7 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept)  0.621   0.660   0.699 \n2 gendermale  -0.0485 -0.0184  0.0117\n3 deptB       -0.0563 -0.0103  0.0356\n4 deptC       -0.347  -0.303  -0.260 \n5 deptD       -0.354  -0.311  -0.268 \n6 deptE       -0.452  -0.403  -0.354 \n7 deptF       -0.631  -0.586  -0.542"
  },
  {
    "objectID": "Worksheets/Worksheet-28.html",
    "href": "Worksheets/Worksheet-28.html",
    "title": "Lesson 28: Worksheet",
    "section": "",
    "text": "In this Worksheet, you’ll explore how adding a covariate to a model can change the coefficient on an explanatory variable.\nWe will work with two nested models trained on the Galton data frame:\n\nheight ~ mother\nheight ~ mother + covar where you will replace covar with a variable we will construct.\n\nTask A. Replace covar with father and observe how the coefficient on mother changes between (i) and (ii). Describe the change as large or small, providing also your definition for large and small in this context.\n\n\n\n\n\n\nANSWER\n\n\n\nThe two models are\n\nlm(height ~ mother, data=Galton) |> conf_interval()\n\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 40.3   46.7   53.1  \n2 mother       0.213  0.313  0.413\n\nlm(height ~ mother + father, data=Galton) |> conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 13.9   22.3   30.8  \n2 mother       0.187  0.283  0.380\n3 father       0.290  0.380  0.470\n\n\nI describe the change in the mother coefficient as small, since the confidence intervals on the two models overlap very substantially. The difference between the .coefs is very small compared to the width of the confidence intervals.\n\n\nTask B. An important factor in whether a covariate changes a coefficient is the strength of the relationship between the covariate and the other explanatory variable. Measure the strength of the relationship between mother and father by fitting the model mother ~ father and finding R2. Describe whether the R2 you find in this way is large or small. (You’ll have to give a definition for “large” and “small” in this context. It will be different than for the context in part (A). Also, note that in this task, the response variable is mother, not height.)\n\n\n\n\n\n\nANSWER\n\n\n\nTo look at the relationship between the covariate father and the other explanatory variable mother, find R2\n\nlm(mother ~ father, data=Galton) |> R2()\n\n    n k    Rsquared       F      adjR2          p df.num df.denom\n1 898 1 0.005426475 4.88865 0.00431646 0.02728512      1      896\n\n\nThe R2 statistic can range from zero to one. On that scale, the above R2 is very close to zero, so there is little if any relationship between the mother’s height and the father’s height. Following social convention, usually there is little or no genetic relationship between the mother and the father. But if you think that married couples tend to be similar in height, the Galton data suggests otherwise.\n\n\nTask C. Now you are going to create a new covariate that is going to be closely related to mother. This is a matter of making the new variable very similar to mother, like this:\n\nGalton <- Galton %>% \n  mutate(new_var = 6*mother + 2*father)\n\nThe new_var consists of six parts mother and two parts father.\n\nWhat is the R2 between mother and new_var?\nComparing the mother coefficient from the nested pair of models height ~ mother and height ~ mother + new_var, would you say that new_var changes things substantially?\n\n\n\n\n\n\n\nANSWER\n\n\n\n\nlm(mother ~ new_var, data = Galton) |> R2()\n\n    n k  Rsquared        F     adjR2 p df.num df.denom\n1 898 1 0.8926256 7448.632 0.8925057 0      1      896\n\n\nAnd now the change in the mother coefficient\n\nlm(height ~ mother, data=Galton) |> conf_interval()\n\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 40.3   46.7   53.1  \n2 mother       0.213  0.313  0.413\n\nlm(height ~ mother + new_var, data=Galton) |> conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 13.9   22.3   30.8  \n2 mother      -1.15  -0.856 -0.563\n3 new_var      0.145  0.190  0.235\n\n\nNotice that the mother coefficient changed sign between the two models. This is called “Simpson’s Paradox.” But it’s really only a paradox to people who don’t understand that using a covariate that is closely related to an explanatory variable can substantially change the coefficient on the explanatory variable.\n\n\nTask D. Going back to the commands in (C), increase the mixture in new_var to fifty parts mother and one part father. What happens to the width of the confidence interval on mother when this close copy of mother is used as a covariate?\n\n\n\n\n\n\nANSWER\n\n\n\nNote that we have already calculated, above, the mother coefficient from height ~ mother.\n\nGalton <- Galton %>% \n  mutate(new_var = 50*mother + 1*father)\nlm(height ~ mother + new_var, data=Galton) |> conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept)  13.9    22.3    30.8  \n2 mother      -23.2   -18.7   -14.2  \n3 new_var       0.290   0.380   0.470\n\n\nThe confidence interval on mother becomes extremely wide!\n\n\nTask E. Just for interest’s sake … Like Task D, but make new_var 50 parts mother and zero parts father. Something perhaps unexpected happens to bother the mother and the new_var coefficients. Describe what this is.\n\n\n\n\n\n\nANSWER\n\n\n\n\nGalton <- Galton %>% \n  mutate(new_var = 50*mother + 0*father)\nlm(height ~ mother + new_var, data=Galton) |> conf_interval()\n\n# A tibble: 3 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) 40.3   46.7   53.1  \n2 mother       0.213  0.313  0.413\n3 new_var     NA     NA     NA    \n\n\nSince new_var and mother have R2=1, new_var provides no new information. R is programmed to recognize such cases (which are typically the result of a mistake by the modeler) and disregard the no-new-information variable. (This is indicated with NA.) With new_var no longer in the model, the mother coefficient returns to its value from the smaller of the nested models!"
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "",
    "text": "See Takeaways from Lesson 28 for a review of the last class. There, we introduced the term “covariate” to describe an explanatory variable that isn’t of direct interest but which might be important to how the system being modeled works.\nAdjusting for severity …\nThe effect size w.r.t. an explanatory variable is automatically adjusted for all the covariates."
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html#adjusting-for-age",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html#adjusting-for-age",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "Adjusting for age",
    "text": "Adjusting for age\n“Life tables” are compiled by governments from death certificates.\n\nLTraw <- readr::read_csv(\"life-table-raw.csv\")\n\nRows: 120 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): age, male, mnum, mlife_exp, female, fnum, flife_exp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nLT <- tidyr::pivot_longer(LTraw |> select(age, male, female), c(\"male\", \"female\"), names_to=\"sex\", values_to=\"mortality\")\n\nAge pyramids comparing the US population in 1972 and 2021\n\n\n\n\n\nQuestions:\n\nWhen were people aged 35-39 in 1972 born? Why are there so few of them?\nHow old would you have to be in 1972 to be part of the “baby boom?” Can you see the echo of the baby boom in 2021?\nHow many 85+ year-olds will there be in 2040?\n\nThe raw data:\n\n\nCode\nPop2020 <- readr::read_csv(\"nc-est2021-agesex-res.csv\",\n                           show_col_types=FALSE) |>\n  filter(SEX > 0, AGE<999) |>\n  mutate(sex = ifelse(SEX==1, \"female\", \"male\"), \n         age=AGE, pop=ESTIMATESBASE2020) |> \n  select(age, sex, pop)\n\n\n\nPop2020\n\n# A tibble: 202 × 3\n     age sex        pop\n   <dbl> <chr>    <dbl>\n 1     0 female 1907982\n 2     1 female 1928926\n 3     2 female 1980392\n 4     3 female 2028781\n 5     4 female 2068682\n 6     5 female 2081588\n 7     6 female 2072810\n 8     7 female 2069511\n 9     8 female 2086029\n10     9 female 2109096\n# … with 192 more rows\n\n\nUS mortality at actual age distribution:\n\nOverall <- Pop2020 |> left_join(LT)\n\nJoining, by = c(\"age\", \"sex\")\n\nOverall |> group_by(sex) |>\n  summarize(mortality = 100000*sum(pop*mortality)/sum(pop))\n\n# A tibble: 2 × 2\n  sex    mortality\n  <chr>      <dbl>\n1 female      708.\n2 male       1351.\n\n\nThe WHO standard age distribution\n\n\nCode\nRaw <- readr::read_csv(\"who-standard-age-distribution.csv\",\n                            show_col_types=FALSE)\nTmp <- Raw |> mutate(mid = (high+low)/2)\npopfun <- approxfun(Tmp$mid, Tmp$pop, yleft=8.860, yright=0.04)\nStandard <- tibble(\n  age = 0:99,\n  pop = popfun(age)\n)\nggplot(Standard, aes(xmin=-pop, xmax=pop, y=age)) + geom_ribbon(alpha=.3, aes(xmin=0), fill=\"green\") + \n  geom_ribbon(alpha=.3, aes(xmax=0), fill=\"blue\")  \n\n\n\n\n\nUS mortality at WHO standard age distribution:\n\nOverall <- Standard |> left_join(LT)\n\nJoining, by = \"age\"\n\nOverall |> group_by(sex) |>\n  summarize(mortality = 100000*sum(pop*mortality)/sum(pop))\n\n# A tibble: 2 × 2\n  sex    mortality\n  <chr>      <dbl>\n1 female      439.\n2 male        681."
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html#age-adjusted-death-rates-over-time",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html#age-adjusted-death-rates-over-time",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "Age-adjusted death rates over time",
    "text": "Age-adjusted death rates over time\nFrom the SSA (p. 15)"
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html#back-to-berkeley",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html#back-to-berkeley",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "Back to Berkeley",
    "text": "Back to Berkeley\n\nmod1 <- model_train(zero_one(admit, one=\"admitted\") ~ gender,\n                    data=UCB_applicants)\nmodel_plot(mod1, x=dept, color=gender, nlevels=10) +\n  ylab(\"Admitted\")\n\n\n\n\n\nmod2 <- model_train(zero_one(admit, one=\"admitted\") ~ gender*dept,\n                    data=UCB_applicants)\nmodel_plot(mod2, x=dept, color=gender, nlevels=10, data_alpha=0.1) +\n  ylab(\"Admitted\")\n\n\n\n\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.931 -0.830 -0.732\n2 gendermale   0.485  0.610  0.736\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender + dept, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 7 × 4\n  term          .lwr   .coef    .upr\n  <chr>        <dbl>   <dbl>   <dbl>\n1 (Intercept)  0.488  0.682   0.877 \n2 gendermale  -0.259 -0.0999  0.0582\n3 deptB       -0.258 -0.0434  0.172 \n4 deptC       -1.47  -1.26   -1.05  \n5 deptD       -1.50  -1.29   -1.09  \n6 deptE       -1.99  -1.74   -1.49  \n7 deptF       -3.65  -3.31   -2.98"
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html#for-lesson-30",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html#for-lesson-30",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "For Lesson 30?",
    "text": "For Lesson 30?\nShould we adjust for department? Let’s go to a DAG.\n\nUCB_dag1 <- dag_make(sex ~ exo(),\n                     dept ~ sex,\n                     admit ~ sex + dept)\ndag_draw(UCB_dag1, vertex.label.cex=1)\n\n\n\n\nIf we think that the connection sex \\(\\longrightarrow\\) department is just a matter of personal choice (as in the 1975 Science article), then we should block the back-door pathway.\nBut if we think that sex \\(\\longrightarrow\\) department reflects systemic issues such as which departments are considered important and get funding, or which careers women think they can succeed in, then we do not want to block the backdoor pathway.\n\nUCB_dag2 <- dag_make(sex ~ exo(),\n                     success ~ sex,\n                     funding ~ sex,\n                     dept ~ success,\n                     admit ~ sex + dept + funding)\ndag_draw(UCB_dag2, vertex.label.cex=1)"
  },
  {
    "objectID": "Worksheets/Worksheet-26.html",
    "href": "Worksheets/Worksheet-26.html",
    "title": "Lesson 26: Worksheet",
    "section": "",
    "text": "In this Worksheet you will draw the prediction and confidence intervals called for in the Intervals by Eye class activity.\nBut here you will draw the intervals by software. We will be using DAGs to generate the data. The three DAGs for the three models will be called dag_one, dag_two, and dag_three. They are defined in the next chunk, but the definitions are not important for your work, which will be based on data generated from the DAGs by sample().\nHere we generate the three data frames. There is one for each of the three DAGs. You can read off the size of the samples from the size argument."
  },
  {
    "objectID": "Worksheets/Worksheet-26.html#model-one",
    "href": "Worksheets/Worksheet-26.html#model-one",
    "title": "Lesson 26: Worksheet",
    "section": "Model One",
    "text": "Model One\nThe data in Samp_one represent a straight-line relationship between y and x. An appropriate model specification is therefore y ~ x.\nTrain y ~ x model on Samp_one. Then plot out the model using model_plot() with the argument interval=\"prediction\". Make another similar plot with interval=\"confidence\".\n\n# for your use\n\n\nHow many points are excluded from the prediction band? Since the prediction is being made at a 95% level, only about 5% of the points should be left out. Is this working.\nCompare the width of the confidence band at its narrowest point to the width of the prediction band. A rule of thumb is that these widths should be related by \\(1/\\sqrt{n}\\). Are they?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\nmod_one <- lm(y ~ x, data=Samp_one)\nmodel_plot(mod_one, interval=\"prediction\")\nmodel_plot(mod_one, interval=\"confidence\")\n\n\n\n\n\n\n\n\n\n\n\n\nThere are four data points excluded from the prediction interval. Since the sample size is \\(n=100\\), this is indeed close to the theoretical 5%. (If you repeat the analysis using a different value in set.seed(), you may get a different number.)\nThe “width” (actually, the height, since the interval is always in terms of the response variable) of the confidence interval is about 0.4 at its narrowest point. The width of the prediction interval is about 4. These are indeed related by \\(1/\\sqrt{n=100}\\)."
  },
  {
    "objectID": "Worksheets/Worksheet-26.html#model-2-a-sine-wave",
    "href": "Worksheets/Worksheet-26.html#model-2-a-sine-wave",
    "title": "Lesson 26: Worksheet",
    "section": "Model 2: A sine wave",
    "text": "Model 2: A sine wave\nThe data in Samp_two have a sine-wave pattern. We will not study models for such patterns in detail, even though they are important in a number of areas. For our purposes, use the model specification y ~ cos(x) + sin(x).\nAs in the previous section, train the model on the Samp_two data and use model_plot() to show both the prediction and confidence intervals.\n\nAre about 5% of the points excluded from the prediction band?\nDoes the width of the confidence interval (at it’s narrowest point) have the rule-of-thumb \\(1/\\sqrt{n}\\) relationship to the width of the prediction interval?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\nmod_two <- lm(y ~ sin(x), data=Samp_two)\nmodel_plot(mod_two, interval=\"prediction\")\nmodel_plot(mod_two, interval=\"confidence\")\n\n\n\n\n\n\n\n\n\n\n\n\nI count 18 points outside the prediction interval, although there are a few cases where it’s hard to tell. The sample has size \\(n=400\\). 5% of 400 is 20, which is very close to the number observed.\nThe “width” of the prediction interval is a little more than 3. It’s hard to read from the graph the width of the confidence interval at its narrowest point, but it is much less than one.\n\nWe can calculate the width by using model_eval(). The x value at the narrowest point is \\(\\mathtt{x}=\\pi\\).\n\nmodel_eval(mod_two, x=pi, interval=\"confidence\")\n\n\n\n \n  \n    x \n    .output \n    .lwr \n    .upr \n  \n \n\n  \n    3.14 \n    3.04 \n    2.94 \n    3.14 \n  \n\n\n\nmodel_eval(mod_two, x=pi, interval=\"prediction\")\n\n\n\n \n  \n    x \n    .output \n    .lwr \n    .upr \n  \n \n\n  \n    3.14 \n    3.04 \n    1.19 \n    4.89 \n  \n\n\n\n\nThe prediction interval has width 3.7, the confidence interval has width 0.2. This is quite close to the value suggested by the rule of thumb, which gives \\(3.7/\\sqrt{400} = 0.185\\)."
  },
  {
    "objectID": "Worksheets/Worksheet-26.html#model-three",
    "href": "Worksheets/Worksheet-26.html#model-three",
    "title": "Lesson 26: Worksheet",
    "section": "Model three",
    "text": "Model three\nUse the model specification y ~ x + group for your model. Train the model using Samp_three then answer the same questions about the number of excluded points from the prediction interval and the relative width of the prediction and confidence intervals.\n\n\n\n\n\n\nAnswer\n\n\n\n\nmod_three <- lm(y ~ x + group, data=Samp_three)\nmodel_plot(mod_three, interval=\"prediction\")\nmodel_plot(mod_three, interval=\"confidence\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe count of excluded points needs to be made separately for the points in group A and the points in group B. It looks like about 4 group A points have been exclude and 3 group B points. Since there are 100 points in each group, this is roughly 5%.\nThe “width” of the prediction interval is about 5.6. (See the calculations below.) The width of the confidence intervals is about 0.5-0.6. With 100 points in each group, this is consistent with the rule of thumb.\n\n\nmodel_eval(mod_three, x=5, group=c(\"group A\", \"group B\"),\n           interval=\"prediction\")\n\n\n\n \n  \n    x \n    group \n    .output \n    .lwr \n    .upr \n  \n \n\n  \n    5 \n    group A \n    21 \n    18.00 \n    24 \n  \n  \n    5 \n    group B \n    11 \n    8.02 \n    14 \n  \n\n\n\nmodel_eval(mod_three, x=5, group=c(\"group A\", \"group B\"),\n           interval=\"confidence\")\n\n\n\n \n  \n    x \n    group \n    .output \n    .lwr \n    .upr \n  \n \n\n  \n    5 \n    group A \n    21 \n    20.7 \n    21.3 \n  \n  \n    5 \n    group B \n    11 \n    10.7 \n    11.3 \n  \n\n\n\n\nThe prediction interval has width 6, the confidence interval has width 0.6. This is quite close to the value suggested by the rule of thumb, which gives \\(3.7/\\sqrt{100} = 0.185\\)."
  },
  {
    "objectID": "Day-by-day/Lesson-29/adjusting-activity.html#adjusting-visually",
    "href": "Day-by-day/Lesson-29/adjusting-activity.html#adjusting-visually",
    "title": "Spring 2023 Math 300Z",
    "section": "Adjusting, visually",
    "text": "Adjusting, visually\nThese are two graphs of the data from Clock_auction showing the relationship between the winning price and the number of bidders. (I’ve simplified the number of bidders to two categories.) The age of the clock is a covariate. The large dots show the mean age and mean price of the clocks in those auctions with 10 or more bidders versus 9 or fewer bidders.\n\n\nCode\nClock_auction <- Clock_auction |> mutate(nbidders = ifelse(bidders >= 10, \"10 or more\", \"9 or fewer\"))\nStats <- Clock_auction |> group_by(nbidders) |>\n  summarize(mp = mean(price), mage = mean(age))\n\n\n\nmod1 <- lm(price ~ nbidders, data=Clock_auction) \n\nmodel_plot(mod1, x=age, color=nbidders) |>\n  gf_point(mp ~ mage, color=~nbidders, data=Stats, size=3)\n\n\n\n\nPart A. In the model without age as a covariate, what is the difference in mean prices for the 10-or-more-bidders group versus the 9-or-fewer-bidders group?\nPart B. Now the picture when including age as a covariate. Adjusting for age, what is the difference in mean prices for the 10-or-more-bidders group versus the 9-or-fewer-bidders group?\n\nmod2 <- lm(price ~ nbidders + age, data=Clock_auction) \n\nmodel_plot(mod2, x=age, color=nbidders) |>\n  gf_point(mp ~ mage, color=~nbidders, data=Stats, size=3)\n\n\n\n\nPart C. Here are confidence intervals for the two models graphed above. Explain what about these coefficients matches the conclusions you got in Parts (A) and (B)?\n\nmod1 |> conf_interval()\n\n# A tibble: 2 × 4\n  term                .lwr .coef   .upr\n  <chr>              <dbl> <dbl>  <dbl>\n1 (Intercept)        1226. 1420  1614. \n2 nbidders9 or fewer -479. -221.   37.1\n\nmod2 |> conf_interval()\n\n# A tibble: 3 × 4\n  term                  .lwr  .coef   .upr\n  <chr>                <dbl>  <dbl>  <dbl>\n1 (Intercept)        -467.    -56.3  354. \n2 nbidders9 or fewer -490.   -336.  -182. \n3 age                   7.79   10.6   13.5\n\n\n\nThis activity was inspired by schematic diagrams in Milo Schield’s Statistical Literacy: Seeing the story behind the statistics, 2011, pp. 224-5."
  },
  {
    "objectID": "Day-by-day/Lesson-29/Teaching-notes-29.html#class-activity",
    "href": "Day-by-day/Lesson-29/Teaching-notes-29.html#class-activity",
    "title": "Instructor Teaching Notes for Lesson 29",
    "section": "Class activity",
    "text": "Class activity"
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "",
    "text": "Deniers of a smoking/cancer link claimed there was a common cause for both: a “cancer gene.”\n\n\n\n\n\n   \n\nSmoking\n\nSmoking   \n\nLung cancer\n\nLung cancer   \n\nSmoking->Lung cancer\n\n    \n\nSmoking gene\n\nSmoking gene   \n\nSmoking gene->Smoking\n\n    \n\nSmoking gene->Lung cancer\n\n   \n\n\n\n\n\nThe gene had not been identified, so no data could be collected on it.\nThis is an example of confounding: the effects of the (supposed) gene and of smoking are mixed together."
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html#back-to-berkeley",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html#back-to-berkeley",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "Back to Berkeley",
    "text": "Back to Berkeley\nShould we adjust for department? Let’s go to a DAG.\n\nUCB_dag1 <- dag_make(sex ~ exo(),\n                     dept ~ sex,\n                     admit ~ sex + dept)\ndag_draw(UCB_dag1, vertex.label.cex=1)\n\n\n\n\nIf we think that the connection sex \\(\\longrightarrow\\) department is just a matter of personal choice (as in the 1975 Science article), then we should block the back-door pathway.\nBut if we think that sex \\(\\longrightarrow\\) department reflects systemic issues such as which departments are considered important and get funding, or which careers women think they can succeed in, then we do not want to block the backdoor pathway.\n\nUCB_dag2 <- dag_make(sex ~ exo(),\n                     success ~ sex,\n                     dept_funding ~ sex,\n                     dept ~ success,\n                     admit ~ sex + dept + dept_funding)\ndag_draw(UCB_dag2, vertex.label.cex=1)"
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html#birthweight-collider",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html#birthweight-collider",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "Birthweight collider",
    "text": "Birthweight collider\nObservations from the 1960s:\n\nSmoking is associated with lower birthweight\nLower birthweight is associated with increased mortality\n\nQuestion: Does smoking have a direct effect on mortality?\n\n\n\n\n\n\n\nH\n\n  \n\nSmoking\n\nSmoking   \n\nBirth weight\n\nBirth weight   \n\nSmoking->Birth weight\n\n    \n\nMortality of infant\n\nMortality of infant   \n\nSmoking->Mortality of infant\n\n   ?   \n\nBirth weight->Mortality of infant\n\n   \n\n\n\n\n\nHow do you look at the direct effect of smoking on mortality? Block the other pathway by using birth weight as a covariate.\nWhen this was done, by looking only at low-birthweight babies, it was found that smoking reduces mortality.\nMight there be something else going on? Is there another cause for low birthweight?\n\n\n\n\n\n\n\nJ\n\n  \n\nBirth defect\n\nBirth defect   \n\nBirth weight\n\nBirth weight   \n\nBirth defect->Birth weight\n\n    \n\nMortality of infant\n\nMortality of infant   \n\nBirth defect->Mortality of infant\n\n    \n\nSmoking\n\nSmoking   \n\nSmoking->Birth weight\n\n    \n\nSmoking->Mortality of infant\n\n    \n\nBirth weight->Mortality of infant"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#simple-causal-paths",
    "href": "Day-by-day/Lesson-30/simple-paths.html#simple-causal-paths",
    "title": "Spring 2023 Math 300Z",
    "section": "Simple causal paths",
    "text": "Simple causal paths"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#mediator",
    "href": "Day-by-day/Lesson-30/simple-paths.html#mediator",
    "title": "Spring 2023 Math 300Z",
    "section": "Mediator",
    "text": "Mediator\n\n\n\n\n\n   \n\nA\n\nA   \n\nB\n\nB   \n\nA->B\n\n    \n\nC\n\nC   \n\nB->C\n\n   \n\n\n\n\n\n\nTo see the full path from A to C, should you include B as a covariate?\nTo observe the relationship A \\(\\rightarrow\\) B, should you include C as a covariate?\nTo observe the relationship B \\(\\rightarrow\\) C, should you include A as a covariate?\n\n\nmediator <- dag_make(\n  A ~ exo(),\n  B ~ 2.5*A + exo(),\n  C ~ -1.2*B + exo()\n)\nSamp <- sample(mediator, size=1000)\n\n\n# Question 1\nlm(C ~ A, data=Samp) |> conf_interval()\nlm(C ~ A + B, data=Samp) |> conf_interval()\n\n\n# Question 2\nlm(B ~ A, data=Samp) |> conf_interval()\nlm(B ~ A + C, data=Samp) |> conf_interval()\n\n\n# Question 3\nlm(C ~ B, data=Samp) |> conf_interval()\nlm(C ~ B + A, data=Samp) |> conf_interval()"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#common-cause",
    "href": "Day-by-day/Lesson-30/simple-paths.html#common-cause",
    "title": "Spring 2023 Math 300Z",
    "section": "Common cause",
    "text": "Common cause\n\n\n\n\n\n   \n\nB\n\nB   \n\nC\n\nC   \n\nB->C\n\n    \n\nA\n\nA   \n\nA->C\n\n   \n\n\n\n\n\n\ncommon_cause <- dag_make(\n  A ~ exo(),\n  B ~ exo(),\n  C ~ 5*B - 2*A + exo()\n)\nSamp <- sample(common_cause, size=1000)\n\n\nTo see the direct relationship between A and C, should you include B as a covariate?\nTo see the relationship between B and A, should you include C as a covariate?\n\n\n# Question 1\nlm(C ~ A, data=Samp) |> conf_interval()\nlm(C ~ A + B, data=Samp) |> conf_interval()\n\n\n# Question 2\nlm(A ~ B, data=Samp) |> conf_interval()\nlm(A ~ B + C, data=Samp) |> conf_interval()"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#contributing-causes",
    "href": "Day-by-day/Lesson-30/simple-paths.html#contributing-causes",
    "title": "Spring 2023 Math 300Z",
    "section": "Contributing causes",
    "text": "Contributing causes\n\n\n\n\n\n   \n\nA\n\nA   \n\nC\n\nC   \n\nA->C\n\n    \n\nB\n\nB   \n\nB->C\n\n   \n\n\n\n\n\n\ncontrib_causes <- dag_make(\n  B ~ exo(),\n  A ~ exo(),\n  C ~ -2*B + 3*A + exo()\n)\nSamp <- sample(contrib_causes, size=1000)\n\n\nTo see the effect of B on C, do you need to include A as a covariate?\n\n\n\n# A tibble: 2 × 4\n  term           .lwr  .coef   .upr\n  <chr>         <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.0643  0.127  0.317\n2 B           -2.23   -2.04  -1.85 \n\n\n# A tibble: 3 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) -0.0424  0.0199  0.0822\n2 B           -2.05   -1.99   -1.93  \n3 A            2.93    2.99    3.06  \n\n\n\nWhich model has the better confidence interval on B?"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#collider",
    "href": "Day-by-day/Lesson-30/simple-paths.html#collider",
    "title": "Spring 2023 Math 300Z",
    "section": "Collider",
    "text": "Collider\nSame network as contributing causes, but focussing on relationship between A & B.\n\nTo see the correct (lack of) relationship between A and B, should you include C as a covariate?\n\n\n\n# A tibble: 2 × 4\n  term           .lwr   .coef   .upr\n  <chr>         <dbl>   <dbl>  <dbl>\n1 (Intercept) -0.0246  0.0356 0.0959\n2 B           -0.0768 -0.0158 0.0451\n\n\n# A tibble: 3 × 4\n  term           .lwr    .coef   .upr\n  <chr>         <dbl>    <dbl>  <dbl>\n1 (Intercept) -0.0218 -0.00216 0.0175\n2 B            0.569   0.593   0.617 \n3 C            0.292   0.299   0.305"
  },
  {
    "objectID": "Day-by-day/Lesson-30/simple-paths.html#confounder",
    "href": "Day-by-day/Lesson-30/simple-paths.html#confounder",
    "title": "Spring 2023 Math 300Z",
    "section": "Confounder",
    "text": "Confounder\n\n\n\n\n\n   \n\nA\n\nA   \n\nC\n\nC   \n\nA->C\n\n    \n\nB\n\nB   \n\nA->B\n\n    \n\nB->C\n\n   \n\n\n\n\n\n\nconfounder <- dag_make(\n  A ~ exo(),\n  B ~ 4*A + exo(),\n  C ~ 2*A  + 0.5*B + exo()\n)\nSamp <- sample(confounder, size=1000)\n\n\nTo see the correct direct connection between B and C, should you include A as a confounder?\n\n\nlm(C ~ B, data=Samp) |> conf_interval()\nlm(C ~ B + A, data=Samp) |> conf_interval()"
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html#discovering-the-rules-for-small-dags",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html#discovering-the-rules-for-small-dags",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "Discovering the rules for small DAGs",
    "text": "Discovering the rules for small DAGs\nClass activity"
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html#more-complex-dags",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html#more-complex-dags",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "More complex DAGs",
    "text": "More complex DAGs\nIn considering the relationship between two nodes, enumerate each of the paths that connect the two nodes.\nExample: Smoking with a non-genetic mediator: Tar\nThere are two paths from Tar to Lung cancer:\n\n\n\n\n\n   \n\nSmoking gene\n\nSmoking gene   \n\nLung cancer\n\nLung cancer   \n\nSmoking gene->Lung cancer\n\n    \n\nSmoking\n\nSmoking   \n\nSmoking gene->Smoking\n\n  Path 2   \n\nTar\n\nTar   \n\nSmoking->Tar\n\n    \n\nTar->Lung cancer\n\n  Path 1  \n\n\n\n\n\nTwo types of path between two endpoint nodes:\n\nA correlating path: Starting from some node on the path, causal influence can flow (along the arrows) to both endpoints.\n\nBLOCK a correlating path by using some node along it as a covariate. Otherwise, it’s open.\n\nA colliding path: There’s no node on the path from which causal influence can flow (along the arrows) to both endpoints.\n\nOPEN a colliding path by using the collider as a covariate. Otherwise, it’s closed.\n\none <- dag_make(\n  A ~ exo(),\n  B ~ A + exo(),\n  D ~ A + exo(), \n  C ~ B + D +exo()\n)\ndag_draw(one)\n\n\n\nSamp <- sample(one, size=1000)\n\n\nlm(D ~ A, data=Samp) |> conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr    .coef   .upr\n  <chr>         <dbl>    <dbl>  <dbl>\n1 (Intercept) -0.0665 -0.00368 0.0591\n2 A            0.950   1.01    1.07  \n\nlm(D ~ A + B, data=Samp) |> conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr    .coef   .upr\n  <chr>         <dbl>    <dbl>  <dbl>\n1 (Intercept) -0.0666 -0.00373 0.0591\n2 A            0.927   1.01    1.10  \n3 B           -0.0654 -0.00292 0.0596\n\nlm(D ~ A + C, data=Samp) |> conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr  .coef   .upr\n  <chr>         <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.0270 0.0243 0.0757\n2 A            0.299  0.374  0.449 \n3 C            0.297  0.325  0.354 \n\nlm(D ~ A + B + C, data=Samp) |> conf_interval()\n\n# A tibble: 4 × 4\n  term           .lwr   .coef    .upr\n  <chr>         <dbl>   <dbl>   <dbl>\n1 (Intercept) -0.0162  0.0283  0.0728\n2 A            0.484   0.552   0.620 \n3 B           -0.554  -0.500  -0.446 \n4 C            0.456   0.486   0.516 \n\n\n\none <- dag_make(\n  A ~ exo(),\n  E ~ 10*C + exo(),\n  B ~ A + exo(),\n  D ~ A + exo(), \n  C ~ B + D +exo()\n)\ndag_draw(one)\n\n\n\nSamp <- sample(one, size=1000)\nlm(D ~ A, data=Samp) |> conf_interval()\n\n# A tibble: 2 × 4\n  term           .lwr   .coef   .upr\n  <chr>         <dbl>   <dbl>  <dbl>\n1 (Intercept) -0.0804 -0.0196 0.0413\n2 A            0.916   0.976  1.04  \n\nlm(D ~ A + C, data=Samp) |> conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr   .coef   .upr\n  <chr>         <dbl>   <dbl>  <dbl>\n1 (Intercept) -0.0791 -0.0295 0.0202\n2 A            0.221   0.298  0.375 \n3 C            0.313   0.343  0.373 \n\nlm(D ~ A + E, data=Samp) |> conf_interval()\n\n# A tibble: 3 × 4\n  term           .lwr   .coef   .upr\n  <chr>         <dbl>   <dbl>  <dbl>\n1 (Intercept) -0.0763 -0.0266 0.0231\n2 A            0.224   0.301  0.378 \n3 E            0.0311  0.0341 0.0371\n\n\n\nCan Tar be used to avoid the confounding due to genetics? How do you block the back-door pathway?\n\n\n\n\n\n\n## The Berkeley graduate admissions data from 1973\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- model_train(zero_one(admit, one=\"admitted\") ~ gender,\n                    data=UCB_applicants)\nmodel_plot(mod1, x=dept, color=gender, nlevels=10) +\n  ylab(\"Admitted\")\n\n\n\n:::\n\nmod2 <- model_train(zero_one(admit, one=\"admitted\") ~ gender*dept,\n                    data=UCB_applicants)\nmodel_plot(mod2, x=dept, color=gender, nlevels=10, data_alpha=0.1) +\n  ylab(\"Admitted\")\n\n\n\n\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.931 -0.830 -0.732\n2 gendermale   0.485  0.610  0.736\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender + dept, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 7 × 4\n  term          .lwr   .coef    .upr\n  <chr>        <dbl>   <dbl>   <dbl>\n1 (Intercept)  0.488  0.682   0.877 \n2 gendermale  -0.259 -0.0999  0.0582\n3 deptB       -0.258 -0.0434  0.172 \n4 deptC       -1.47  -1.26   -1.05  \n5 deptD       -1.50  -1.29   -1.09  \n6 deptE       -1.99  -1.74   -1.49  \n7 deptF       -3.65  -3.31   -2.98"
  },
  {
    "objectID": "Day-by-day/Lesson-30/Teaching-notes-30.html#the-berkeley-graduate-admissions-data-from-1973",
    "href": "Day-by-day/Lesson-30/Teaching-notes-30.html#the-berkeley-graduate-admissions-data-from-1973",
    "title": "Instructor Teaching Notes for Lesson 30",
    "section": "The Berkeley graduate admissions data from 1973",
    "text": "The Berkeley graduate admissions data from 1973\n\nmod1 <- model_train(zero_one(admit, one=\"admitted\") ~ gender,\n                    data=UCB_applicants)\nmodel_plot(mod1, x=dept, color=gender, nlevels=10) +\n  ylab(\"Admitted\")\n\n\n\n\n\nmod2 <- model_train(zero_one(admit, one=\"admitted\") ~ gender*dept,\n                    data=UCB_applicants)\nmodel_plot(mod2, x=dept, color=gender, nlevels=10, data_alpha=0.1) +\n  ylab(\"Admitted\")\n\n\n\n\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 2 × 4\n  term          .lwr  .coef   .upr\n  <chr>        <dbl>  <dbl>  <dbl>\n1 (Intercept) -0.931 -0.830 -0.732\n2 gendermale   0.485  0.610  0.736\n\nmodel_train(zero_one(admit, one=\"admitted\") ~ gender + dept, \n            data=UCB_applicants) |> conf_interval()\n\nWaiting for profiling to be done...\n\n\n# A tibble: 7 × 4\n  term          .lwr   .coef    .upr\n  <chr>        <dbl>   <dbl>   <dbl>\n1 (Intercept)  0.488  0.682   0.877 \n2 gendermale  -0.259 -0.0999  0.0582\n3 deptB       -0.258 -0.0434  0.172 \n4 deptC       -1.47  -1.26   -1.05  \n5 deptD       -1.50  -1.29   -1.09  \n6 deptE       -1.99  -1.74   -1.49  \n7 deptF       -3.65  -3.31   -2.98"
  }
]