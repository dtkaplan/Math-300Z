{
  "hash": "15756229d843f08c6c0460337d33cbbd",
  "result": {
    "markdown": "---\ntitle: \"Math 300 Lesson 21 Notes\"\nsubtitle: \"Signal and noise\"\nauthor: \"YOUR NAME HERE\"\ndate: \"December, 2022\"\noutput:\n  pdf_document:\n    toc: yes\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n---\n\n\n\n\n## Overview\n\nIn accounting for the variation in a response variable `y`, we conceive of `y` as being a combination of signal and noise. The signal is defined by a model specification, for instance `y ~ x + c`. Different model specifications correspond to different definitions of what is signal. The noise is defined as all the variation in `y` that is not signal. \n\n### Reading \n\n[Lesson **21** from *LST*](https://dtkaplan.github.io/Math-300R/Textbook/Reading-notes-lesson-21.html)\n\n\n\n### Objectives\n\n21.1 Use model training to separate signal from noise in a response variable. \n\n21.2 Recognize that the same training data will show a different signal depending on what model specification is used. \n\n\n\n[Updated list of objectives](../Objectives/Obj-lesson-21.html)\n\n### Libraries \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaic)\nlibrary(math300)\n```\n:::\n\n\n--------\n\n\nLesson \n--------\n\nA regression model separates the response variable into two components: the signal and the noise. Exactly what constitutes the signal is determined by the model specification. In this Lesson, we'll track variation as it is pushed down the causal links in a DAG and observe how fitting a model to data from the DAG separates signal from noise.\n\n### Exercise 1\n\nWe start with a simple DAG consisting of two elements, each of which is formed entirely of noise:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nex1_dag <- dag_make(\n  x ~ exo(1.0) - 2,\n  y ~ exo(2.5) + 4\n)\n```\n:::\n\n\nThe `exo()` function generates exogenous noise. The argument to `exo()` sets the magnitude of the noise\n\n#### Task 1.1\n\nDraw a picture of `ex1_dag` to confirm that node `x` is not causally connected to node `y`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Draw a picture of `ex1_dag`.\n```\n:::\n\n\nGenerate a sample data from `ex1_dag` with a few hundred rows and wrangle it to display the variance of `x` and the variance of `y`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample(ex1_dag = 500) %>%\n#  summarize(vx = _______, vy = _______)\n```\n:::\n\n\nBased on the calculated variances, say whether the argument to `exo()` sets the standard deviation or the variance of the exogenous noise.\n\n*Your answer*:\n\nEven though `x` and `y` are not causally connected in `ex1_dag`, train a model with the specification `y ~ x` to a sample from `ex1_dag` and examine the coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mod1.1 <- lm(y ~ x, data=sample(ex1_dag, size=500))\n# coefficients(mod1.1)\n```\n:::\n\n\nExamine the coefficients you just calculated and describe what about them suggests that `x` and `y` are not causally connected. (If you're not sure, increase the sample size by a factor of 10.)\n\n*Your answer*:\n\n#### Task 1.2\n\nThe code in the next chunk evaluates the model `mod1.1` for each row in the training data, producing a data frame. There are three columns we want to look at: `.response`, `.output`, `.resid`. Using wrangling, calculate the variance of each of these columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model_eval(mod1.1) %>%\n#   summarize(var(.response), var(.output), var(.resid))\n```\n:::\n\n\nThe `.response` column is simply the response variable of the training data. It is a combination of signal plus noise. The `.output` column is an estimate of the signal. The `.resid` column is an estimate of the noise.\n\nAccording to the model `mod1.1`, how much signal is in the response variable?\n\n*Your answer*:\n\nNOTE: You might wonder why any signal shows up at all, since `ex1_dag` doesn't have any connection between `x` and `y`. The reason is sampling variation, which produces accidental alignments between `x` and `y` even if they are not connected. We will explore sampling variation more thoroughly in Lessons 22 and 23.\n\n#### Task 1.3\n\nThere's an even simpler model specification that we can try on the data from `ex1_dag`, the specification `y ~ 1`. This specification will separate signal from noise assuming that there are no influences on `y`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mod1.3 <- lm(y ~ 1, data=sample(ex1_dag, size=500))\n# coefficients(mod1.3)\n```\n:::\n\n\nAgain, we can evaluate `mod1.3` on the training data and observe the magnitudes of the signal and the noise components of `y` (according to the model specification).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model_eval(mod1.3) %>%\n#   summarize(var(.response), var(.output), var(.resid))\n```\n:::\n\n\nExplain from the calculated variance how `y ~ 1` specifies the division of `y` into signal plus noise.\n\n*Your answer*:\n\n### Exercise 2\n\nWe will turn now to a slightly more complicated DAG: `dag01`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_draw(dag01)\n```\n\n::: {.cell-output-display}\n![](Student-notes-lesson-21_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(dag01)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx ~ exo()\ny ~ 1.5 * x + 4 + exo()\n```\n:::\n:::\n\n\nPay close attention to the formula for `y`. It says that `y` is composed from `x` plus some exogenous noise, plus 5. (`exo()` sets its argument to 1.0 by default.)\n\n#### Task 2.1\n\nGenerate a sample of a few hundred rows from `dag01` and wrangle it to calculate the variance of `y` and of `x`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For task 2.1\n```\n:::\n\n\nHow can you tell from the results that `exo()` generates exogenous noise with a standard deviation of 1. (OK, so it's not exactly 1. That's due to sampling variation, once again!)\n\n*Your answer*:\n\nLook now at the variance of `y` and at the formula that generated `y`, that is, `1.5*x + 4 + exo()`. This means that the variance of `y` is the sum of the variance of `1.5*x` (the signal) and the variance of `exo()` (the noise). The constant `4` does not generate any variability.\n\nThe question of the moment is, \"What is the variance of `1.5 * x`?\" You can answer the question by going back to the previous code chunk, and where you had `var(x)` in the `summarize()` function, change it to `var(1.5 * x)`? \n\nThere is a pretty simple relationship between `var(x)` and `var(1.5 * x)`. What is it? (If you can't see the relationship clearly, go back and change the sample size to be ten or one-hundred times larger.)\n\n*Your answer*:\n\n#### Task 2.2\n\nThe model specification `y ~ x` will separate `y` into signal and noise, putting into the signal only that part of the variation in `y` that comes from `x`. NOTE CAREFULLY that in a model specification, you do not put in numbers such as 1.5. Training the model to the specification will find such numbers for you; those are the coefficients. The right-hand side of the specification simply contains the *names* of the explanatory variables you want to include in the signal.\n\nUse a sample of a few hundred rows from `dag01` to train a model, call it `mod2.2` to the specification `y ~ x`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2.2 <- lm(y ~ x, data=sample(dag01, size=500))\n```\n:::\n\n\nLook at the coefficients and say whether they are appropriate, given the `dag01` formula for `y`.\n\n*Your answer*:\n\nEvaluate `mod2.2` on the training data and calculate the variances of the `.response`, `.output` and `.resid` columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_eval(mod2.2) %>%\n  summarize(var(.response), var(.output), var(.resid))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing training data as input to model_eval().\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n  var(.response) var(.output) var(.resid)\n1       3.010932     2.126415   0.8845164\n```\n:::\n:::\n\n\nHow much variance did the specification `y ~ x` assign to the signal and how much to the noise?\n\n#### Task 2.3\n\nRepeat Task 2.2 but for the model specification `y ~ 1`. This specification insists that `y` does not have any influence from `x`. Determine how big the signal is and how big the noise is. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mod2.3 <- lm(y ~ 1, data=sample(dag01, size=500))\n# model_eval(mod2.3) %>%\n#   summarize(var(.response), var(.output), var(.resid))\n```\n:::\n\n\nWhat happens when the specification conflicts with the actual mechanism? Who wins?\n\n*Your answer*:\n\n### Exercise 3\n\nNow we will work with a different DAG, `dag02`, where `y` is influence by two variables, `x` and `a`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_draw(dag02)\n```\n\n::: {.cell-output-display}\n![](Student-notes-lesson-21_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(dag02)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx ~ exo()\na ~ exo()\ny ~ 3 * x - 1.5 * a + 5 + exo()\n```\n:::\n:::\n\n\n#### Task 3.1\n\na. How much variance is contributed to `y` by the `3 * x` term in the DAG formula?\n\n*Your answer:*\n\nb. How much variance is contributed to `y` by the `-1.5*a` term in the DAG formula?\n\n*Your answer:*\n\n#### Task 3.2\n\nConsider these four model specifications, each of which divides `y` into signal and noise in its own way:\n\ni. `y ~ 1`\nii. `y ~ x`\niii. `y ~ a`\niv. `y ~ x + a`\n\na. Which model specification, (ii) or (iii), extracts a signal with a bigger variance?\n\n*Your answer*:\n\nb. Which model specification extracts a signal with the biggest variance of all?\n\n*Your answer*:\n\n",
    "supporting": [
      "Student-notes-lesson-21_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}