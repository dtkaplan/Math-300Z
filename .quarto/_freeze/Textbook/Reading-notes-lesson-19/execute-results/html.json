{
  "hash": "28a121334a191cd3e3c83bc31876e72c",
  "result": {
    "markdown": "# Preliminaries\n\n\n---\nstatus: \"proofed on Nov 28, 2022\"\n---\n\n\n\n\n\nThis Lesson covers some preliminaries: techniques we use throughout the remaining lessons. \n\n1. Using regression to summarize relationships.\n2. The presentation of descriptions using **intervals** rather than a number like the mean or proportion.\n3. Promotion of the point plot (sometimes jittered) as the standard form for displaying data. Statistical summaries appear as annotations on top of the data layer.\n4. A modern format called a \"**violin plot**\" for displaying the *distribution* of a quantitative variable. Unlike a histogram, the violin plot can be layered as an annotation on top of a point plot.\n5. Extending regression modeling to handle *categorical* response variables.\n\n\n## Regression as a data summary\n\nThe first half of this course emphasized data wrangling and visualization. The well-named `summarize()` function is the natural wrangling choice to compute summaries such as means, medians, or standard deviations. For instance, this command calculates four summary statistics on the `net` running time recorded in the `TenMileRace` data frame:\n\n::: {.column-page-right}\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>%\n  summarize(ave = mean(net), middle = median(net), sd = sd(net), n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       ave middle       sd    n\n1 5599.065   5555 969.6564 8636\n```\n:::\n:::\n\n:::\n\n`summarize()` works hand-in-hand with `group_by()` to calculate groupwise summaries. The following wrangling statement, for instance, looks at the average `net` running time broken up according to the runner's state of residence and presents the results from the fastest state downwards:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>%\n  group_by(state) %>%\n  summarize(ave = mean(net), middle = median(net), sd = sd(net), n = n()) %>%\n  arrange(ave) %>%\n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 5\n   state       ave middle    sd     n\n   <fct>     <dbl>  <dbl> <dbl> <int>\n 1 Australia 2872   2872    NA      1\n 2 Kenya     2934.  2874.  141.    14\n 3 Lithuania 2961   2961    NA      1\n 4 Japan     2992   2992   132.     2\n 5 Colombia  2998   2998    NA      1\n 6 Ethiopia  3185   3185   356.     2\n 7 EN        3251   3251    NA      1\n 8 Ukraine   3256   3256    NA      1\n 9 Russia    3267   3197   272.     3\n10 Romania   3287.  3297   162.     3\n```\n:::\n:::\n\n\nWrangling is essential for many statistical purposes, not just summarizing but also setting up for making graphical displays, cleaning data, and assembling data from multiple sources. \n\nRegression modeling is used only for summarizing. The summary describes the *relationship* between the response and explanatory variables. Think of it as a kind of substitute for `summarize()` when you want to describe relationships. \n\nAs we saw above, `summarize()` and `group_by()` are two different stages of wrangling that, used together, produce a separate summary for each group. Regression modeling, however, offers a rich alternative to grouping. The spirit of what one accomplishes in wrangling with `group_by()` is achieved in regression by *using additional explanatory variables*. \n\n::: {.callout-note}\n## The mean as summary\n\nIn its simplest mode, a regression can calculate means. The result will be identical to `group_by()`/`summarize()` but in a different format.\n\nHere is the mean `net` running time calculated using both approaches.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ 1, data=.) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   5599.065 \n```\n:::\n\n```{.r .cell-code}\nTenMileRace %>% summarize(mn = mean(net))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        mn\n1 5599.065\n```\n:::\n:::\n\n\n[Notice something new in the above command: the `data=.` argument inside `lm()`. The simple `.` is doing something important, carrying the output of the earlier stages of the pipeline into the `data=` argument of `lm()`.]{.aside}\n\nThe groupwise calculations also produce equivalent results, although the results are formatted in different ways.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ sex, data=.) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        sexM \n  5916.3979   -635.6958 \n```\n:::\n\n```{.r .cell-code}\nTenMileRace %>% group_by(sex) %>%summarize(mn = mean(net))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  sex      mn\n  <fct> <dbl>\n1 F     5916.\n2 M     5281.\n```\n:::\n:::\n\nRegression of this sort calculates the mean of a reference group and the **difference in means** between the two groups, whereas the wrangling command presents the mean of each group.\n:::\n\nIn regression, \"grouping\" is extended to quantitative variables. For instance,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ age, data = .) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)         age \n5297.219248    8.189886 \n```\n:::\n:::\n\nThis report indicates a trend of `net` running time increasing with `age` by about 8 seconds per year.\n\nThe `group_by()` function can use a quantitative variable, but the result is a different number for each group rather than a trend.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% group_by(age) %>% summarize(mn = mean(net)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 68 × 2\n     age    mn\n   <int> <dbl>\n 1    10 5635 \n 2    12 5978 \n 3    13 5405.\n 4    14 5620.\n 5    15 5166.\n 6    16 5522.\n 7    17 5716.\n 8    18 5259.\n 9    19 4573 \n10    20 5218.\n# … with 58 more rows\n```\n:::\n:::\n\n\nWith multiple grouping variables, say `age` and `sex`, the output of `summarize()` becomes increasingly complicated. For example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% group_by(sex, age) %>% summarize(mn = mean(net)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 127 × 3\n# Groups:   sex [2]\n   sex     age    mn\n   <fct> <int> <dbl>\n 1 F        10 5635 \n 2 F        13 6831 \n 3 F        14 5941.\n 4 F        15 4854 \n 5 F        16 5678.\n 6 F        17 6011.\n 7 F        18 5720.\n 8 F        19 5285.\n 9 F        20 5970.\n10 F        21 6057.\n# … with 117 more rows\n```\n:::\n:::\n\n\nRegression keeps things simpler, reporting on trends:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ sex + age, data = .) %>% coefficients() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        sexM         age \n 5339.15545  -726.61948    16.89362 \n```\n:::\n:::\n\n\nThe trend reported from this regression model is an increase in `net` of about 16 seconds per year of age. Regression can summarize relationships in more detailed ways as well. The following model looks at the trend with age separately for males and females:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ sex * age, data = .) %>% coefficients() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        sexM         age    sexM:age \n5370.999953 -785.145163   15.961661    1.606559 \n```\n:::\n:::\n\n\nHere, the age trend for women is an increase in `net` running time of 16 seconds per year of age, while for men, that increase is bigger, an extra 1.6 seconds per year of age.\n\nThere are good reasons why `lm()` organizes summaries the way it does. The `lm()` paradigm can make much more efficient use of data than `group_by()`. It also offers much more flexibility. `lm()` can handle multiple \"grouping\" variables together and even lets you \"group\" by quantitative variables.\n\n## Presentation using intervals\n\nStatistical thinking often involves quantifying uncertainty. Uncertainty appears where a newcomer to statistical thinking might not expect it. For example, consider \"**point**\" summaries such as the mean or median. So long as the arithmetic is correct, the result is inevitable; everyone doing the calculation will get the same result. The statistical thinker, however, includes the *data collection process* in the calculation. Each person carrying out his or her data collection process will get different results.\nThe study-to-study variation calls for an interval display, where the interval covers the likely range of results. \n\nPrediction is another context benefiting from an interval display. Prediction is imperfect. The predicted result---for instance, the baby's due date---is typically different from the actual outcome. The statistical thinker knows how to estimate the likely range of the difference between the predicted and actual outcomes.\n\n::: {.callout-note}\n## Example: 1.6 seconds per year?\n\nIt is appropriate to be skeptical of a claim that male runners slow down by  1.6 seconds per year compared to females. After all, people differ; some age more gently than others. As we will see in Lesson 20, the results presented from a regression model depend partly on the play of chance in determining the particular people represented in the data. It is helpful to know *how much* chance affects the results. A summary can indicate this by a range of plausible values, in other words, an \"**interval**\" summary. Here is an interval summary on the coefficients from the running time versus age model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTenMileRace %>% lm(net ~ sex * age, data = .) %>% confint() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  2.5 %      97.5 %\n(Intercept) 5269.766831 5472.233076\nsexM        -927.311125 -642.979202\nage           13.104803   18.818520\nsexM:age      -2.144359    5.357478\n```\n:::\n:::\n\nNotice that the interval on `sexM:age` includes zero.\n\nConstruct interval summaries using the appropriate *extractor* on a regression model. For instance, `confint()` generates an interval summary suggesting there might be no difference in the age trend for males and females.\n:::\n\n\n\n## Point plot as a graphical foundation \n\nRegression models, which will be the primary means of summarizing data in these Lessons, always have a response variable and typically have one or more explanatory variables.^[Actually, the previous sentence should say, \"**zero** or more explanatory variables.\" The model with no explanatory variables (and `y` as the response variable) is denoted by `y ~ 1`. This simple model represents the hypothesis that nothing can explain the variability in `y`.] \n\nIn these Lessons, we will place graphical depictions of model summaries in the context of actual data. Consequently, the graphical frame will reflect the choice of response and explanatory variables. The vertical axis will *always* represent the response variable. The horizontal axis will represent one of the explanatory variables. A point plot will display the data, or a jitter plot when there are categorical variables to be shown. \n\n\nAnother aspect of our unified data graphic format is that it will *always* be a point plot or, closely related, a jitter plot.\n\n::: {.callout-note}\n## Example: When is the baby due?\n\nAs all expecting parents know, a baby's \"due date\" is hardly exact. Pregnancies vary in length. What accounts for this variation?\n\nIn this example, we will entertain the hypothesis that experienced mothers have systematically different gestation periods than first-time mothers. An appropriate response variable is duration of `gestation`. The explanatory variable needs to measure \"experience,\" which is a vague idea. We will make it concrete by representing it by the number of the mother's pregnancies before the one reported in the data.\n\nThe `Gestation` data frame records more than 1200 births. `gestation` records the length of the pregnancy and will be our response variable. `parity` gives the number of previous births to the mother, starting at zero for a first-time mother. Although `parity` is encoded as a number, it has only *discrete* values---0, 1, 2, ... We will therefore graph it as a *categorical* variable, using jittering to avoid overplotting. There are not many rows with parity greater than five; we will focus on those.\n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code}\nGestation %>% \n  filter(parity <= 5) %>%\n  #mutate(parity = as.character(parity)) %>%\n  ggplot(aes(x=parity, y=gestation)) + \n  geom_jitter(alpha=0.2, width=0.2, height=0) \n```\n\n::: {.cell-output-display}\n![Gestational period for pregnancies where the mother had five or fewer previous pregnancies. The `width=0.2` controls the amount of horizontal jittering. We chose it to make the columns of data clear. There is no need to jitter in the vertical direction, so we set `height=0`](Reading-notes-lesson-19_files/figure-html/fig-gestation-jitter-1.png){#fig-gestation-jitter width=672}\n:::\n:::\n\n\nThis graph shows some things at a glance. For example, a typical gestation period is about 275 days (about nine months), and it is much more common to have a low parity than a very high one. \n:::\n\n## Displaying density\n\nIt is easy to see a pattern in @fig-gestation-jitter: It looks like mothers with high parity tend to have gestation periods more reliably close to 280 days than mothers with low parity. However, on the other hand, maybe this pattern is an illusion, an artifact of the small number of pregnancies with parity 3, 4, or 5 and, therefore, less opportunity to see extreme values for `gestation`.\n\nOne way to explore this idea is to plot the density of the dots as a function of gestation for each of the parity levels individually. A \"violin\" layer will make it easier to compare the distributions in the different columns, despite the unevenness in the case count. @fig-violin-intro gives an example.\n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code}\nGestation %>% \n  filter(parity <= 5) %>%\n  ggplot(aes(x=parity, y=gestation)) + \n  geom_jitter(alpha=0.2, width=0.2, height=0) +\n  geom_violin(aes(group=parity), fill=\"blue\", alpha=0.2, color=NA)\n```\n\n::: {.cell-output-display}\n![A violin plot. The long axis of the violin-like shape is oriented along the response-variable axis (that is, the vertical axis in our standard format). The width of the violin for each possible value of the response variable is proportional to the density of data near that value.](Reading-notes-lesson-19_files/figure-html/fig-violin-intro-1.png){#fig-violin-intro width=672}\n:::\n:::\n\n\nThe violin plot is a more flexible display of the distribution of gestation period than a histogram. The histogram has all those bars that clutter up the display. Even worse, one of the axes in the frame of a histogram plot is \"count\" or maybe \"density.\" Such a frame is inconsistent with the response/explanatory axes used for the data. The violin is drawn in the no-mans-land between the different levels of parity, just as the jittering moves data away from a single vertical line into that same no-mans-land. \n\nThis idea of using the graphical no-mans-land between levels of a categorical explanatory variable is not new. You encountered it earlier when you drew box plots. @fig-density-box adds a box-plot annotation layer on top of the violin-plot layer.\n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code}\nGestation %>% \n  filter(parity <= 5) %>%\n  ggplot(aes(x=parity, y=gestation)) + \n  geom_jitter(alpha=0.2, width=0.2, height=0) +\n  geom_violin(aes(group=parity), fill=\"blue\", alpha=0.2, color=NA) +\n  geom_boxplot(aes(group=parity), color=\"blue\", fill=NA, alpha=.5)\n```\n\n::: {.cell-output-display}\n![A box and whisker plot uses the no-mans-land between levels of a categorical explanatory variable.](Reading-notes-lesson-19_files/figure-html/fig-density-plot-1.png){#fig-density-plot width=672}\n:::\n:::\n\nIn practice, there is little reason to layer a box plot on top of a violin. The violin does the job nicely on its own. \n\n\n\n\n## Categorical response variables \n\nRegression modeling will be a fundamental tool in these Lessons for summarizing data. Regression models always have a quantitative response variable, although explanatory variables can be either quantitative or categorical. \n\nOften, the modeling situation calls for a response variable that is *categorical*. Expert modelers can use specialized modeling methods to handle such situations. However, categorical response variables often have just two levels, e.g., Alive/Dead, Promoted/Not, or Win/Loss. We will name the general class of such variables as \"**yes/no**\" or, equivalently, \"**zero-one**\" variables.[More formally, they are called \"**binomial**\" variables.]{.aside}\n\nYes/no response variables can be represented using 0 for one level and 1 for the other. This numerical \"**0/1 encoding**\" is directly suited for regression modeling and enables us to extend the scope of regression models. The *output* of the regression model is always numerical. Nothing in the regression technique restricts those outputs to exactly zero or one, even when the response variable is of the yes/no type. Usually, the modeler interprets such numerical output as probabilities or, more generally, as measures to be converted to probabilities.\n\n::: {.callout-note}\n## R technique: Using `zero_one()`.\nThe `zero_one()` function converts a yes/no variable to the numerical zero-one format. `zero_one()` allows you to specify which of the two levels is represented by 1.\n\nTo illustrate, consider the `mosaicData::Whickham` data frame, which records a 1972-1974 survey, part of a study of the relationship between smoking and mortality. Twenty years after the initial survey, a follow-up established whether or not each person was still alive. \n\n\n::: {#tbl-Whickham-short .cell tab.cap='A few rows of the `Whickham` data frame.' tab.location='margin'}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> outcome </th>\n   <th style=\"text-align:left;\"> smoker </th>\n   <th style=\"text-align:right;\"> age </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 18 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Dead </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> No </td>\n   <td style=\"text-align:right;\"> 67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> No </td>\n   <td style=\"text-align:right;\"> 64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 38 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe `outcome` variable in `Whickham` records the result of the follow-up survey. It is a categorical variable with levels \"Alive\" and \"Dead.\" To examine what the data have to say about the relationship between smoking and mortality, we construct a model with `outcome` as the response variable and `smoking` as an explanatory variable. Before doing so, we translate `outcome` into a zero-one format. Like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nWhickham %>% \n  mutate(alive = zero_one(outcome, one=\"Alive\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> outcome </th>\n   <th style=\"text-align:left;\"> smoker </th>\n   <th style=\"text-align:right;\"> age </th>\n   <th style=\"text-align:right;\"> alive </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 23 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Dead </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> No </td>\n   <td style=\"text-align:right;\"> 67 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> No </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Alive </td>\n   <td style=\"text-align:left;\"> Yes </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNote the correspondence between the `outcome` and the newly created `alive` variable.\n\n:::\n\n\n--------\n\n::: {.callout-warning}\n## Demonstration: Predicting calorie content\n\nStarbucks is a famous coffee-shop franchise with more than 30,000 branches (as of 2021). People go to Starbucks for coffee, but they often buy something to eat as well. In this demonstration, we will look at the calorie content of Starbucks' food offerings. As always, when conducting a statistical analysis, it is helpful to have in mind the motivation for the task. So we will imagine, tongue in cheek, that we want to make food recommendations for the calorie-conscious consumer.\n\nFirst, a **point summary** of the calories in the different types of food products available at Starbucks:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoint_summary <- \n  df_stats(calories ~ type, \n           data = openintro::starbucks, mean)\npoint_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  response          type     mean\n1 calories        bakery 368.7805\n2 calories    bistro box 377.5000\n3 calories hot breakfast 325.0000\n4 calories       parfait 300.0000\n5 calories        petite 177.7778\n6 calories         salad  80.0000\n7 calories      sandwich 395.7143\n```\n:::\n:::\n\n\nThis summary supports the sensible advice to choose salads or smaller portions (type \"petite\") to avoid calories. One might go further, for example, concluding that a sandwich is a poor choice (in terms of calorie content), so lean toward parfaits or hot breakfasts. We can even imagine someone concluding from this summary that a bistro box is a better calorie-conscious choice than a sandwich.\n\n@fig-starbucks-food shows the point summary, using the raw data to put things in context.\n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code}\nopenintro::starbucks %>% \n  ggplot(aes(x=type, y=calories)) +\n  geom_jitter(width=0.2, alpha=0.5) +\n  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), \n                y=NA, color=\"blue\") +\n  geom_point(data=point_summary, aes(y=mean), color=\"red\")\n```\n\n::: {.cell-output-display}\n![Calories of the various food items sold by Starbucks, annotated with point and interval summaries.](Reading-notes-lesson-19_files/figure-html/fig-starbucks-food-1.png){#fig-starbucks-food width=672}\n:::\n:::\n\n\nPlotting the point summary in the context of the raw data shows at a glance that the point summary is not of any genuine use. For instance, using the point summary without the data, we might conclude that hot breakfasts are better than sandwiches. However, the data display suggests otherwise; there is just one low-calorie breakfast. The others are much like sandwiches.\n\nA point summary is compact but cannot represent the *variation* within each food type. An interval summary, as in @fig-starbucks-food2, does show this variation. \n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code}\nopenintro::starbucks %>% \n  ggplot(aes(x=type, y=calories)) +\n  geom_jitter(width=0.2, alpha=0.5) +\n  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), \n                y=NA, color=\"blue\") \n```\n\n::: {.cell-output-display}\n![Calories of the various food items sold by Starbucks, annotated with point and interval summaries.](Reading-notes-lesson-19_files/figure-html/fig-starbucks-food2-1.png){#fig-starbucks-food2 width=672}\n:::\n:::\n\n\nUnlike point summaries, interval summaries can overlap. Such overlap indicates that the groups are not all that different. Here, the interval summary indicates an appropriate conclusion; \"Don't make your diet choices based on food type. Look at the calorie content of individual items before choosing.\"\n\nAdmittedly, in this simple setting the data themselves would lead to the conclusion. However, as we move into more complicated settings, it will become infeasible to see patterns quickly straight from the data. \n\n:::\n",
    "supporting": [
      "Reading-notes-lesson-19_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}