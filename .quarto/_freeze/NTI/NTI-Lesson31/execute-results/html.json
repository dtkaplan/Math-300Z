{
  "hash": "9c23ae691147879a5986d868bc18ce9d",
  "result": {
    "markdown": "---\ntitle: \"Math 300R NTI Lesson 31\"\nsubtitle: \"Spurious correlation\"\nauthor: \"Prof. Danny Kaplan\"\ndate: \"November 04, 2022\"\noutput:\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n    css: NTI.css\n  pdf_document:\n    toc: yes\n---\n\n\n\n\nBy which I mean correlations that are not just statistical noise but do not represent a causal path between two variables.\n\n\n## Objectives\n\n\n\n\n\n\n\n\n31.1 Distinguish \"common cause\" and \"collider\" forms of DAG.\n\n31.2 Construct appropriate DAG to match a narrative hypothesis.\n\n\n\n## Reading\n\nTBD\n\n\n## Lesson\n\nStatisticians are often careful in their use of language about relationships. They will say two variables are \"correlated\" or \"associated\" rather than casually using words like \"connected\" or \"related.\" There is even a proverb, \"Correlation is not causation.\" \n\n\n::: {.cell}\n::: {.cell-output-display}\n![[XKCD's take](https://xkcd.com/552/) on correlation and causation.](www/xkcd-correlation.png){#fig-xkcd-correlation width=459}\n:::\n:::\n\n\nTraditionally, statistics courses have emphasized disputing any causal interpretation of correlations found in data. The response \"Well, maybe,\" in the last panel of the cartoon shows a student correctly having assimilated this lesson.\n\nAnother formulation might be more enlightening for statistics students: \"Correlation is the sign in data of causal connections in mechanisms.\" If two variables `a` and `b` are correlated, then either `a` causes `b` (perhaps indirectly), `b` causes `a` (also perhaps indirectly), or both `a` and `b` are caused by other factors. There's another possibility as well, most easily seen with a corresponding DAG in hand. It's important to consider all of these possibilities, rather than jumping to a conclusion of what causes what. \n\nIn this lesson, we're going to look at only those correlations that would be supported by out-of-sample testing. Later, we'll also need to deal with correlations that are an illusion of sampling fluctuation or due to a systematic hunt.\n\nWe'll use the term \"spurious correlation\" to refer to those correlations created by mechanisms other than a causal path between two variables in a DAG.  \n\n::: {.callout-note icon=false}\n## Paths in DAGS\n\nExamples and exercises classifying causal and correlating paths in DAGs.\n\nSelection on a collider or using it as a covariate.\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_draw(dag09)\n```\n\n::: {.cell-output-display}\n![](NTI-Lesson31_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nSample <- sample(dag09, size=500)\nlm(a ~ b, data = Sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = a ~ b, data = Sample)\n\nCoefficients:\n(Intercept)            b  \n  -0.013249     0.007196  \n```\n:::\n\n```{.r .cell-code}\nlm(a ~ b, data = Sample %>% filter(c==1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = a ~ b, data = Sample %>% filter(c == 1))\n\nCoefficients:\n(Intercept)            b  \n      0.652       -0.400  \n```\n:::\n\n```{.r .cell-code}\nlm(a ~ b, data = Sample %>% filter(c==0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = a ~ b, data = Sample %>% filter(c == 0))\n\nCoefficients:\n(Intercept)            b  \n    -0.6600      -0.3592  \n```\n:::\n\n```{.r .cell-code}\nlm(a ~ b, data = Sample) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = a ~ b, data = Sample)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9370 -0.7473  0.1003  0.6630  2.5546 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)\n(Intercept) -0.013249   0.043811  -0.302    0.762\nb            0.007196   0.044263   0.163    0.871\n\nResidual standard error: 0.9796 on 498 degrees of freedom\nMultiple R-squared:  5.307e-05,\tAdjusted R-squared:  -0.001955 \nF-statistic: 0.02643 on 1 and 498 DF,  p-value: 0.8709\n```\n:::\n:::\n\n:::\n\n::: {.callout-note icon=false}\n## Regression to mediocrity\n\nAn unusually large deviation is likely to be followed by one not so unusually large.\n:::\n\n\n## Learning Checks\n\n\n\n\n\n\n\n\n\n## 31.1\n\n::: {.callout-note}\n## Solution\n\n:::\n\n--------\n\n\n## Documenting software\n\n  \n\n",
    "supporting": [
      "NTI-Lesson31_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}