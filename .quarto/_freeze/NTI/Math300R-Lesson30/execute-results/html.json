{
  "hash": "0fcc56285c185dcbaedd4866afa37849",
  "result": {
    "markdown": "---\ntitle: \"Math 300R NTI Lesson 30\"\nsubtitle: \"Confounding\"\nauthor: \"Prof. Danny Kaplan\"\ndate: \"October 14, 2022\"\noutput:\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n    css: NTI.css\n  pdf_document:\n    toc: yes\n---\n\n\n\n\n## Objectives\n\n\n\n\n\n\n\n\n#. Identify confounding in a DAG\n\n#. Choose whether to include covariate depending on form of DAG\n\n\n\n\n## Reading\n\nTBD\n\n\n## Lesson\n\nEarlier we described two different types of statistical task:\n\n1. Prediction. Say something about what the outcome will be for a new case.\n2. Relationship. Describe how two or more variables are inter-related.\n\nIn a prediction task, we use training data to build a model based on data from the system of interest. The model is then used as a function to calculate the output (and its precision). The goal is to minimize out-of-sample prediction error. Including covariates in the model can sometimes improve the precision, but sometimes not.\n\nIn a relationship task, we also use training data to build a model. But rather than looking at the output from the model directly, we look at the partial derivative of the model function with respect to an input of interest. This quantifies the strength of the relationship between selected input variable and the response variable.\n\nSince we're using first order polynomial models (e.g. `y ~ a + b + c`), there is no technical difficulty finding the partial derivative. It is simply the model coefficient on the variable of interest.\n\nIn today's lesson, we're going to use gaming so that we know exactly what the causal connections are. Remember, it's just a game! Our objective in playing the game is to learn in what circumstances we can capture the true causal mechanism behind the data.\n\n::: {.callout-note icon=false}\n## Example: Sorting out multiple causes\n\n`dag02` simulates a situation where two variables are connected causally to `y`. Questions: Can a fitted model capture the true relationships? Must we use both variables?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag02\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\nx ~ eps()\n\n[[2]]\na ~ eps()\n\n[[3]]\ny ~ 3 * x - 1.5 * a + 5 + eps()\n\nattr(,\"class\")\n[1] \"list\"      \"dagsystem\"\n```\n:::\n\n```{.r .cell-code}\nSample <- sample(dag02, size=500)\nlm(y ~ x, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           x \n   4.956510    2.995888 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ a, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           a \n   5.062005   -1.540196 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ a + x, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           a           x \n   4.925914   -1.545395    2.998776 \n```\n:::\n:::\n\n\nConclusion: Ignoring one of the explanatory variables prevents us (of course!) from seeing that variable's relationship with `y`. But the other variable's connection shows up correctly. Using both explanatory variables let's us capture the correct mechanism behind `y`.\n:::\n\nBut things aren't always as simple as in the previous example. Consider `dag08`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_draw(dag08)\n```\n\n::: {.cell-output-display}\n![](Math300R-Lesson30_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nHere both `c` and `x` have a causal relationship with `y`. They often happen to have a causal relationship with each other. Will this interfere with finding the direct relationships between `x` and `y` and between `c` and `y`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag08\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\nc ~ eps()\n\n[[2]]\nx ~ c + eps()\n\n[[3]]\ny ~ x + c + 3 + eps()\n\nattr(,\"class\")\n[1] \"list\"      \"dagsystem\"\n```\n:::\n\n```{.r .cell-code}\nSample <- sample(dag08, size=500)\nlm(y ~ x, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           x \n   3.039470    1.582127 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ c, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           c \n   3.033517    2.122726 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ c + x, data = Sample) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           c           x \n   3.029310    1.047104    1.044198 \n```\n:::\n:::\n\n\nHere we need to include both `c` and `x` in the model to see the correct causal relationships. If we leave out either `x` or `c` the other variable will \"inherit\" some of the causal connection between the left-out variable and the response.\n\nThis is called **confounding**. The dictionary has two different definitions of \"confound\":\n\n1. To surprise or confuse someone.\n2. To mix up (something) with something else so that the individual elements become difficult to distinguish.\n\nIt's the second definition that is relevant to us.\n\nAs an example of the \"mixing up,\" look at the coefficients for the model `y ~ c`. The DAG shows `c` having an effect size of 1 directly on `y`. But `c` also has an effect on `y` that is mediated by `x`. If we leave `x` out of the model, that indirect effect is mixed in with the direct effect. \n\nThe mixing of the direct and indirect causal routes from `c` to `y` is actually correctly captured by the coefficient 2 from the model. It's important to be aware of this mixing. If you weren't, you might be confused (confounded in the first definition!) because the results from `y ~ c` and `y ~ c + x` appear to conflict with one another.\n\n\n## Learning Checks\n\n\n\n\n\n\n\n\n\n## 30.1\n\nDags with longer confounding pathways. Is there mixing when leaving out an element in the pathway. Mix up the directions of the arrows and show that the mixing occurs when the covariate is *included* in the model.\n\nRegression to the mean example.\n\nCollider?\n\n\n\n::: {.callout-note}\n## Solution\n\n:::\n\n--------\n\n\n\n## Documenting software\n\n  \n\n",
    "supporting": [
      "Math300R-Lesson30_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}