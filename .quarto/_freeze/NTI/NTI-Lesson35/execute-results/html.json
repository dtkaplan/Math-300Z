{
  "hash": "8aec795a45dfb5cf5943b1dea39df846",
  "result": {
    "markdown": "---\ntitle: \"Math 300R NTI Lesson 35\"\nsubtitle: \"Accounting for prevalence\"\nauthor: \"Prof. Danny Kaplan\"\ndate: \"November 04, 2022\"\noutput:\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n    css: NTI.css\n  pdf_document:\n    toc: yes\n---\n\n\n\n\n\n## Objectives\n\n\n\n\n\n\n\n\n35.1 Explain why case-control data may not give an proper measure of \"prevalence.\"\n\n35.2 Understand sensitivity and specificity as conditional probabilities.\n\n35.3 Calculate false-positive and false-negative rates for a given prevalence.\n\n\n\n## Reading\n\nTBD\n\n\n## Lesson\n\nIn [Lesson 33](Math300R-Lesson33.html) we built a classifier based on simulated data from `dag10`. \n\n- A classifier is a function of the variables deemed relevant by the designer and that produces a yes/no output.\n- Discovering a suitable function requires insight and usually trial and error.  \n\n\n\nHere's a classifier relevant to `dag10`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nC1 <- make_classifier(c1 ~ b < 0)\n```\n:::\n\n\n`C1` is a function taking a data frame as input. The calculation is whether `b` is less than 0. If so, the function output is a 1. The output will be added as column `c1` to the input data\n\nTo evaluate it, create a dataframe from `dag10` and run the classifier on it. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nSample <- sample(dag10, size=1000) %>% C1()\nwith(Sample, table(y, c1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   c1\ny     -   +\n  0 368 125\n  1 131 376\n```\n:::\n:::\n\n\nThe false-positive rate is 125/1000, the false-negative rate is 131/1000. The \"accuracy\" is (368+376)/1000, about 74%.\n\nWe designed classifier `C1()` using where the disease state is 1 about half the time, as appropriate for a **case-control** design.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSample %>% summarize(yesses = mean(y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 1\n  yesses\n   <dbl>\n1  0.507\n```\n:::\n:::\n\n\nNow we want to deploy the classifier in a realistic setting, where the **base rate** is only, say, 10%. To simulate this, we'll keep all of the 0s from the simulation, but only 11% of the 1s. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nField_results <- sample(dag10, \n                        size=1000, \n                        survive=~ifelse(y==1, unif() < 0.11, TRUE)) %>% C1()\nwith(Field_results, table(y, c1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   c1\ny     -   +\n  0 683 225\n  1  23  69\n```\n:::\n:::\n\n\nThe false negative rate is now close to zero: 19/1000. But the false positive rate is 31%, much higher than with the case-control data used to design the classifier. \n\nWhat's gone wrong? Why did the false positive rate change? \n\nThe reason is that the \"**base rate**\" (or **prevalence**) for the disease is 10.1% in `dag10b` compared to the 50% in `dag10`. Same classifier, but a different false positive rate.\n\nWe would like to have a way to characterize a classifier that is independent of the base rate.\n\nThe false positive rate is a probability: p(0 & +). Similarly, the false negative rate is p(1 & -). We can read these off the table. \n\nThe quantities of interest to the patient and doctor are different probabilities: \n\n- p(0 | -) --- probability you don't have the disease given a negative test result\n- p(1 | +) --- probability you have the disease given a positive test result\n\nCalculate these probabilities from the classifer test results for the two base rates we've looked at: 50% for `dag10` and 21% for `dag10b`.\n\n\n- Case/control --- p(0 | -) is 368/(368 + 131) = 73%\n- Field -- p(0 | -) is 759/(746 + 29) = 96%\n\n- Case/control --- p(1 | +) is 376/(376 + 125) = 75%\n- Field -- p(1 | +) is 88/(248+88) = 26%\n\nThese patient-centered probabilities change as the base rate changes. It turns out that the proper way to characterize the classifier is with two different probabilities:\n\n- Sensitivity: Probability of a + test if you have the disease: p(+ | 1)\n- Specificity: Probability of a - test if you do not have the disease: p(- | 1)\n\nNote that these are not probabilities of direct interest to the patient or doctor. But they do come out the same regardless of the base rate of the disease.\n\n- Case/control --- p(+ | 1) is 376/(376+131) = 74%\n- Field -- p(+ | 1) is 88/(29+88) = 75%\n\n- Case/control --- p(- | 0) is 368/(368 + 125) = 75%\n- Field -- p(- | 0) is 746/(746+248)= 75%\n\nGiven the sensitivity/specificity and the base rate, we can calculate the probability of interest to the patient\n\np(1 | +) = p(+ | 1) p(1) / (p(+ | 1)p(1) + p(-|0)p(0))\n\nIn statistics, the sensitivity/specificity is called the \"likelihood function\", the probability of the observed data under the actual values in the world. THIS IS WEAK.\n\n## Learning Checks\n\n\n\n\n\n\n\n\n\n## 35.1\n\nGiven some classifier summaries, calculate the false-positive and false-negative rates as well as the sensitivity and specificity\n\n::: {.callout-note}\n## Solution\n\n:::\n\n--------\n\n## 35.Q\n\n\n\nTITLE GOES HERE: Customize the classifiers in (ref:ant-take-room) for a population in which species A is three times as common as species B.\n\n::: {callout-note}\n## Solution\n\nFollow the same procedure as in (ref:ant-take-room), but duplicate each of the A rows two times, so that the data show a world in which A is three times as common as B. That is,  \n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> species </th>\n   <th style=\"text-align:left;\"> size </th>\n   <th style=\"text-align:left;\"> color </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> reddish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> reddish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> reddish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> B </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> brownish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> B </td>\n   <td style=\"text-align:left;\"> small </td>\n   <td style=\"text-align:left;\"> brownish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> brownish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> brownish </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> large </td>\n   <td style=\"text-align:left;\"> brownish </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nFor the classifier using just size as an explanatory variable ... There are 7 rows for which size is large. Of these six are species A so the classifier output is 6/7. For size small, there is just one row, which  is B, so the classifier output is 0/1.\n\nFor the classifier using just color as an explanatory variable ... There are five rows for which color is brownish. Of these, 2 are species A. So the classifier output is 2/5 for brownish. For reddish, the classifier output is 3/3.\n\n:::\n\n--------\n\n## 35.R\n\nThe two tables below are different summaries of the Univ. of California Berkeley graduate admissions data from the 197e fall quarter. (Data frame: `UCB_applicants`) Each of the tables is about conditional probabilities about admission and sex.\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table A</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> admitted </th>\n   <th style=\"text-align:right;\"> rejected </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> female </td>\n   <td style=\"text-align:right;\"> 31.7 </td>\n   <td style=\"text-align:right;\"> 46.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> male </td>\n   <td style=\"text-align:right;\"> 68.3 </td>\n   <td style=\"text-align:right;\"> 53.9 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table B</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> female </th>\n   <th style=\"text-align:right;\"> male </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> admitted </td>\n   <td style=\"text-align:right;\"> 30.4 </td>\n   <td style=\"text-align:right;\"> 44.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rejected </td>\n   <td style=\"text-align:right;\"> 69.6 </td>\n   <td style=\"text-align:right;\"> 55.5 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n1. Which table displays p(sex given admit)? \n\n::: {.callout-note} \n## Solution Table \nA\n:::\n\n2. Which table displays p(admit given sex)? \n\n::: {.callout-note} \n## Solution \nTable B\n:::\n\n3. Which of these statements is true?\n    a. Table A shows that admitted students are more likely to be male. \n    \n::: {.callout-note} \n## Solution \nTrue\n:::\n\n    b. Table A shows that rejected students are more likely to be male. \n    \n::: {.callout-note} \n## Solution \nTrue\n:::\n\n    c. Table A shows that females are less likely to be admitted than rejected. \n::: {.callout-note} \n## Solution False. \n\nThere's nothing in Table A to tell us what fraction of applicants were admitted. Because table A stratifies by  admitted/rejected, we don't know how large those two groups are with respect to one another.\n:::\n\n    d. Table B shows that admitted students are more likely to be male. \n    \n::: {.callout-note} \n## Solution False. \nTable B is stratified on female/male. As  a result, there's no information in Table B about what fraction of applicants is male.\n:::\n\n    e. Table B shows that females are less likely to be admitted than males. \n    \n4. Suppose you are interested in the possibility of discrimination against women in graduate admissions (in Berkeley in 1973). Which of these questions is the right one to ask, and which table gives you the information needed to answer the question?\n    a. What is the probability of an admitted student being a female compared to the probability of a rejected student being a female? \n    \n::: {.callout-note} \n## Solution False. \nThe question is about the relative admissions probability of females and males.\n:::\n\n    b. What is the probability of a female applicant being admitted compared to the probability that an admitted student is male? \n\n::: {.callout-note} \n## Solution False. You want to compare like with like. The group involved in \"the probability of a female student being admitted\" is females, whereas the group involved in  \"the probability that an admitted student is male\" is admitted students. There's little if any meaning in comparing a probability among the group of females to a probability among group of admitted students.\n:::\n\n    c. What is the probability of  a female applicant being admitted compared to the probability of a male applicant being admitted? \n    \n::: {.callout-note} \n## Solution True. \nWe want to compare two groups: females and males. Here, we're comparing the probability of being admitted in each of the comparison groups. Table **B** is formatted to enable this comparison. \n:::\n\n\n\n\n\n## Documenting software\n\n  \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}