{
  "hash": "59d500bc3e23a5cb471489e8de1051f7",
  "result": {
    "markdown": "---\ntitle: \"Math 300R NTI Lesson 23\"\nsubtitle: \"sampling variation from a single sample\"\nauthor: \"Prof. Danny Kaplan\"\ndate: \"October 14, 2022\"\noutput:\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n    css: NTI.css\n  pdf_document:\n    toc: yes\n---\n\n\n\n\n## Objectives\n\n\n\n\n\n\n\n\n23.1 Use bootstrapping to estimate sampling variation.\n\n23.2 Infer sampling variation from a regression table: \"standard error\" of a model coefficient.\n\n23.3 Construct and interpret confidence intervals on a model coefficient.\n\n23.4. Understand and use scaling of confidence interval length as a function of $n$.\n\n\n## Reading\n\nTBD\n\n\n## Lesson\n\n::: {.callout-tip icon=FALSE}\n## Setup \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"../_startup.R\")\n```\n:::\n\n:::\n\n\n\nThe point of today's lesson is to show how some properties of the sampling distribution can be estimated from a single sample, rather than the many trials of sample-then-summarize that we used in Lesson 22.\n\n## Bootstrapping\n\nOne approach is to mimic what we did when we had a DAG available: run many trials. But all we have is a sample, not the DAG. Can we run many trials from the sample itself?\n\nLet's use the `moderndive::amazon_books` data set and the model tilde `list_price ~ num_pages`\n\nHere's the results on the actual data:\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(list_price ~ num_pages, data = moderndive::amazon_books) %>% coefficients()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)   num_pages \n 11.8438357   0.0198815 \n```\n:::\n:::\n\nInterpretation: books cost about $12 plus 2 cents per page.\n\nHere is our first stab at sampling from the data. Note that when sampling from a data set, `sample()` sets the sample size to be the same as the number of rows in the data set.\n\n::: {.cell}\n\n```{.r .cell-code}\ntrial <- function() {\n  lm(list_price ~ num_pages, data = sample(moderndive::amazon_books)) %>% \n    coefficients()\n}\n{do(100) * trial()} %>% summarize(sd(Intercept), sd(num_pages))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  sd(Intercept) sd(num_pages)\n1  1.350947e-14  2.356966e-17\n```\n:::\n:::\n\n::: {.callout-note icon=false}\n## Questions\n\n- How to interpret these numbers? What are they telling us about the sampling distribution on the regression coefficients?\n- What's wrong?\n- How to fix it?\n:::\n\nIntroduce the `replace=TRUE` argument for `sample()`. Explain what it does and show the result. \nIs the result correct? We can't know, because we don't have access to the data-generating DAG in order to run many trials. But we can test the method on data generated from a DAG and confirm that it gives a reasonable result.\n\n::: {.callout-important icon=false}\n## Activity\n\nEach student should construct one from a dag of his or her choice.\n:::\n\n### Regression table\n\nIn the readings, we mentioned that there are formulas for the standard deviation of the sampling distribution. [NEEDED TO GIVE THIS A NAME EARLIER: \"SD of sampling variability\", \"standard error\"] All you need to know about the formulas for the standard error is that i) they exist for linear regression and ii) the standard error is inversely proportional to $\\sqrt{n}$.\n\nShow how to construct the regression table and where to find the relevant standard error\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndo(3) * {lm(list_price ~ num_pages, data = moderndive::amazon_books) %>% broom::tidy()}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  term        estimate std.error statistic  p.value  .row .index\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl> <int>  <dbl>\n1 (Intercept)  11.8      1.79         6.63 1.40e-10     1      1\n2 num_pages     0.0199   0.00479      4.15 4.24e- 5     2      1\n3 (Intercept)  11.8      1.79         6.63 1.40e-10     1      2\n4 num_pages     0.0199   0.00479      4.15 4.24e- 5     2      2\n5 (Intercept)  11.8      1.79         6.63 1.40e-10     1      3\n6 num_pages     0.0199   0.00479      4.15 4.24e- 5     2      3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(list_price ~ num_pages, data = moderndive::amazon_books) %>% broom::glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1  0.0511  0.0481  13.9    17.2 4.24e-5     1 -1304. 2614. 2625.  61999.     320\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n```\n:::\n:::\n\n\n\n## Margin of error\n\nConfidence interval as estimate $\\pm 2\\times$ standard error.\n\nGraphics for confidence interval. They need to know how to read them, not to make the graphics.\n\n## Learning Checks\n\n\n\n\n\n\n\n\n\n## 23.1\n\nVocabulary: Sampling distribution, standard error, sampling variability, sample size\n\n::: {.callout-note}\n## Solution\n\n:::\n\n--------\n\n\n\n\n## Documenting software\n\n* File creation date: 2022-10-14\n* R version 4.2.1 (2022-06-23)\n* `tidyverse` package version: 1.3.2\n* `mosaic` package version: 1.8.4\n* `math300` package version: 0.1.0.9000\n\n  \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}