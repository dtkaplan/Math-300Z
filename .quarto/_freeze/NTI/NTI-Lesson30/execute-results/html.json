{
  "hash": "120af7b232e98c7e1f4adbb33e5836b8",
  "result": {
    "markdown": "---\ntitle: \"Math 300R NTI Lesson 30\"\nsubtitle: \"Confounding\"\nauthor: \"Prof. Danny Kaplan\"\ndate: \"December 23, 2022\"\noutput:\n  html_document:\n    theme: lumen\n    toc: yes\n    toc_float: yes\n    css: NTI.css\n  pdf_document:\n    toc: yes\n---\n\n\n\n\n## Objectives\n\n\n\n\n\n\n\n\n30.1 Identify confounding in a DAG\n\n30.2 Choose whether to include covariate depending on form of DAG\n\n\n\n\n## Reading\n\nTBD\n\n\n## Lesson\n\nEarlier we described two different types of statistical task:\n\n1. Prediction. Say something about what the outcome will be for a new case.\n2. Relationship. Describe how two or more variables are inter-related.\n\nIn a prediction task, we use training data to build a model based on data from the system of interest. The model is then used as a function to calculate the output (and its precision). The goal is to minimize out-of-sample prediction error. Including covariates in the model can sometimes improve the precision, but sometimes not.\n\nIn a relationship task, we also use training data to build a model. But rather than looking at the output from the model directly, we look at the partial derivative of the model function with respect to an input of interest. This quantifies the strength of the relationship between selected input variable and the response variable.\n\nSince we're using first order polynomial models (e.g. `y ~ a + b + c`), there is no technical difficulty finding the partial derivative. It is simply the model coefficient on the variable of interest.\n\nIn today's lesson, we're going to use gaming so that we know exactly what the causal connections are. Remember, it's just a game! Our objective in playing the game is to learn in what circumstances we can capture the true causal mechanism behind the data.\n\n::: {.callout-note icon=false}\n## Example: Sorting out multiple causes\n\n`dag02` simulates a situation where two variables are connected causally to `y`. Questions: Can a fitted model capture the true relationships? Must we use both variables?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag02\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx ~ exo()\na ~ exo()\ny ~ 3 * x - 1.5 * a + 5 + exo()\n```\n:::\n\n```{.r .cell-code}\nSample <- sample(dag02, size=500)\nlm(y ~ x, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           x \n   5.084037    2.964035 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ a, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           a \n   5.011383   -1.324158 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ a + x, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           a           x \n   4.998403   -1.420510    3.005586 \n```\n:::\n:::\n\n\nConclusion: Ignoring one of the explanatory variables prevents us (of course!) from seeing that variable's relationship with `y`. But the other variable's connection shows up correctly. Using both explanatory variables let's us capture the correct mechanism behind `y`.\n:::\n\nBut things aren't always as simple as in the previous example. Consider `dag08`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_draw(dag08)\n```\n\n::: {.cell-output-display}\n![](NTI-Lesson30_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nHere both `c` and `x` have a causal relationship with `y`. They often happen to have a causal relationship with each other. Will this interfere with finding the direct relationships between `x` and `y` and between `c` and `y`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag08\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nc ~ exo()\nx ~ c + exo()\ny ~ x + c + 3 + exo()\n```\n:::\n\n```{.r .cell-code}\nSample <- sample(dag08, size=500)\nlm(y ~ x, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           x \n   3.010714    1.453153 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ c, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           c \n   3.014904    1.909548 \n```\n:::\n\n```{.r .cell-code}\nlm(y ~ c + x, data = Sample) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)           c           x \n  3.0045437   0.9876089   0.9449694 \n```\n:::\n:::\n\n\nHere we need to include both `c` and `x` in the model to see the correct causal relationships. If we leave out either `x` or `c` the other variable will \"inherit\" some of the causal connection between the left-out variable and the response.\n\nThis is called **confounding**. The dictionary has two different definitions of \"confound\":\n\n1. To surprise or confuse someone.\n2. To mix up (something) with something else so that the individual elements become difficult to distinguish.\n\nIt's the second definition that is relevant to us.\n\nAs an example of the \"mixing up,\" look at the coefficients for the model `y ~ c`. The DAG shows `c` having an effect size of 1 directly on `y`. But `c` also has an effect on `y` that is mediated by `x`. If we leave `x` out of the model, that indirect effect is mixed in with the direct effect. \n\nThe mixing of the direct and indirect causal routes from `c` to `y` is actually correctly captured by the coefficient 2 from the model. It's important to be aware of this mixing. If you weren't, you might be confused (confounded in the first definition!) because the results from `y ~ c` and `y ~ c + x` appear to conflict with one another.\n\n\n## Learning Checks\n\n\n\n\n\n\n\n\n\n\n\n::: {.callout-warning}\n## Is horsepower the cause?\n\nIt might seem from the negative sign on the effect size of engine horsepower on fuel economy that a more powerful engine is not as efficient than a less powerful engine at moving the car a given number of miles. That's a reasonable conclusion. But the statistical thinker always keeps in mind other possibilities. For instance, another factor in fuel economy is the overall weight of the vehicle. A van designed to haul many passengers weighs more than a 2-passenger sporty vehicle. The van needs more horsepower because it is accelerating more weight.\n\n::: {.cell}\n\n:::\n\n@fig-four-hp-mpg-dags shows four DAGs, each of which describe a plausible scenario.\n\n::: {.content-visible when-format=\"html\"}\n::: {#fig-four-hp-mpg-dags .cell .column-page-right layout-ncol=\"4\"}\n::: {.cell-output-display}\n![Dag A](NTI-Lesson30_files/figure-html/fig-four-hp-mpg-dags-1.png){#fig-four-hp-mpg-dags-1 width=25%}\n:::\n\n::: {.cell-output-display}\n![Dag B](NTI-Lesson30_files/figure-html/fig-four-hp-mpg-dags-2.png){#fig-four-hp-mpg-dags-2 width=25%}\n:::\n\n::: {.cell-output-display}\n![Dag C](NTI-Lesson30_files/figure-html/fig-four-hp-mpg-dags-3.png){#fig-four-hp-mpg-dags-3 width=25%}\n:::\n\n::: {.cell-output-display}\n![Dag D](NTI-Lesson30_files/figure-html/fig-four-hp-mpg-dags-4.png){#fig-four-hp-mpg-dags-4 width=25%}\n:::\n\nScenarios for the relationship between automobile fuel economy, weight, and horsepower\n:::\n:::\n\n:::: {.content-visible when-format=\"pdf\"}\n::: {.callout-warning}\nManually insert the four part figure as a single png\n:::\n::::\n\nIn DAG A, the vehicle's design weight determines that an engine with high horsepower will be part of the design. The weight is also responsible for the lower fuel economy.\n\nThe other DAGs describe other scenarios. In DAG C, for instance, the car designers decided to build a muscle car and put in a big engine. The engine itself adds to the vehicle's weight, and the higher weight determines lower miles per gallon. DAG D expresses a slightly different belief: again the choice to build a muscle car (high `hp`) influences the weight. But in DAG B, the big engine also directly influences the fuel economy, perhaps because the fuel-to-air ratio of the car, in normal use, is not optimal.\n\nAs we will see in Lesson 28, to reveal the direct causal link between engine power and fuel economy requires different choices for the model formula depending on which DAG you think might be relevant.\n:::\n\n---------\n\nTo illustrate, let's consider prices of houses as recorded in the `mosaicData::SaratogaHouses` data frame, based on house sales in Saratoga County, NY, USA in 2006. We'll follow a question asked by then-student Candice Corvetti in her Stat 101 class at Williams College: \"How much is a fireplace worth?\" Response variable: `price`. Explanatory variable: `fireplaces`. Since a handful of the houses has multiple fireplaces, we will simplify by filtering out those houses to retain only the ones with a single fireplace or none.\n\n::: {.cell}\n\n```{.r .cell-code}\nSimplified <- SaratogaHouses %>% \n  filter(fireplaces <= 1)\nMod <- lm(price ~ fireplaces, data = Simplified)\nMod_values <- model_eval(Mod, fireplaces = c(0,1))\nMod_values\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"font-family: Courier; width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fireplaces </th>\n   <th style=\"text-align:right;\"> .output </th>\n   <th style=\"text-align:right;\"> .lwr </th>\n   <th style=\"text-align:right;\"> .upr </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 174653.4 </td>\n   <td style=\"text-align:right;\"> -751.4332 </td>\n   <td style=\"text-align:right;\"> 350058.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 235162.9 </td>\n   <td style=\"text-align:right;\"> 59783.5404 </td>\n   <td style=\"text-align:right;\"> 410542.3 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n\n```{.r .cell-code}\nSimplified %>%\n  ggplot(aes(x=fireplaces, y = price)) +\n  geom_jitter() +\n  geom_errorbar(data=Mod_values, aes(ymin=.output, ymax=.output, x = fireplaces), y=NA,\n                color=\"blue\")\n```\n\n::: {.cell-output-display}\n![](NTI-Lesson30_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nFrom the graphic, you can see that houses with a fireplace tend to have higher prices. From the report of the evaluated model, you can calculate the effect size: $235K for a house with a fireplace, $175K for a house without one. This suggests the value of a fireplace is $60K. \n\nThere are, of course, many other things that determine the price of a house. Real-estate agents famously list the three most important factors as \"location, location, and location.\" Common sense brings in other explanatory variables: how big the house is, how luxurious, how many bathrooms, and so on. The statistical thinker knows to put any one explanatory variable into the context of other plausable factors. \n\nFor simplicity, let's collect all the factors other than `fireplaces` into a hypothetical variable which we will call \"`fancy`.\" Here are three plausible DAGs that plausibly describe an affect of fireplace on `price` in the context of `fancy`.\n\n:::: {.content-visible when-format=\"html\"}\n::: {#fig-fireplace-dags .cell .column-page-right layout-ncol=\"3\"}\n::: {.cell-output-display}\n![Dag A](NTI-Lesson30_files/figure-html/fig-fireplace-dags-1.png){#fig-fireplace-dags-1 width=33%}\n:::\n\n::: {.cell-output-display}\n![Dag B](NTI-Lesson30_files/figure-html/fig-fireplace-dags-2.png){#fig-fireplace-dags-2 width=33%}\n:::\n\n::: {.cell-output-display}\n![Dag C](NTI-Lesson30_files/figure-html/fig-fireplace-dags-3.png){#fig-fireplace-dags-3 width=33%}\n:::\n\nScenarios relating the price of a house to having a fireplace\n:::\n::::\n\n:::: {.content-visible when-format=\"pdf\"}\n::: {.callout-warning}\nManually insert the three-part figure as a single png\n:::\n::::\n\nIn DAG A, `fancy` and `fireplace` both contribute to `price`, but independently. In DAG B, `fireplace` directly contributes to `price`, but whether or not a house has a fireplace depends on the level of `fancy`. In DAG D, `fireplace` has no direct affect on `price`, which is set entirely by `fancy`. The `fireplace` variable is just an indicator of `fancy`.\n\nWe can't say from the data alone which of these three DAGs is the closest description of the situation. In Lessons 28, 30, and 31 we will consider how the choice of explanatory variables in a model leads to a faithful or misleading picture of the connections. There you will find out that DAGS A & B both imply that `fancy` should be an explanatory variable if we want the effect size from the model to represent the **direct** effect of a fireplace on price. Easy enough to fit that model, ... except that we don't have an actual variable `fancy` in the `SaratogaHouses` data frame. To keep things simple for the moment, we will use `livingArea`---the size of the house---as a rough approximation to the hypothetical `fancy`.\n\nThe effect size of `fireplaces` on `price` is found by comparing the model output for houses with and without a fireplace, *holding the values of all the other explanatory variables* **constant**.\n\n::: {.cell}\n\n```{.r .cell-code}\nMod2 <- lm(price ~ fireplaces + livingArea, data = Simplified)\nmodel_eval(Mod2, fireplaces = c(0,1), livingArea = 2000)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"font-family: Courier; width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fireplaces </th>\n   <th style=\"text-align:right;\"> livingArea </th>\n   <th style=\"text-align:right;\"> .output </th>\n   <th style=\"text-align:right;\"> .lwr </th>\n   <th style=\"text-align:right;\"> .upr </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 2000 </td>\n   <td style=\"text-align:right;\"> 234706.4 </td>\n   <td style=\"text-align:right;\"> 101212.9 </td>\n   <td style=\"text-align:right;\"> 368199.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2000 </td>\n   <td style=\"text-align:right;\"> 240420.8 </td>\n   <td style=\"text-align:right;\"> 106988.7 </td>\n   <td style=\"text-align:right;\"> 373852.8 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n:::\nFor a house with living area 2000 feet^2^, the model output is $235K with no fireplace and $240K with a fireplace, putting the effect size of `fireplace` on `price` at $5K. That's much smaller than the previous model, `price ~ fireplace`, gave for the effect size. The reason for the difference in results from the two models is that houses with fireplaces tend to be larger in area. \n\n---------\n\n\n\n\n\n::: {.callout-warning}\n## Note in draft: For the confounding section\n\nAn idea ...\n\n\nSuppose the DAG is that fireplaces cause living area (`fancy`) and that both of these cause price. That's distinct from DAG C in the above, because the causal arrow from `fancy` to `fireplace` is reversed. Could we decide between DAG C and this new DAG. How about the models `fireplace ~ livingArea` versus `fireplace` versus `fancy` plus `price`.\n:::\n\n--------\n\nFor models that are constructed by adding together different terms, like the `price ~ fireplaces + livingArea` model of the previous example, the estimated effect size for a given term is the corresponding model coefficient. The confidence interval on that effect size is simply the confidence interval on the coefficient. For example, for fireplaces:\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(price ~ fireplaces + livingArea, data = Simplified) %>% confint()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"font-family: Courier; width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> lwr </th>\n   <th style=\"text-align:right;\"> upr </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 6979.0960 </td>\n   <td style=\"text-align:right;\"> 27188.993 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fireplaces </td>\n   <td style=\"text-align:right;\"> -1521.3683 </td>\n   <td style=\"text-align:right;\"> 12950.131 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> livingArea </td>\n   <td style=\"text-align:right;\"> 102.7093 </td>\n   <td style=\"text-align:right;\"> 114.913 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n:::\n\nThus, the confidence interval for the effect of a fireplace ranges from negative $1500 to positive $13,000. Broad though this may seem at first, it does carry genuine information. You can be confident that a fireplace alone will not add as much as $50,000 to the price of the house, nor will it cause the house's value to fall by $10,000. \n\nThe confidence interval on the `livingArea` is pretty narrow $103 to $115 per square foot. If you're looking to save a bit of money by shopping for a slighly smaller house, say 200 square-feet smaller, you can adjust your budget downwards by something in the range of $206,000 to $230,000. The units here come from multiplying the area units (square feet) by the effect size units (dollars per square feet), producing a quantity denominated in dollars.\n\nIt's important always to keep in mind that an estimate of an effect size will likely be misleading if your choice of model seriously misrepresents reality. For instance, a salesperson hawking add-on fireplaces might show you results from the \"obvious\" model `price ~ fireplace`, leading to an effect size of $52,000 to $69,000, calculated this way.\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(price ~ fireplaces, data = Simplified) %>% confint()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"font-family: Courier; width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> lwr </th>\n   <th style=\"text-align:right;\"> upr </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 168209.69 </td>\n   <td style=\"text-align:right;\"> 181097.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fireplaces </td>\n   <td style=\"text-align:right;\"> 51899.26 </td>\n   <td style=\"text-align:right;\"> 69119.92 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n:::\n\nIt would be unfair to say that the $52,000 to $69,000 claim is a lie; it's entirely consistent with the data. But it relies on a grossly implausible description of the factors that determine house price.\n\n\n\n--------\n\n## 30.1\n\nDags with longer confounding pathways. Is there mixing when leaving out an element in the pathway. Mix up the directions of the arrows and show that the mixing occurs when the covariate is *included* in the model.\n\nRegression to the mean example.\n\nCollider?\n\n\n\n::: {.callout-note}\n## Solution\n\n:::\n\n--------\n\n\n\n## Documenting software\n\n  \n\n## Ideas\n\n- Diagram the anti-lock brake situation, why the introduction of anti-lock brakes increased the number of accidents.\n",
    "supporting": [
      "NTI-Lesson30_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}