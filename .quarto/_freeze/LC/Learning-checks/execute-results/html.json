{
  "hash": "72592a610ed4f50710995c5f2264c0bb",
  "result": {
    "markdown": "---\ntitle: \"Learning Checks from *Modern Dive*\"\n---\n\n\n\n\n## Chapter 1: Getting started\n\n\n\n::: {.callout-note icon=false}\n## LC 1.1 Block 1 Day 1\n\nRepeat the earlier installation steps, but for the `dplyr`, `nycflights13`, and `knitr` packages. This will install the earlier mentioned `dplyr` package for data wrangling, the `nycflights13` package containing data on all domestic flights leaving a NYC airport in 2013, and the `knitr` package for generating easy-to-read tables in R. We'll use these packages in the next section.\n:::\n\n\n\n::: {.callout-note icon=false}\n## LC 1.2  Block 1 Day 1\n\n\"Load\" the `dplyr`, `nycflights13`, and `knitr` packages as well by repeating the earlier steps.\n:::\n\n\nRun `View(flights)` \\index{R packages!utils!View()} in your console in RStudio, either by typing it or cutting-and-pasting it into the console pane. Explore this data frame in the resulting pop up viewer. You should get into the habit of viewing any data frames you encounter. Note the uppercase `V` in `View()`. R is case-sensitive, so you'll get an error message if you run `view(flights)` instead of `View(flights)`\n\n::: {.callout-note icon=false}\n## LC 1.3  Block 1 Day 1\n\nWhat does any *ONE* row in this `flights` dataset refer to?\n\n- A. Data on an airline \n- B. Data on a flight\n- C. Data on an airport\n- D. Data on multiple flights\n:::\n\n\n::: {.callout-note icon=false}\n## LC 1.4  Block 1 Day 1\n\nWhat are some other examples in this dataset (`flights`) of *categorical* variables?  What makes them different than *quantitative* variables?\n:::\n\n\n\n\n::: {.callout-note icon=false}\n## LC 1.5  Block 1 Day 1\n\nWhat properties of each airport do the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` describe in the `airports` data frame? Take your best guess.\n\n:::\n\n\n::: {.callout-note icon=false}\n## LC 1.6  Block 1 Day 1\n\nProvide the names of variables in a data frame with at least three variables where one of them is an identification variable and the other two are not. Further, create your own tidy data frame that matches these conditions.\n:::\n\n\n\n\n::: {.callout-note icon=false}\n## LC 1.7  Block 1 Day 1\n\nLook at the help file for the `airports` data frame. Revise your earlier guesses about what the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` each describe.\n:::\n\n\n\n\n\n## Chapter 2: Visualization\n\n\n\n::: {.callout-note icon=false}\n## LC 2.1 Block 1 Day 2\n\nTake a look at both the `flights` and `alaska_flights` data frames by running `View(flights)` and `View(alaska_flights)`. In what respect do these data frames differ? For example, think about the number of rows in each dataset.\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.2-2.6  Block 1 Day 2\n\n What are some practical reasons why `dep_delay` and `arr_delay` have a positive relationship?\n\n What variables in the `weather` data frame would you expect to have a negative correlation (i.e., a negative relationship) with `dep_delay`? Why? Remember that we are focusing on numerical variables here. Hint: Explore the `weather` dataset by using the `View()` function. \n\nWhy do you believe there is a cluster of points near (0, 0)? What does (0, 0) correspond to in terms of the Alaska Air flights?\n\nWhat are some other features of the plot that stand out to you?\n\nCreate a new scatterplot using different variables in the `alaska_flights` data frame by modifying the example given.\n\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.7-2.8 Block 1 Day 2\n\nWhy is setting the `alpha` argument value useful with scatterplots? What further information does it give you that a regular scatterplot cannot?\n\nAfter viewing Figure \\@ref(fig:alpha), give an approximate range of arrival delays and departure delays that occur most frequently. How has that region changed compared to when you observed the same plot without `alpha = 0.2` set in Figure \\@ref(fig:noalpha)?\n:::\n\n\n\n::: {.callout-note icon=false}\n## LC 2.9-2.10  Block 1 Day 3\n\n**LC 2.9** Take a look at both the `weather` and `early_january_weather` data frames by running `View(weather)` and `View(early_january_weather)`. In what respect do these data frames differ?\n\n**LC 2.10** `View()` the `flights` data frame again. Why does the `time_hour` variable uniquely identify the hour of the measurement, whereas the `hour` variable does not? \n:::\n\n::: {.callout-note icon=false}\n## LC 2.11-2.13  Block 1 Day 3\n\n**LC 2.11** Why should linegraphs be avoided when there is not a clear ordering of the horizontal axis?\n\n**LC 2.12** Why are linegraphs frequently used when time is the explanatory variable on the x-axis?\n\n**LC 2.12** Plot a time series of a variable other than `temp` for Newark Airport in the first 15 days of January 2013.\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.18-2.21  Block 1 Day 3\n\nWhat other things do you notice about this faceted plot?  How does a faceted plot help us see relationships between two variables?\n\nWhat do the numbers 1-12 correspond to in the plot?  What about 25, 50, 75, 100?\n\nFor which types of datasets would faceted plots not work well in comparing relationships between variables? Give an example describing the nature of these variables and other important characteristics.\n\n**LC 2.21** Does the `temp` variable in the `weather` dataset have a lot of variability?  Why do you say that?\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.22-2.25 Boxplots  Block 1 Day 4\n\n**LC 2.22** What does the dot at the bottom of the plot for May correspond to?  Explain what might have occurred in May to produce this point.\n\n**LC 2.23** Which months have the highest variability in temperature?  What reasons can you give for this?\n\n**LC 2.24** We looked at the distribution of the numerical variable `temp` split by the numerical variable `month` that we converted using the `factor()` function in order to make a side-by-side boxplot. Why would a boxplot of `temp` split by the numerical variable `pressure` similarly converted to a categorical variable using the `factor()` not be informative?\n\n**LC 2.25** Boxplots provide a simple way to identify outliers.  Why may outliers be easier to identify when looking at a boxplot instead of a faceted histogram?\n:::\n\n\n\n\n\n\n::: {.callout-note icon=false}\n## LC 2.26-2.29 Histograms  Block 1 Day 4\n\n**LC 2.26** Why are histograms inappropriate for categorical variables?\n\n**LC 2.27** What is the difference between histograms and barplots?\n\n**LC 2.28** How many Envoy Air flights departed NYC in 2013?\n\n**LC 2.29** What was the 7th highest airline for departed flights from NYC in 2013? How could we better present the table to get this answer quickly?\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.30-2.31 Pie charts  Block 1 Day 4\n\n**LC 2.30** Why should pie charts be avoided and replaced by barplots?\n\n**LC 2.31** Why do you think people continue to use pie charts?\n:::\n\n\n::: {.callout-note icon=false}\n## LC 2.32-2.37  Block 1 Day 4\n\n**LC 2.32** What kinds of questions are not easily answered by looking at Figure \\@ref(fig:flights-stacked-bar) (2.23)?\n\n**LC 2.33** What can you say, if anything, about the relationship between airline and airport in NYC in 2013 in regards to the number of departing flights?\n\n**LC 2.34** Why might the side-by-side barplot be preferable to a stacked barplot in this case?\n\n**LC 2.35** What are the disadvantages of using a dodged barplot, in general?\n\n**LC 2.36** Why is the faceted barplot preferred to the side-by-side and stacked barplots in this case?\n\n**LC 2.37** What information about the different carriers at different airports is more easily seen in the faceted barplot?\n:::\n\n\n## Chapter 3: Wrangling\n\n\n\n::: {.callout-note icon=false}\n## LC 3.1  Block 1 Day 5\nWhat's another way of using the \"not\" operator `!` to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the `flights` data frame? Test this out using the previous code.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.2 Block 1 Day 5\nSay a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five-year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor's approach?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.3 Block 1 Day 5\nModify the earlier `summarize()` function code that creates the `summary_temp` data frame to also use the `n()` summary function: `summarize(... , count = n())`. What does the returned value correspond to?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.4 Block 1 Day 5\nWhy doesn't the following code work?  Run the code line-by-line instead of all at once, and then look at the data.  In other words, run `summary_temp <- weather %>% summarize(mean = mean(temp, na.rm = TRUE))` first.\n:::\n\n::: {.callout-note icon=false}\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_temp <- weather %>%   \n  summarize(mean = mean(temp, na.rm = TRUE)) %>% \n  summarize(std_dev = sd(temp, na.rm = TRUE))\n```\n:::\n\n:::\n\n::: {.callout-note icon=false}\n## LC 3.5  Block 1 Day 6\nRecall from Chapter \\@ref(viz) when we looked at temperatures by months in NYC. What does the standard deviation column in the `summary_monthly_temp` data frame tell us about temperatures in NYC throughout the year?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.6   Block 1 Day 6\nWhat code would be required to get the mean and standard deviation temperature for each day in 2013 for NYC?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.7   Block 1 Day 6\nRecreate `by_monthly_origin`, but instead of grouping via `group_by(origin, month)`, group variables in a different order `group_by(month, origin)`. What differs in the resulting dataset?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.8   Block 1 Day 6\nHow could we identify how many flights left each of the three airports for each `carrier`?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.9  Block 1 Day 6\nHow does the `filter()` operation differ from a `group_by()` followed by a `summarize()`?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.10  Block 1 Day 6\nWhat do positive values of the `gain` variable in `flights` correspond to?  What about negative values?  And what about a zero value?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.11  Block 1 Day 6\nCould we create the `dep_delay` and `arr_delay` columns by simply subtracting `dep_time` from `sched_dep_time` and similarly for arrivals?  Try the code out and explain any differences between the result and what actually appears in `flights`.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.12  Block 1 Day 76\nWhat can we say about the distribution of `gain`?  Describe it in a few sentences using the plot and the `gain_summary` data frame values.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.13  Block 1 Day 7\nLooking at Figure \\@ref(fig:reldiagram), when joining `flights` and `weather` (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of `year`, `month`, `day`, `hour`, and `origin`, and not just `hour`?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.14  Block 1 Day 7\nWhat surprises you about the top 10 destinations from NYC in 2013?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.15  Block 1 Day 7\nWhat are some advantages of data in normal forms?  What are some disadvantages?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.16  Block 1 Day 7\nWhat are some ways to select all three of the `dest`, `air_time`, and `distance` variables from `flights`?  Give the code showing how to do this in at least three different ways.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.17  Block 1 Day 7\nHow could one use `starts_with()`, `ends_with()`, and `contains()` to select columns from the `flights` data frame?  Provide three different examples in total: one for `starts_with()`, one for `ends_with()`, and one for `contains()`.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.18  Block 1 Day 7\nWhy might we want to use the `select` function on a data frame?\n:::\n\n::: {.callout-note icon=false}\n## LC 3.19  Block 1 Day 7\nCreate a new data frame that shows the top 5 airports with the largest arrival delays from NYC in 2013.\n:::\n\n::: {.callout-note icon=false}\n## LC 3.20  Block 1 Day 7\nLet's now put your newly acquired data wrangling skills to the test!\n\nAn airline industry measure of a passenger airline's capacity is the [available seat miles](https://en.wikipedia.org/wiki/Available_seat_miles), which is equal to the number of seats available multiplied by the number of miles or kilometers flown summed over all flights. \n\nFor example, let's consider the scenario in @fig-available-seat-miles. Since the airplane has 4 seats and it travels 200 miles, the available seat miles are $4 \\times 200 = 800$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example of available seat miles for one flight.](images/flowchart.012.png){#fig-available-seat-miles width=512 height=40%}\n:::\n:::\n\n\nExtending this idea, let's say an airline had 2 flights using a plane with 10 seats that flew 500 miles and 3 flights using a plane with 20 seats that flew 1000 miles, the available seat miles would be $2 \\times 10 \\times 500 + 3 \\times 20 \\times 1000 = 70,000$ seat miles. \n\nUsing the datasets included in the `nycflights13` package, compute the available seat miles for each airline sorted in descending order. After completing all the necessary data wrangling steps, the resulting data frame should have 16 rows (one for each airline) and 2 columns (airline name and available seat miles). Here are some hints:\n\n1. **Crucial**: Unless you are very confident in what you are doing, it is worthwhile not starting to code right away. Rather, first sketch out on paper all the necessary data wrangling steps not using exact code, but rather high-level *pseudocode* that is informal yet detailed enough to articulate what you are doing. This way you won't confuse *what* you are trying to do (the algorithm) with *how* you are going to do it (writing `dplyr` code). \n1. Take a close look at all the datasets using the `View()` function: `flights`, `weather`, `planes`, `airports`, and `airlines` to identify which variables are necessary to compute available seat miles.\n1. Figure \\@ref(fig:reldiagram) showing how the various datasets can be joined will also be useful. \n1. Consider the data wrangling verbs in Table \\@ref(tab:wrangle-summary-table) as your toolbox!\n::\n\n## Chapter 4: Tidy\n\n\n::: {.callout-note icon=false}\n## LC 4.1   Block 1 Day 8\nWhat are common characteristics of \"tidy\" data frames?\n::\n\n::: {.callout-note icon=false}\n## LC 4.2  Block 1 Day 8\nWhat makes \"tidy\" data frames useful for organizing data?\n::\n\n::: {.callout-note icon=false}\n## LC 4.3  Block 1 Day 8\nTake a look at the `airline_safety` data frame included in the `fivethirtyeight` data package. Run the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairline_safety\n```\n:::\n\n\nAfter reading the help file by running `?airline_safety`, we see that `airline_safety` is a data frame containing information on different airline companies' safety records. This data was originally reported on the data journalism website, FiveThirtyEight.com, in Nate Silver's article, [\"Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past?\"](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/). Let's only consider the variables `airlines` and those relating to fatalities for simplicity:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairline_safety_smaller <- airline_safety %>% \n  select(airline, starts_with(\"fatalities\"))\nairline_safety_smaller\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 56 × 3\n   airline               fatalities_85_99 fatalities_00_14\n   <chr>                            <int>            <int>\n 1 Aer Lingus                           0                0\n 2 Aeroflot                           128               88\n 3 Aerolineas Argentinas                0                0\n 4 Aeromexico                          64                0\n 5 Air Canada                           0                0\n 6 Air France                          79              337\n 7 Air India                          329              158\n 8 Air New Zealand                      0                7\n 9 Alaska Airlines                      0               88\n10 Alitalia                            50                0\n# … with 46 more rows\n```\n:::\n:::\n\n\nThis data frame is not in \"tidy\" format. How would you convert this data frame to be in \"tidy\" format, in particular so that it has a variable `fatalities_years` indicating the incident year and a variable `count` of the fatality counts?\n::\n\n::: {.callout-note icon=false}\n## LC 4.4  Block 1 Day 9\n Convert the `dem_score` data frame into\na \"tidy\" data frame and assign the name of `dem_score_tidy` to the resulting long-formatted data frame.\n::\n\n::: {.callout-note icon=false}\n## LC 4.5  Block 1 Day 9\n Read in the life expectancy data stored at <https://moderndive.com/data/le_mess.csv> and convert it to a \"tidy\" data frame. \n::\n\n## Chapter 5: Regression\n\n\n\n::: {.callout-note icon=false}\n## LC 5.1 Block 2 Day 1\nConduct a new exploratory data analysis with the same outcome variable $y$ being `score` but with `age` as the new explanatory variable $x$. Remember, this involves three things:\n\n(a) Looking at the raw data values.\n(a) Computing summary statistics.\n(a) Creating data visualizations.\n\nWhat can you say about the relationship between age and teaching scores based on this exploration?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.2  Block 2 Day 1\nFit a new simple linear regression using `lm(score ~ age, data = evals_ch5)` where `age` is the new explanatory variable $x$. Get information about the \"best-fitting\" line from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your earlier exploratory data analysis?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.3  Block 2 Day 1\nGenerate a data frame of the residuals of the model where you used `age` as the explanatory $x$ variable.\n:::\n\n::: {.callout-note icon=false}\n## LC 5.4  Block 2 Day 2\nConduct a new exploratory data analysis with the same explanatory variable $x$ being `continent` but with `gdpPercap` as the new outcome variable $y$. What can you say about the differences in GDP per capita between continents based on this exploration?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.5  Block 2 Day 2\nFit a new linear regression using `lm(gdpPercap ~ continent, data = gapminder2007)` where `gdpPercap` is the new outcome variable $y$. Get information about the \"best-fitting\" line from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your previous exploratory data analysis?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.6  Block 2 Day 2\nUsing either the sorting functionality of RStudio's spreadsheet viewer or using the data wrangling tools you learned in Chapter \\@ref(wrangling), identify the five countries with the five smallest (most negative) residuals? What do these negative residuals say about their life expectancy relative to their continents' life expectancy?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.7  Block 2 Day 2\nRepeat this process, but identify the five countries with the five largest (most positive) residuals. What do these positive residuals say about their life expectancy relative to their continents' life expectancy?\n:::\n\n::: {.callout-note icon=false}\n## LC 5.8  Block 2 Day 3\nNote in Figure @fig:three-lines there are 3 points marked with dots and:\n\n* The \"best\" fitting solid regression line in blue\n* An arbitrarily chosen dotted red line \n* Another arbitrarily chosen dashed green line\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Regression line and two others.](Learning-checks_files/figure-html/fig-three-lines-1.png){#fig-three-lines width=85%}\n:::\n:::\n\n\nCompute the sum of squared residuals by hand for each line and show that of these three lines, the regression line in blue has the smallest value.\n:::\n\n## Chapter 6: Multiple regression\n\n::: {.callout-note icon=false}\n## LC 6.1  Block 2 Day 4\nCompute the observed values, fitted values, and residuals not for the interaction model as we just did, but rather for the parallel slopes model we saved in `score_model_parallel_slopes`.\n:::\n\n::: {.callout-note icon=false}\n## LC 6.2  \nConduct a new exploratory data analysis with the same outcome variable $y$ `debt` but with `credit_rating` and `age` as the new explanatory variables $x_1$ and $x_2$. What can you say about the relationship between a credit card holder's debt and their credit rating and age?\n:::\n\n::: {.callout-note icon=false}\n## LC 6.3\nConduct a new exploratory data analysis with the same outcome variable $y$ `debt` but with `credit_rating` and `age` as the new explanatory variables $x_1$ and $x_2$. What can you say about the relationship between a credit card holder's debt and their credit rating and age?\n:::\n\n::: {.callout-note icon=false}\n## LC 6.4\n\nFit a new simple linear regression using `lm(debt ~ credit_rating + age, data = credit_ch6)` where `credit_rating` and `age` are the new numerical explanatory variables $x_1$ and $x_2$. Get information about the \"best-fitting\" regression plane from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your previous exploratory data analysis? \n:::\n\n## Chapter 7: Sampling\n\n\n\n\n::: {.callout-note icon=false}\n## LC 7.1 Block 3 Day 1\nWhy was it important to mix the bowl before we sampled the balls?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.2 Block 3 Day 1\nWhy is it that our 33 groups of friends did not all have the same numbers of balls that were red out of 50, and hence different proportions red?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.3 Block 3 Day 1\nWhy couldn't we study the effects of sampling variation when we used the virtual shovel only once? Why did we need to take more than one virtual sample (in our case 33 virtual samples)?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.4 Block 3 Day 1\nWhy did we not take 1000 \"tactile\" samples of 50 balls by hand?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.5 Block 3 Day 1\nLooking at Figure \\@ref(fig:samplingdistribution-virtual-1000), would you say that sampling 50 balls where 30% of them were red is likely or not? What about sampling 50 balls where 10% of them were red?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.6 Block 3 Day 1\nIn Figure 7.9, we used shovels to take 1000 samples each, computed the resulting 1000 proportions of the shovel's balls that were red, and then visualized the distribution of these 1000 proportions in a histogram. We did this for shovels with 25, 50, and 100 slots in them. As the size of the shovels increased, the histograms got narrower. In other words, as the size of the shovels increased from 25 to 50 to 100, did the 1000 proportions\n\n- A. vary less,\n- B. vary by the same amount, or\n- C. vary more?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.7 Block 3 Day 1\nWhat summary statistic did we use to quantify how much the 1000 proportions red varied?\n\n- A. The interquartile range\n- B. The standard deviation\n- C. The range: the largest value minus the smallest.\n:::\n\n::: {.callout-note icon=false}\n## LC 7.8 Block 3 Day 2\nIn the case of our bowl activity, what is the *population parameter*? Do we know its value?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.9 Block 3 Day 2\nWhat would performing a census in our bowl activity correspond to? Why did we not perform a census?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.10 Block 3 Day 2\nWhat purpose do *point estimates* serve in general? What is the name of the point estimate specific to our bowl activity? What is its mathematical notation?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.11 Block 3 Day 2\nHow did we ensure that our tactile samples using the shovel were random?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.12 Block 3 Day 2\nWhy is it important that sampling be done *at random*?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.13 Block 3 Day 2\nWhat are we *inferring* about the bowl based on the samples using the shovel?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.14 Block 3 Day 2\nWhat purpose did the *sampling distributions* serve?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.15 Block 3 Day 2\nWhat does the *standard error* of the sample proportion $\\widehat{p}$ quantify? \n:::\n\n::: {.callout-note icon=false}\n## LC 7.16 Block 3 Day 2\nThe table that follows is a version of Table \\@ref(tab:comparing-n-2) matching sample sizes $n$ to different *standard errors* of the sample proportion $\\widehat{p}$, but with the rows randomly re-ordered and the sample sizes removed. Fill in the table by matching the correct sample sizes to the correct standard errors.\n\n\nStandard errors of $\\hat{p}$ based on n = 25, 50, 100\n\nSample size | Standard error of $\\hat{p}$\n------------|----------------------------\n$n=$ | 0.94\n$n=$ | 0.45\n$n=$ | 0.69\n\n\nFor the following four *Learning checks*, let the *estimate* be the sample proportion $\\widehat{p}$: the proportion of a shovel's balls that were red. It estimates the population proportion $p$: the proportion of the bowl's balls that were red.\n:::\n\n::: {.callout-note icon=false}\n## LC 7.17 Block 3 Day 2\nWhat is the difference between an *accurate* and a *precise* estimate? \n:::\n\n::: {.callout-note icon=false}\n## LC 7.18 Block 3 Day 2\nHow do we ensure that an estimate is *accurate*? How do we ensure that an estimate is *precise*?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.19 Block 3 Day 2\nIn a real-life situation, we would not take 1000 different samples to infer about a population, but rather only one. Then, what was the purpose of our exercises where we took 1000 different samples?\n:::\n\n::: {.callout-note icon=false}\n## LC 7.20 Block 3 Day 2\nFigure \\@ref(fig:accuracy-vs-precision) with the targets shows four combinations of \"accurate versus precise\" estimates. Draw four corresponding *sampling distributions* of the sample proportion $\\widehat{p}$, like the one in the leftmost plot in Figure \\@ref(fig:comparing-sampling-distributions-3).\n:::\n\n::: {.callout-note icon=false}\n## LC 7.21 Block 3 Day 3\nThe Royal Air Force wants to study how resistant all their airplanes are to bullets. They study the bullet holes on all the airplanes on the tarmac after an air battle against the Luftwaffe (German Air Force).\n:::\n\n::: {.callout-note icon=false}\n## LC 7.22 Block 3 Day 3\nImagine it is 1993, a time when almost all households had landlines. You want to know the average number of people in each household in your city. You randomly pick out 500 phone numbers from the phone book and conduct a phone survey.\n:::\n\n::: {.callout-note icon=false}\n## LC 7.23 Block 3 Day 3\nYou want to know the prevalence of illegal downloading of TV shows among students at a local college.  You get the emails of 100 randomly chosen students and ask them, \"How many times did you download a pirated TV show last week?\".\n:::\n\n::: {.callout-note icon=false}\n## LC 7.24 Block 3 Day 3\nA local college administrator wants to know the average income of all graduates in the last 10 years. So they get the records of five randomly chosen graduates, contact them, and obtain their answers. \n:::\n\n\n\n\n\n## Chapter 8: Confidence intervals\n\n\n\n::: {.callout-note icon=false}\n## LC 8.1 Block 3 Day 5\nWhat is the chief difference between a bootstrap distribution and a sampling distribution?\n:::\n\n::: {.callout-note icon=false}\n## LC 8.2 Block 3 Day 5\nLooking at the bootstrap distribution for the sample mean in Figure \\@ref(fig:one-thousand-sample-means), between what two values would you say *most* values lie?\n:::\n\n::: {.callout-note icon=false}\n## LC 8.3 Block 3 Day 6\n\nWhat condition about the bootstrap distribution must be met for us to be able to construct confidence intervals using the standard error method?\n:::\n\n::: {.callout-note icon=false}\n## LC 8.4 Block 3 Day 6\nSay we wanted to construct a 68% confidence interval instead of a 95% confidence interval for $\\mu$. Describe what changes are needed to make this happen. Hint: we suggest you look at Appendix \\@ref(appendix-normal-curve) on the normal distribution.\n:::\n\n::: {.callout-note icon=false}\n## LC 8.5 Block 3 Day 8\nConstruct a 95% confidence interval for the *median* year of minting of *all* US pennies. Use the percentile method and, if appropriate, then use the standard-error method.\n:::\n\n\n\n\n\n\n\n## Chapter 9: Hypothesis testing\n\n\n\n\n::: {.callout-note icon=false}\n## LC 9.1 Block 4 Day 2\nWhy does the following code produce an error? In other words, what about the response and predictor variables make this not a possible computation with the `infer` package?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(moderndive)\nlibrary(infer)\nnull_distribution_mean <- promotions %>%\n  specify(formula = decision ~ gender, success = \"promoted\") %>% \n  hypothesize(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\"))\n```\n:::\n\n:::\n\n::: {.callout-note icon=false}\n## LC 9.2  Block 4 Day 2\nWhy are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of promotion proportions for the two genders?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.3 Block 4 Day 2\nUsing the definition of _p-value_, write in words what the $p$-value represents for the hypothesis test comparing the promotion rates for males and females.\n:::\n\n::: {.callout-note icon=false}\n## LC 9.4 Block 4 Day 2\nDescribe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between the promotion rate of males and females using this study.\n:::\n\n::: {.callout-note icon=false}\n## LC 9.5 Block 4 Day 3\nWhat is wrong about saying, \"The defendant is innocent.\" based on the US system of criminal trials?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.6 Block 4 Day 3\nWhat is the purpose of hypothesis testing?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.7 Block 4 Day 3\n What are some flaws with hypothesis testing?  How could we alleviate them?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.8 Block 4 Day 3\nConsider two $\\alpha$ significance levels of 0.1 and 0.01. Of the two, which would lead to a more *liberal* hypothesis testing procedure? In other words, one that will, all things being equal, lead to more rejections of the null hypothesis $H_0$.\n:::\n\n::: {.callout-note icon=false}\n## LC 9.9\nConduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same? \n:::\n\n::: {.callout-note icon=false}\n## LC 9.10\nWhat conclusions can you make from viewing the faceted histogram looking at `rating` versus `genre` that you couldn't see when looking at the boxplot?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.11\nDescribe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.\n:::\n\n::: {.callout-note icon=false}\n## LC 9.12\nWhy are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.13\nUsing the definition of $p$-value, write in words what the $p$-value represents for the hypothesis test comparing the mean rating of romance to action movies.\n:::\n\n::: {.callout-note icon=false}\n## LC 9.14\nWhat is the value of the $p$-value for the hypothesis test comparing the mean rating of romance to action movies?\n:::\n\n::: {.callout-note icon=false}\n## LC 9.15\nTest your data wrangling knowledge and EDA skills:\n\n- Use `dplyr` and `tidyr` to create the necessary data frame focused on only action and romance movies (but not both) from the `movies` data frame in the `ggplot2movies` package.\n- Make a boxplot and a faceted histogram of this population data comparing ratings of action and romance movies from IMDb.\n- Discuss how these plots compare to the similar plots produced for the `movies_sample` data.\n:::\n\n\n\n\n## Chapter 10: Inference for regression\n\n\n::: {.callout-note icon=false} \n## LC 10.1  Block 4 Day 7\nContinuing with our regression using `age` as the explanatory variable and teaching `score` as the outcome variable.\n\n- Use the `get_regression_points()` function to get the observed values, fitted values, and residuals for all 463 instructors. \n- Perform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern but comment on what you find here.\n:::\n\n\n::: {.callout-note icon=false} \n## LC 10.2 Block 4 Day 8\nRepeat the inference but this time for the correlation coefficient instead of the slope. Note the implementation of `stat = \"correlation\"` in the `calculate()` function of the `infer` package.\n:::\n\n\n\n\n\n\n## Chapter 11: Tell your story with data\n\n\n\n\n\n\n<!--\nv2 TODO: Inference for regression for Seattle house prices\n\n**` paste0(\"(LC\", chap, \".\", (lc <- lc + 1), \")\")`** Check that the LINE conditions are met for inference to be made in this Seattle house prices example.\n-->\n\n::: {.callout-note icon=false}\n## LC 11.1  Block 4 Day 2\nRepeat the regression modeling in Subsection 11.2.3 and the prediction making you just did on the house of condition 5 and size 1900 square feet in Subsection 12.2.4, but using the parallel slopes model you visualized in Figure 11.6. Show that it's $524,807!\n:::\n\n::: {.callout-note icon=false}\n## LC 11.2\nWhat date between 1994 and 2003 has the fewest number of births in the US? What story could you tell about why this is the case?\n:::\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "Learning-checks_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}