{
  "hash": "9ee21aa76c97a33c91401d19b4d267ca",
  "result": {
    "markdown": "---\ntitle: \"Learning Checks Lesson 19\"\n---\n\n\n## Setup\n\nThe `math300` package will be needed for lessons 20 through 39.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(math300)\nlibrary(moderndive)\nlibrary(NHANES)\n```\n:::\n\n\n\n1.  One of these pipeline commands will work and the other won't. Which one will work? Explain why the other one doesn't work.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    lm(net ~ age, data = TenMileRace)\n    TenMileRace %>% lm(net ~ age)\n    ```\n    :::\n\n\n2.  An example from the *OpenIntro* book uses data on promotions. Some data wrangling commands that might be relevant are these:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    promotions %>% tally()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    # A tibble: 1 × 1\n          n\n      <int>\n    1    48\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    promotions %>% group_by(decision) %>% tally()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    # A tibble: 2 × 2\n      decision     n\n      <fct>    <int>\n    1 not         13\n    2 promoted    35\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    promotions %>% group_by(gender) %>% tally()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    # A tibble: 2 × 2\n      gender     n\n      <fct>  <int>\n    1 male      24\n    2 female    24\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    promotions %>% group_by(gender, decision) %>% tally()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    # A tibble: 4 × 3\n    # Groups:   gender [2]\n      gender decision     n\n      <fct>  <fct>    <int>\n    1 male   not          3\n    2 male   promoted    21\n    3 female not         10\n    4 female promoted    14\n    ```\n    :::\n    :::\n\n\nYou could use such wrangling to compare groups. For instance, you can use the results of the last command to calculate separately the proportion of males who were promoted and, similarly, the proportion of females.\n\na\\. **What are those proportions?**\n\nThe following wrangling command will calculate the proportions for you, but it is a bit complicated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions %>%\n  group_by(gender) %>%\n  summarize(prop_promoted = sum(decision==\"promoted\") / n())\n```\n:::\n\n\nb\\. **Use the above command to check your calculations in (a).**\n\nc\\. In the regression paradigm, the comparison of proportions between the two groups is done directly in `lm()`, like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions %>%\n  mutate(promoted = zero_one(decision, one=\"promoted\")) %>%\n  lm(promoted ~ gender, data = .) %>%\n  coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) genderfemale \n   0.8750000   -0.2916667 \n```\n:::\n:::\n\n\nWe'll explain the purpose of `zero_one()` in Lesson 19, but putting that matter aside for a moment, compare the two coefficients in the regression model to the proportion results you got from wrangling.\n\ni.  **What does the value of the intercept coefficient correspond to in the wrangling results?**\n\nii. **What does the `genderfemale` coefficient correspond to in the wrangling results?** (Hint: you will have to do a bit of arithmetic on the wrangling results.)\n\n\n\n\n\n## 19.1\n\nConsider the `moderndive::evals` data that records students' evaluations (`score`, on a 1-5 scale) of the professors in each of several courses (the course `ID`), as well as the `age`, \"average beauty rating\" (`bty_avg`) of the professor, enrollment in the course (`cls_students`) and the level o the course (`cls_level`). Each row in the data frame is an individual course section.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n|  ID| score| age| bty_avg| cls_students|cls_level |\n|---:|-----:|---:|-------:|------------:|:---------|\n| 329|   2.7|  64|   2.333|           22|upper     |\n| 313|   4.2|  42|   2.667|           86|upper     |\n| 430|   4.5|  33|   5.833|          120|lower     |\n|  95|   4.2|  48|   4.333|           33|upper     |\n| 209|   4.8|  60|   3.667|           34|upper     |\n| 442|   3.6|  61|   3.333|           39|lower     |\n| 351|   4.6|  50|   3.333|           26|lower     |\n| 317|   3.7|  52|   6.500|           44|upper     |\n| 444|   4.1|  52|   4.500|          111|lower     |\n| 315|   3.8|  52|   6.000|           88|upper     |\n:::\n:::\n\n\nThe following commands model `score` versus `age` and plots the data as a point plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(score ~ age, data = moderndive::evals) %>% coef()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)          age \n 4.461932354 -0.005938225 \n```\n:::\n\n```{.r .cell-code}\nopenintro::evals %>% gf_point(score ~ age, alpha=0.2 )\n```\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n1. Explain why some of the dots are darker than others?\n\n::: {.callout-note}\n## Solution\n\nAll the ages have integer values---e.g., 43, 44, 45---so the dots line up in vertical lines.\n\nSimilarly, the scores have values only to one decimal place---e.g., 3.1, 3.2, 3.3---so the dots line up in horizontal lines. If there are two or more rows in `evals` that have the same age and score, the dots will be plotted over one another. Since transparency (`alpha = 0.2`) is being used, points where there is a lot of overplotting will appear darker.\n:::\n\n2. Remake the plot, but using `gf_jitter()` instead of `gf_point()`. Explain what's different about the jittered plot. (Hint: Almost all of the dots are the same lightness.)\n\n::: {.callout-note}\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenintro::evals %>% gf_jitter(score ~ age, alpha=0.2 )\n```\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\"Jittering\" means to shift each dot by a small random amount. This reduces the number of instances where dots are overplotted.\n:::\n\n3. Now make a jitter plot of score versus class level (`cls_level`).\n    a. What do the tick-mark labels on the horizontal axis describe? Are they numerical?\n    b. To judge from the plot, are their more lower-level than upper-level courses? Explain briefly what graphical feature lets you answer this question at a glance.\n\n::: {.callout-note}\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenintro::evals %>% gf_jitter(score ~ cls_level)\n```\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\na. The tick-mark labels are the levels of the categorical variable `cls_level`. The are words, not numbers.\nb. There are many more dots in the right column than in the left. Since `lower` level class are shown in the left column, there are fewer lower-level courses than upper-level courses. \n:::\n\n4. The two columns of points in the plot you made in (3) are not separated by very much empty space. You can fix this by giving `gf_jitter()` an argument `width=0.2`. Try different numerical values for `width` and report which one you find most effective at making the two columns clearly separated while avoiding overplotting.\n\n5. Are the scores, on average, different for the lower- vs upper-level classes? It's hard to get more than a rough idea of the distribution of scores by looking at the \"density\" of points. The reason is that the number of points differs in the two columns. But there is an easy fix: add a layer to the graphic that shows the distribution (more or less like a histogram displays a distribution of values). You can do this by piping the jitter plot layer into a geom called a \"violin,\" like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenintro::evals %>% \n  gf_jitter(score ~ cls_level) %>%\n  gf_violin(fill=\"blue\", alpha=0.2, color=NA)\n```\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nExplain how to read the violins.\n\n--------\n\n## 19.2\n\nThe `openintro::promotions` data comes the the 1970s and records the gender of 38 people along with the result of a decision to promote (or not) the person. =\n\nChapter 2 of ModernDive suggests graphically depicting `decision` versus `gender` by using a bar plot. There are two ways to make the bar plot, depending on which variable you assign to the horizontal axis and which to the fill color.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions %>% gf_bar(~ decision, fill=~ gender)\npromotions %>% gf_bar(~ gender, fill=~decision)\n```\n\n::: {.cell-output-display}\n![Two different ways to plot promotion outcome and gender](LC-lesson19_files/figure-html/fig-promotion-bars-1.png){#fig-promotion-bars-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Two different ways to plot promotion outcome and gender](LC-lesson19_files/figure-html/fig-promotion-bars-2.png){#fig-promotion-bars-2 width=672}\n:::\n:::\n\n\nPlots like those in @fig-promotion-bars might be attractive or not, depending on your taste. What they don't accomplish is to make sure which is the response variable and which the explanatory variable.\n\nThe choice of response and explanatory variables depends, of course, on what you are trying to display. But everyday English gives a big hint. For instance, you might describe the question at hand as, \"Does gender affect promotion decisions.\" Here, the variable doing the affecting is `gender`, and the outcome is the `decision`.\n\nModeling decision as a function of gender is easy once you convert the response variable to a zero-one variable. Like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(zero_one(decision, one=\"promoted\") ~ gender, data = promotions)\ncoefficients(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) genderfemale \n   0.8750000   -0.2916667 \n```\n:::\n\n```{.r .cell-code}\nmosaicModel::mod_eval(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  gender model_output\n1   male    0.8750000\n2 female    0.5833333\n```\n:::\n:::\n\n\n1. Explain what is the relationship between the model coefficients and the model outputs.\n\n::: {.callout-note}\n## Solution\n\nThe coefficients tell how to calculate the model output. These coefficients say that the model output will be 0.875, but subtract 0.292 if the person is female.\n\nThe model outputs give the probability of being promoted for each of the two genders.\n:::\n\n2. Make this plot and explain what the red lines show. (We don't expect you to be able to write the command to generate such plots on your own, but we do expect you to be able to interpret them.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions %>% \n  gf_jitter(zero_one(decision) ~ gender, height=0.2, width=0.2) %>%\n  gf_errorbar(model_output + model_output ~ gender, data=mod_eval(mod), \n              color=\"red\", inherit=FALSE) %>%\n  label_zero_one()\n```\n:::\n\n\n::: {.callout-note}\n## Solution\n\nThe red lines show the proportion of the people in each gender group who were promoted. The y-axis scale on the left refers to the zero-one encoding of `decision`, while the y-axis labels on the right make it easier to read off the numerical value of the proportion.\n:::\n\n--------\n\n## 19.3\n\nThe `mosaicData::Whickham` data from comes from a survey of a thousand or so nurses in the UK in the 1970s. The data record the `age` of each nurse along with whether the nurse was still alive in a follow-up survey 20 years later (`outcome`).\n\nMake this graph from the `Whickham` data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_jitter(zero_one(outcome) ~ age, data = Whickham, alpha=0.3, height=0.1) %>% \n  label_zero_one() \n```\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n1. Explain in everyday language what the graph shows about the lives of humans.\n\n2. Make the graph again, but leave out the `%>% label_zero_one()`. Then explain what `label_zero_one()` does.\n\n::: {.callout-note}\n## Solution\n\n1. The graph shows that young nurses tended to be alive at the 20-year follow-up, older nurses not so much.\n\n2. `%>% label_zero_one()` adds an axis on the left of the graph showing that in the zero-one tranform of `outcome`, \"Alive\" is assigned the value 1 and \"Dead\" the value 0.\n:::\n\n### Solution\n\n--------\n\n## 19.4\n\nAbout the summarization of models. Pipe the model fit into any of four functions:\n\ni. `%>% coef()`\nii. `%>% regression_summary()`\niii. `%>% rsquared()`\niv. `%>% confint()`\n\nREDO `confint()` so that the columns are named `lower`, `middle`, `upper`\n\n### Solution\n\n\n--------\n\n## 19.5 (Obj. 19.3)\n\nCalculation of a 95% coverage interval (or any other percent level interval) is straightforward with the right software. To illustrate, consider the efficiency of cars and light trucks in terms of CO_2 emissions per mile driven. We'll use the `CO2city` variable in the `math300::MPG` data frame. The basic calculation using the `mosaic` package is:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_stats( ~ CO2city, data = math300::MPG, coverage(0.95))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  response   lower   upper\n1  CO2city 276.475 684.525\n```\n:::\n:::\n\n\nThe following figure shows a violin plot of `CO2city` which has been annotated with various coverage intervals. Use the calculation above to identify which of the intervals corresponds to which coverage level.\n\n1. 50% coverage interval -A- (c)\n2. 75% coverage interval -A- (e)\n3. 90% coverage interval -A- (g)\n4. 100% coverage interval -A- (i). This extends from the min to the max, so you could have figured this out just from the figure.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/kangaroo-freeze-candy-2-1.png){width=672}\n:::\n:::\n\n\n\n--------\n\n## 19.6 (Obj 19.3)\n\nThe two jitter + violin graphs below show the distribution of two  different variables, X and Y. Which variable has more variability?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/goat-take-linen-1-1.png){width=50%}\n:::\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/goat-take-linen-1-2.png){width=50%}\n:::\n:::\n\n\n::: {.callout-note}\n## Solution\n\nThere is about  the same level of variability in variable A and variable B. This surprises some people. Remember, the amount of variability has to do with the spread of *values* of the variable. In variable B, those values are have a 95% prediction interval of about 30 to 65,  about the same as for variable A. There are two things about plot (b) that  suggest to many people that there is more variability in  variable B. \n\n1. The larger horizontal spread of the dots. Note that variable B is shown along the vertical axis. The horizontal spread imposed by  jittering is completely arbitrary: the only values that count are on the y axis.  \n2.  The  scalloped, irregular edges of the violin plot. \n\nOn the other hand, some people look at the clustering of the data points in graph (b) into several discrete values, creating empty spaces in between. To them, this clustering implies less variability. And, in a way, it does. But the *statistical* meaning of variability has to do with  the overall spread of the  points, not whether they are restricted to discrete values.   \n\n:::\n\n--------\n\n## 19.7 (Objs. 19.3 & 19.4)\n\nThe graphs below show a violin plot of body mass index (BMI) for adults and children. One of the graphs shows a correct 95% coverage interval on BMI, the other does not.\n\nIdentify the incorrect graph and say what feature of the graph led to your answer.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/goat-hurt-painting-1-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](LC-lesson19_files/figure-html/goat-hurt-painting-1-2.png){width=672}\n:::\n:::\n\n\n::: {.callout-note}\n## Solution\nGraph (b) is correct. In graph (a), you can see that the interval fails to include a lot of the low BMI children and extends too high. For adults, the graph (a) interval extends too far low and doesn't go high enough.\n:::\n\n--------\n\n## 19.E\n\nThere are two equivalent formats describing an interval numerically that are widely used:\n\ni. Specify the lower and upper endpoints of the interval, e.g. 7 to 13.\nii. Specify  the center and half-width of the interval, e.g. 10 ± 3, which is  just the same as 7 to 13.\n\nComplete the following table to show the equivalences between the two notations.\n\n\n::: {.cell}\n::: {.cell-output-display}\n|Interval |bottom-to-top |plus-or-minus |\n|:--------|:-------------|:-------------|\n|(a)      |3 to 11       |              |\n|(b)      |              |108 ± 10      |\n|(c)      |              |30 ± 1        |\n|(d)      |97 to  100    |              |\n|(e)      |-4 to  16     |              |\n:::\n:::\n\n\n::: {.callout-note}\n## Solution\n\na. 7 ± 4\nb. 98 to 118\nc. 29 to 31\nd. 98.5 ± 1.5\ne. 6 ± 10\n\nIt's a matter of judgement which format to use. The bottom-to-top notation highlights the range of the interval  while the plus-or-minus notation emphasizes the center of the interval. As a rule of thumb, I suggest this:\n\n* If the first two digits are different between the top and bottom of the interval, use the bottom-to-top notation. So,  write 387 to 393.  If the first two digits are the same, use plus-or-minus. For instancer, the ratio of the mass of the Earth to that of the Moon is 81.3005678 ± 0.0000027. This is easier to take in at a glance than the equivalent 81.3005651 - 81.3005708\n\n:::\n\n--------\n\n## 19.F\n\n::: {.callout-warning}\n## Still in draft\n\nSuppose there are other explanatory variables to be displayed. In that case, we will use color and faceting. If there are *no* explanatory variables, as in `y ~ 1`, we will jitter the data horizontally to avoid overplotting.]\n:::\n\n\n--------\n\n## Demonstration: Predicting calorie content\n\nStarbucks is a famous coffee-shop franchise with more than 30,000 branches (as of 2021). People go to Starbucks for coffee, but they often buy something to eat as well. In this demonstration, we will look at the calorie content of Starbucks' food offerings. As always, when conducting a statistical analysis, it is helpful to have in mind the motivation for the task. So we will imagine, tongue in cheek, that we want to make food recommendations for the calorie-conscious consumer.\n\nFirst, a **point summary** of the calories in the different types of food products available at Starbucks:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_stats(calories ~ type, \n         data = openintro::starbucks, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  response          type     mean\n1 calories        bakery 368.7805\n2 calories    bistro box 377.5000\n3 calories hot breakfast 325.0000\n4 calories       parfait 300.0000\n5 calories        petite 177.7778\n6 calories         salad  80.0000\n7 calories      sandwich 395.7143\n```\n:::\n:::\n\n\nThis summary supports the sensible advice to choose salads or smaller portions (type \"petite\") to avoid calories. One might go further, for example, concluding that a sandwich is a poor choice (in terms of calorie content), so lean toward parfaits or hot breakfasts. We can even imagine someone concluding from this summary that a bistro box is a better calorie-conscious choice than a sandwich.\n\n@fig-starbucks-food shows the point summary, using the raw data to put things in context.\n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code  code-fold=\"true\"}\nopenintro::starbucks %>% \n  ggplot(aes(x=type, y=calories)) +\n  geom_jitter(width=0.2, alpha=0.5) +\n  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), \n                y=NA, color=\"blue\") +\n  geom_point(data=point_summary, aes(y=mean), color=\"red\")\n```\n\n::: {.cell-output-display}\n![Calories of the various food items sold by Starbucks, annotated with point and interval summaries.](LC-lesson19_files/figure-html/fig-starbucks-food-1.png){#fig-starbucks-food width=672}\n:::\n:::\n\n\nPlotting the point summary in the context of the raw data shows at a glance that the point summary is not of any genuine use. For instance, using the point summary without the data, we might conclude that hot breakfasts are better than sandwiches. However, the data display suggests otherwise; there is just one low-calorie breakfast. The others are much like sandwiches.\n\nA point summary is compact but cannot represent the *variation* within each food type. An interval summary, as in @fig-starbucks-food2, does show this variation. \n\n\n::: {.cell .fig-cap-location-margin}\n\n```{.r .cell-code  code-fold=\"true\"}\nopenintro::starbucks %>% \n  ggplot(aes(x=type, y=calories)) +\n  geom_jitter(width=0.2, alpha=0.5) +\n  geom_errorbar(data=point_summary, aes(ymin=mean, ymax=mean), \n                y=NA, color=\"blue\") \n```\n\n::: {.cell-output-display}\n![Calories of the various food items sold by Starbucks, annotated with point and interval summaries.](LC-lesson19_files/figure-html/fig-starbucks-food2-1.png){#fig-starbucks-food2 width=672}\n:::\n:::\n\n\nUnlike point summaries, interval summaries can overlap. Such overlap indicates that the groups are not all that different. Here, the interval summary indicates an appropriate conclusion; \"Don't make your diet choices based on food type. Look at the calorie content of individual items before choosing.\"\n\nAdmittedly, in this simple setting the data themselves would lead to the conclusion. However, as we move into more complicated settings, it will become infeasible to see patterns quickly straight from the data. \n\n\n\n\n\n\n",
    "supporting": [
      "LC-lesson19_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}