---
title: "Confounding"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
lesson <- 30
source("../_startup.R")
library("math300")
```

Many people are concerned that the chemicals used by lawn-greening companies are a source of cancer or other illness. Imagine designing a  study that could confirm or refute this concern. The study would sample households, some with a history of using lawn-greening chemicals and others that have never used them. The question for the study designers: What variables to record?

An obvious answer: record both chemical use and a measure of health outcome, say whether anyone in that household has developed cancer in the last five years. We will suppose that the two possible levels of grass treatment are "organic" or "chemicals." As for illness, the levels will be "cancer" or "not." 

Here are two very simple DAGs describing possible theories:

$$\text{illness} \leftarrow \text{grass treatment}\ \ \ \ \text{ or   }\ \ \ \ \ \text{illness} \rightarrow \text{grass treatment}$$


The DAG on the left expresses the belief among people who think chemical grass treatment might cause cancer. But belief is not necessarily reality, so we should consider the right-hand DAG. For example, one way to avoid the possibility of $\text{illness} \rightarrow \text{grass treatment}$ is to include only households where cancer (if any) started *after* the grass treatment. Note that we are not ignoring the right-hand DAG; we are using the study design to disqualify it.

The statistical thinker knows that covariates are important. But which covariates? Answering that requires knowing a lot about the "domain," that is, how things connect in the world. Such knowledge helps in thinking about the bigger picture and, in particular, possible covariates that connect plausibly to the response variable and the primary explanatory variable, grass treatment. 

For now, suppose that the study designers have not yet become statistical thinkers and have rushed out to gather data on illness and grass treatment. Here are a few rows from the data (which we have simulated for this example):

```{r echo=FALSE}
# Same dag mechanism, wealth not shown in the first one
dag_lawn1 <- dag_make(
  .wealth ~ exo(),
  grass ~ binom(.wealth - 0.5, labels=c("organic", "chemicals")),
  illness ~ binom(-2*(.wealth+2.5) + 0.5*(grass == "chemicals"), labels=c("not", "cancer"))
)
dag_lawn2 <- dag_make(
  wealth ~ exo(),
  grass ~ binom(wealth - 0.5, labels = c("organic", "chemicals")),
  illness ~ binom(-2*(wealth+2.5) + 0.5*(grass == "chemicals"), labels=c("not", "cancer"))
)
# set.seed(104); dag_draw(dag_lawn1)

set.seed(120) # important to get the misleading display
Cancer_data <- sample(dag_lawn2, size=1000) 
```



```{r echo=FALSE}
Cancer_data[330:339,] %>% select(-wealth) %>% knitr::kable()
```

Analyzing such data is straightforward. First, check the overall cancer rate:

```{r}
# overall cancer rate
lm(zero_one(illness, one="cancer") ~ 1, data = Cancer_data) %>% coefficients()
```

In these data, 2.6% of the sampled households had cancer in the last five years. How does the grass treatment affect that rate?

```{r}
mod <- lm(zero_one(illness, one="cancer") ~ grass, data = Cancer_data)
coefficients(mod)
```

For households whose lawn treatment is "organic," the risk of cancer is higher by 2.3 percentage points compared to households that treat their grass with chemicals. We were expecting the reverse, but it is what the data show. On the other hand, there is sampling variability to take into account. Look at the confidence intervals:

```{r}
confint(mod)
```

The confidence interval on `grassorganic` does not include zero, but it comes close. So might the chemical treatment of grass be protective against cancer? Only at this point do the study designers do what they should have from the start: think about covariates.

One theory---just a theory---is this: Green grass is not a necessity, so the households who treat their lawn with chemicals tend to have money to spare. Wealthier people also tend to have better health, partly because of better access to health care. Another factor is that wealthier people can live in less polluted neighborhoods and are less likely to work in dangerous conditions, such as exposure to toxic chemicals. Such a link between wealth and illness points to a DAG hypothesis where "`wealth`" influences how the household's `grass` is treated and `wealth` similarly influences the risk of developing `cancer`. Like this: 

```{r echo=FALSE}
dag_draw(dag_lawn2, seed=120, vertex.label.cex=1)
```

A description of this structure of causality is, "The effect of grass treatment on illness is **confounded** by wealth." The [Oxford Languages](https://languages.oup.com/google-dictionary-en/) dictionary offers two definitions of "confound."

1. *Cause surprise or confusion in someone, especially by acting against their expectations.* 
2. *Mix up something with something else so that the individual elements become difficult to distinguish.*

This second definition carries the statistical meaning of "confound." 

The first definition seems relevant to our story since the protagonist expected that chemical use would be associated with higher cancer rates and was surprised to find otherwise. But, the statistical thinker does not throw up her hands when dealing with mixed-up causal factors. Instead, she uses modeling techniques to untangle the influences of various factors.

Using covariates in models is one such technique. Our wised-up study designers go back to collect a covariate representing household wealth. Here is a glimpse at the updated data.

```{r echo=FALSE}
Cancer_data[330:339,] %>%  knitr::kable()
```
Having measured `wealth`, we can use it as a covariate in the model of `illness`: 

```{r}
lm(zero_one(illness, one="cancer") ~ grass + wealth, data = Cancer_data) %>%
  confint()
```

With `wealth` as a covariate, the model shows that (all other things being equal) "organic" lawn treatment reduces cancer risk. However, we do not see this directly from the `grass` and `illness` variables because all other things are not equal: wealthier people are more likely to use chemical lawn treatment. (Keep in mind that this is **simulated data**. Do not conclude from this example anything about the safety of the chemicals used for lawn greening.)

## Block that path!

Let us look more generally at the possible causal connections among three variables, which we will call X, Y, and C. We will stipulate that X points causally toward Y and that C is a possible covariate. Like all DAGs, there cannot be a cycle of causation.  These conditions leave three distinct DAGs that do not have a cycle, shown in @fig-three-dags-cancer.

```{r echo=FALSE}
#| label: fig-three-dags-cancer
#| fig-cap: "Three different DAGs connecting X, Y, and C."
#| column: page-inset-right
#| layout-ncol: 3
#| fig-subcap: 
#|   - "C is a confounder."
#|   - "C is a mechanism."
#|   - "C is a consequence."

dag_A<- dag_make(
  C ~ exo(),
  X ~ C,
  Y ~ X + C
)

dag_B<- dag_make(
  X ~ exo(),
  C ~ X,
  Y ~ C + X
)


dag_C<- dag_make(
  X ~ exo(),
  C ~ X + Y,
  Y ~ X
)


# dag_draw(dag_lawn2, seed=124, vertex.label.cex=1)
# dag_draw(dag_A, seed=114, vertex.label.cex=1)
# dag_draw(dag_B, seed=116, vertex.label.cex=1)
knitr::include_graphics("www/abc-dag-1.png")
knitr::include_graphics("www/abc-dag-2.png")
knitr::include_graphics("www/abc-dag-3.png")
```
C plays a different role in each of the three dags. In sub-figure (a), C causes both X and Y. In (b), part of the way that X influences Y is *through* C. We say, in this case, "C is a mechanism by which X causes Y. In sub-figure (c), C does not cause either X or Y. Instead, C is a consequence of both X and Y.^[In any given real-world context, good practice calls for considering each possible DAG structure and concocting a story behind it. Such stories will sometimes be implausible, but there can also be surprises that give the modeler new insight.]

To understand how a DAG informs whether or not to include a covariate, 
It will help to give general names to some of the sub-structures seen in the @fig-three-dags-cancer DAGs. @fig-dag-paths shows some of these sub-structures, removing other links that are not part of the structure.

```{r echo=FALSE}
#| label: fig-dags-paths
#| fig-cap: "Sub-structures seen in @fig-three-dags-cancer."
#| column: page-inset-right
#| fig-subcap: 
#|   - "Direct causal link from X to Y"
#|   - "Causal path from X through C to Y"
#|   - "Correlating path connecting X and Y via C"
#|   - "C as a consequence of X and Y"
#| layout-ncol: 4
knitr::include_graphics("www/abc-direct.png")
knitr::include_graphics("www/abc-causal.png")
knitr::include_graphics("www/abc-correlating.png")
knitr::include_graphics("www/abc-collider.png")
```

- A "**direct causal link**" between X and Y. There are no intermediate nodes.

- A "**causal path**" from C to X and on to Y. A causal path is one where, starting at the originating node, flow along the arrows can get to the terminal node, passing through all intermediate nodes. 

- A "**correlating path**" from Y through X to C. Correlating paths are distinct from causal paths because, in a correlating path, there is no way to get from one end to the other by following the flows.

- A "**collider**" `wealth`. In other words, both X and Y are causes of C. 

Look back to @fig-three-dags-cancer(a), where `wealth` is a confounder. A confounder is always an intermediate node in a *correlating path*. 


:::

Including a covariate either blocks or opens the pathway on which that covariate lies. Which it will be depends on the kind of pathway. A causal path, as in @fig-dags-paths(b), is blocked by including the covariate. Otherwise, it is open. A correlating path (@fig-dags-path(c)) is similar: the path is open unless the covariate is included in the model. A colliding path, as in @fig-dags-paths(d), is blocked *unless* the covariate is included---the opposite of a causal path.  

Often, covariates are selected to block all paths except the direct link between the explanatory and response variable. This means *do* include the covariate if it is on a correlating path and *do not* include it if the covariate is at the collision point.

As for a causal path, the choice depends on what is to be studied. Consider the DAG drawn in @fig-three-dags-cancer(b), reproduced here for convenience: 

```{r echo=FALSE}
#| column: margin
knitr::include_graphics("www/grass-dag-2.png")
```

`grass` influences `illness` through two distinct paths: 

i. the direct link from `grass` to `illness`.
ii. the causal pathway from `grass` through `wealth` to `illness`. 

Admittedly, it is far-fetched that choosing to green the grass makes a household wealthier, but focus on the topology of the DAG and not the unlikeliness of this specific causal scenario.

There is no way to block a direct link from an explanatory variable to a response. If there were a reason to do this, the modeler probably selected the wrong explanatory variable. 

But there is a genuine choice to be made about whether to block pathway (ii). If the interest is the purely biochemical link between grass-greening chemicals and illness, then block pathway (ii). However, if the interest is in the *total* effect of `grass` and `illness`, including both biochemistry and the sociological reasons why `wealth` influences `illness`, then leave the pathway open.
