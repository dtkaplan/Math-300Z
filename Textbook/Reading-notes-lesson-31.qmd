---
title: "Non-causal correlation"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
lesson <- 31
source("../_startup.R")
```


::: {.callout-note}
## Example: The flu vaccine

As you know, people are encouraged to get vaccinated before flu season. This recommendation is particularly emphasized for older adults, say, 60 and over. 

The benefits of the flu vaccine have been extensively studied. It's been found based on medical records that older adults who are vaccinated have a lower mortality rate than unvaccinated older adults. This is certainly a **correlation** between vaccination and (lower) mortality, but is there necessarily a causal connection.

In 2012, the *Lancet*, a leading medical journal, published a [systematic examination and comparison of many previous studies](https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(11)70295-X/fulltext).  (Such a study of earlier studies is called a *meta-analysis*.) The *Lancet* article describes a hypothesis that existing flu vaccines may not be as effective as was originally found.

>  *A series of observational studies undertaken between 1980 and 2001 attempted to estimate the effect of seasonal influenza vaccine on rates of hospital admission and mortality in [adults 65 and older]. Reduction in all-cause mortality after vaccination in these studies ranged from 27% to 75%. In 2005, these results were questioned after reports that increasing vaccination in people aged 65 years or older did not result in a significant decline in mortality. Five different research groups in three countries have shown that these early observational studies had substantially overestimated the mortality benefits in this age group because of unrecognized confounding. This error has been attributed to a healthy vaccine recipient effect: reasonably healthy older adults are more likely to be vaccinated, and a small group of frail, undervaccinated elderly people contribute disproportionately to deaths, including during periods when influenza activity is low or absent.*

:::

----------

## Causality & Correlation

Causality is about relationships among entities in the world, e.g. the immunological properties of the drug acetaminophen lead to a reduction in fever. Correlation is about relationships that are evident in data, which might or might not be due to direct causal connections. For example, people who take acetaminophen tend to have fever, but this is not because acetaminophen causes fever. Instead, people who are unwell, and perhaps have fever, are more likely to take acetaminophen than those who are asymptomatic.

Correlations are properly part of the evidence to support a claim or quantification of causation. Indeed, whenever there is a correlation between two variables, it's likely that there is some chain of causal connections that links the two variables, even if that chain is not directly from one variable to the other. For instance, taking the flu vaccine is correlated with reduced mortality. Some of this correlation is due to the immunological properties of the vaccine itself. But some of the correlation results from healthy people being more likely to take the vaccine than sick people, and healthy people having a lower mortality than sick people.

Seen as a pessimist, this chapter can help you understand some of the ways that correlations can be present without a direct causal pathway, and how you can be badly mislead if you rely purely on data without any causal theory of the way your system works in the real world. 

Seen as an optimist, this chapter is about ways of calculating effect sizes from data that allow you to incorporate knowledge of the causal connections amongst the variables in your data. 

The field of statistics comprises both optimists and pessimists. Perhaps to oversimplify, the pessimists think the proper domain of statistics is data and stylized mathematical models, and ought not include speculative notions of causal connections in the real world. The only sort of causal connection that the pessimists will accept is that of the experimenter who *sets* the values of inputs, for example by giving one "**treatment**" group of patients a drug and another "**control**" group a "**placebo**". This has been a highly productive attitude in statistics, resulting in the development of clever designs for experiments that give the most information with the least laboratory effort. Unfortunately, the no-causation-without-experimentation philosophy leaves us without recourse when working with a system where a controlled experiment is not feasible.

Perhaps the outstanding historical example of the limits of the no-causation-without-experimentation philosophy relates to the health effects of smoking. Nowadays, the morbidity and mortality caused by tobacco smoking is mainstream knowledge. Among the other proofs of the causal relationship is the decline in mortality due to lung cancer amoung populations where smoking became much less popular. Until the mid 1960s, however, some statisticians were in the vanguard of challenging the idea of a causal connection between smoking and, e.g., lung cancer. Notably, Ronald Fisher, generally considered to be the leading statistical figure of the 20th century, vehemently and influentially criticized the evidence for the causal connection.

```{r xkcd-correlation, echo = FALSE, fig.cap = "(ref:xkcd-correlation-cap)"}
#| label: fig-xkcd-correlation
#| fig-cap: 'Insisting that "correlation is not causation" can interfere with making useful judgements, as interpreted by Randall Munroe in his [XKCD cartoon series](https://xkcd.com/552/).'
include_graphics("www/xkcd-correlation.png")
```


The optimists, again to oversimplify, believe it is possible to make useful statements (e.g. "the class helped" in @fig-xkcd-correlation) about the causal connections that underlie data. They emphasize that statistics can support decision making even when knowledge of causation is incomplete and uncertain.

The optimists and the pessimists use the same set of mathematical and statistical tools for data analysis, particularly the calculation of effect sizes. The difference between them is the range of legitimate conclusions that can be drawn. The pessimists place in the center the idea that "correlation is not causation" and that *only* controlled experiment can be a justification for making causal conclusions. (We'll study experiment in [Lesson 32](Reading-notes-lesson-32.html).) The optimists also see the difference between correlation and causation: correlation is a mathematical property, causation is a physical one. And the optimists accept that controlled experiment is an excellent way to form strong conclusions. But they accept other sources of knowledge or theoretical speculations as potentially useful, and use effect-size calculations in a way that, contingent on that knowledge or speculation, creates through the process of data analysis situations analogous to those created in the laboratory by careful experimentation. 

--------

## Old stuff

Interest in data often stems from a desire to anticipate the consequences of an intervention. Is a new polio vaccine effective? Will increasing the consumption of organic food improve health generally? Does giving bed nets to poor people in malaria-prone regions reduce the incidence of malaria?  

The previous chapters introduced techniques for modeling a response variable as a function of explanatory variables. Each model is a machine for turning inputs into outputs. Change the input and the output will change correspondingly. But this does not mean that nature works in the same way. Changing an input in the real world -- administering polio vaccine, eating organic food, providing bed nets to the poor -- may not *cause* the same change in the response variable as happens when you change the input to a model.

*The key word here is "**cause**."*

Statisticians are careful to distinguish between two different interpretations of relationship: **"correlation"** and **"causal."** Every successful prediction model `Y ~ X` is a demonstration that there is a correlation between the response Y and the explanatory variable X.^["Successful" means that the prediction performance of the model is better than the performance of a no-input model.] But the performance of the model does not itself tell us that X *causes* Y in the real world. There are other possible configurations that will produce a correlation between X and Y. For instance, both X and Y may themselves have a common cause C without X being otherwise related to Y. In such a circumstance, a real-world intervention to change X will have no effect on Y. To put this in the form of a story, consider that the start of the school year and leaves changing color are correlated. But an intervention to start the school year in mid-winter will not result in  leaves changing color. There's a common cause for the school year and colorful folliage that produces the relationship: the end of summer.

This chapter considers simple networks of causality involving three variables, generically called X, Y, and C. Always, we'll imagine that the modeler's interest is in anticipating how an intervention to change X will create to a change in Y. To accomplish this, the modeler has two basic choices for structuring a model, either

1. `Y ~ X`, or
2. `Y ~ X + C`.

It's surprising to many people that models (1) and (2) can have utterly different, even contradictory implications for how a change in model input X will produce a change in the model output Y. To the modeler trying to capture how the real world works, there's a fundamental choice to be made between using model (1) or model (2) to anticipate the consequences of a real-world intervention on X.

Consider this hypothesis: "It's harder to learn to drive as you move into your 20s." The hypothesis might or might not be true. The way such hypotheses are formed is often by anecdote. Say, you're having dinner when the conversation turns to a friend who has been learning to drive in her 30s. She explains that even after taking many lessons last year, she failed her driving test twice. Others at the table, who started driving in their teens, learned in a much shorter amount of time.

The hypothesis suggests a practical recommendation: It will be easier to learn to drive when younger, so better to start young. Such recommendations to take an action are always rooted in causality: starting young will *cause* you to have less difficulty learning to drive. A diagram, or *graphical causal model*, representing the causal hypothesis is seen in @fig-learn-to-drive-1.

```{r echo=FALSE, out.width = "40%"}
#| label: fig-learn-to-drive-1
#| fig-cap: "A simple graphical causal model expressing the hypothesis that age when learning to drive is the causal factor for the difficulty of learning to drive."
knitr::include_graphics("www/anxiety-drive-1.png")
```

The direction of the arrow in fig-learn-to-drive-1 is a crucial feature. The diagram asserts that a person's age when learning to drive *causes* difficulty, as opposed to the other way around. 

So, does learning to drive when young make it easier to succeed? You might collect some data, perhaps a survey asking people at what age (if ever) they learned to drive (X) and how difficult it was (Y). Suppose you build a successful model Y ~ X. This establishes a correlation X and Y (and vice versa), confirming the dinner table anecdote.  

If you were undertaking serious study of the hypothesis, you should consider how other factors might influence the situation. For instance, it might be that people who learn to drive in their 30s were more anxious about driving when in their teens. That anxiety is why they didn't learn in their teens.  The anxiety might also influence the drivers perception of the difficulty learning. Such a situation is expressed in the graphical causal models in @fig-learn-to-drive-2.


```{r echo=FALSE}
#| label: fig-learn-to-drive-2
#| fig-cap: 'Two possible graphical causal models of the hypothesis, "Age causes difficulty learning to drive," which do not incorporate a direct link from age to difficulty learning.  Left: Anxiety itself leads to people deferring learning to drive, and to increased difficulty when learning. Right: Age is causally linked to difficulty, but the issue is really the diminished support available to older learners.'
knitr::include_graphics("www/anxiety-drive-3.png")
```


Another possibility is that older learners have busier lives and less support for learning to drive. (@fig-learn-to-drive-2(right)) It's harder for older learners to schedule opportunities to practice or to find car owners who can help them learn. 

There is nothing inevitable about graphical causal networks. We can, and often do, intervene in ways that alter the causal flow. For example, @fig-friend-drive shows the network when a later-in-life friend steps in to support a mature student.

```{r echo=FALSE}
#| label: fig-friend-drive
#| fig-cap: "Intervening in a system can change the structure of the graphical causal network. Here, a friend has stepped in to provide the support needed to learn to drive, severing the link that previously connected age when learning to support. (That link -- now severed -- reflects the kind of learning support often available to teenage students of driving, but not to older learners.)"
knitr::include_graphics("www/anxiety-drive-4.png")
```



::: {.callout-note icon=false}
## Causal Caution

Just because you've calculated an effect size doesn't mean that you have captured any sort of causal relationship between the variables. To illustrate, use `dag01` and fit two different models: `y ~ x` and `x ~ y`.

```{r}
Sample <- sample(dag01, size=500)
lm(y ~ x, data = Sample)
lm(x ~ y, data = Sample)
```

You can't tell from these coefficients whether `x` causes `y` or vice versa (or something entirely different). The words "correlation" or "association" are used when we don't want to claim that there is a causal connection. Many statisticians will only use those words unless the data come from an **experiment**. 

We're going to use causal language ("relationship", "effect," etc.) because that is often the matter of concern to decision making. But using language doesn't doesn't make the connection causal.

:::

