[
  {
    "objectID": "LC/Learning-checks.html",
    "href": "LC/Learning-checks.html",
    "title": "Learning Checks from Modern Dive",
    "section": "",
    "text": "LC 1.1 Block 1 Day 1\n\n\n\nRepeat the earlier installation steps, but for the dplyr, nycflights13, and knitr packages. This will install the earlier mentioned dplyr package for data wrangling, the nycflights13 package containing data on all domestic flights leaving a NYC airport in 2013, and the knitr package for generating easy-to-read tables in R. We’ll use these packages in the next section.\n\n\n\n\n\n\n\n\nLC 1.2 Block 1 Day 1\n\n\n\n“Load” the dplyr, nycflights13, and knitr packages as well by repeating the earlier steps.\n\n\nRun View(flights) in your console in RStudio, either by typing it or cutting-and-pasting it into the console pane. Explore this data frame in the resulting pop up viewer. You should get into the habit of viewing any data frames you encounter. Note the uppercase V in View(). R is case-sensitive, so you’ll get an error message if you run view(flights) instead of View(flights)\n\n\n\n\n\n\nLC 1.3 Block 1 Day 1\n\n\n\nWhat does any ONE row in this flights dataset refer to?\n\nA. Data on an airline\nB. Data on a flight\nC. Data on an airport\nD. Data on multiple flights\n\n\n\n\n\n\n\n\n\nLC 1.4 Block 1 Day 1\n\n\n\nWhat are some other examples in this dataset (flights) of categorical variables? What makes them different than quantitative variables?\n\n\n\n\n\n\n\n\nLC 1.5 Block 1 Day 1\n\n\n\nWhat properties of each airport do the variables lat, lon, alt, tz, dst, and tzone describe in the airports data frame? Take your best guess.\n\n\n\n\n\n\n\n\nLC 1.6 Block 1 Day 1\n\n\n\nProvide the names of variables in a data frame with at least three variables where one of them is an identification variable and the other two are not. Further, create your own tidy data frame that matches these conditions.\n\n\n\n\n\n\n\n\nLC 1.7 Block 1 Day 1\n\n\n\nLook at the help file for the airports data frame. Revise your earlier guesses about what the variables lat, lon, alt, tz, dst, and tzone each describe."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-2-visualization",
    "href": "LC/Learning-checks.html#chapter-2-visualization",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 2: Visualization",
    "text": "Chapter 2: Visualization\n\n\n\n\n\n\nLC 2.1 Block 1 Day 2\n\n\n\nTake a look at both the flights and alaska_flights data frames by running View(flights) and View(alaska_flights). In what respect do these data frames differ? For example, think about the number of rows in each dataset.\n\n\n\n\n\n\n\n\nLC 2.2-2.6 Block 1 Day 2\n\n\n\nWhat are some practical reasons why dep_delay and arr_delay have a positive relationship?\nWhat variables in the weather data frame would you expect to have a negative correlation (i.e., a negative relationship) with dep_delay? Why? Remember that we are focusing on numerical variables here. Hint: Explore the weather dataset by using the View() function.\nWhy do you believe there is a cluster of points near (0, 0)? What does (0, 0) correspond to in terms of the Alaska Air flights?\nWhat are some other features of the plot that stand out to you?\nCreate a new scatterplot using different variables in the alaska_flights data frame by modifying the example given.\n\n\n\n\n\n\n\n\nLC 2.7-2.8 Block 1 Day 2\n\n\n\nWhy is setting the alpha argument value useful with scatterplots? What further information does it give you that a regular scatterplot cannot?\nAfter viewing Figure @ref(fig:alpha), give an approximate range of arrival delays and departure delays that occur most frequently. How has that region changed compared to when you observed the same plot without alpha = 0.2 set in Figure @ref(fig:noalpha)?\n\n\n\n\n\n\n\n\nLC 2.9-2.10 Block 1 Day 3\n\n\n\nLC 2.9 Take a look at both the weather and early_january_weather data frames by running View(weather) and View(early_january_weather). In what respect do these data frames differ?\nLC 2.10 View() the flights data frame again. Why does the time_hour variable uniquely identify the hour of the measurement, whereas the hour variable does not?\n\n\n\n\n\n\n\n\nLC 2.11-2.13 Block 1 Day 3\n\n\n\nLC 2.11 Why should linegraphs be avoided when there is not a clear ordering of the horizontal axis?\nLC 2.12 Why are linegraphs frequently used when time is the explanatory variable on the x-axis?\nLC 2.12 Plot a time series of a variable other than temp for Newark Airport in the first 15 days of January 2013.\n\n\n\n\n\n\n\n\nLC 2.18-2.21 Block 1 Day 3\n\n\n\nWhat other things do you notice about this faceted plot? How does a faceted plot help us see relationships between two variables?\nWhat do the numbers 1-12 correspond to in the plot? What about 25, 50, 75, 100?\nFor which types of datasets would faceted plots not work well in comparing relationships between variables? Give an example describing the nature of these variables and other important characteristics.\nLC 2.21 Does the temp variable in the weather dataset have a lot of variability? Why do you say that?\n\n\n\n\n\n\n\n\nLC 2.22-2.25 Boxplots Block 1 Day 4\n\n\n\nLC 2.22 What does the dot at the bottom of the plot for May correspond to? Explain what might have occurred in May to produce this point.\nLC 2.23 Which months have the highest variability in temperature? What reasons can you give for this?\nLC 2.24 We looked at the distribution of the numerical variable temp split by the numerical variable month that we converted using the factor() function in order to make a side-by-side boxplot. Why would a boxplot of temp split by the numerical variable pressure similarly converted to a categorical variable using the factor() not be informative?\nLC 2.25 Boxplots provide a simple way to identify outliers. Why may outliers be easier to identify when looking at a boxplot instead of a faceted histogram?\n\n\n\n\n\n\n\n\nLC 2.26-2.29 Histograms Block 1 Day 4\n\n\n\nLC 2.26 Why are histograms inappropriate for categorical variables?\nLC 2.27 What is the difference between histograms and barplots?\nLC 2.28 How many Envoy Air flights departed NYC in 2013?\nLC 2.29 What was the 7th highest airline for departed flights from NYC in 2013? How could we better present the table to get this answer quickly?\n\n\n\n\n\n\n\n\nLC 2.30-2.31 Pie charts Block 1 Day 4\n\n\n\nLC 2.30 Why should pie charts be avoided and replaced by barplots?\nLC 2.31 Why do you think people continue to use pie charts?\n\n\n\n\n\n\n\n\nLC 2.32-2.37 Block 1 Day 4\n\n\n\nLC 2.32 What kinds of questions are not easily answered by looking at Figure @ref(fig:flights-stacked-bar) (2.23)?\nLC 2.33 What can you say, if anything, about the relationship between airline and airport in NYC in 2013 in regards to the number of departing flights?\nLC 2.34 Why might the side-by-side barplot be preferable to a stacked barplot in this case?\nLC 2.35 What are the disadvantages of using a dodged barplot, in general?\nLC 2.36 Why is the faceted barplot preferred to the side-by-side and stacked barplots in this case?\nLC 2.37 What information about the different carriers at different airports is more easily seen in the faceted barplot?"
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-3-wrangling",
    "href": "LC/Learning-checks.html#chapter-3-wrangling",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 3: Wrangling",
    "text": "Chapter 3: Wrangling\n\n\n\n\n\n\nLC 3.1 Block 1 Day 5\n\n\n\nWhat’s another way of using the “not” operator ! to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the flights data frame? Test this out using the previous code.\n\n\n\n\n\n\n\n\nLC 3.2 Block 1 Day 5\n\n\n\nSay a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five-year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor’s approach?\n\n\n\n\n\n\n\n\nLC 3.3 Block 1 Day 5\n\n\n\nModify the earlier summarize() function code that creates the summary_temp data frame to also use the n() summary function: summarize(... , count = n()). What does the returned value correspond to?\n\n\n\n\n\n\n\n\nLC 3.4 Block 1 Day 5\n\n\n\nWhy doesn’t the following code work? Run the code line-by-line instead of all at once, and then look at the data. In other words, run summary_temp <- weather %>% summarize(mean = mean(temp, na.rm = TRUE)) first.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nsummary_temp <- weather %>%   \n  summarize(mean = mean(temp, na.rm = TRUE)) %>% \n  summarize(std_dev = sd(temp, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\nLC 3.5 Block 1 Day 6\n\n\n\nRecall from Chapter @ref(viz) when we looked at temperatures by months in NYC. What does the standard deviation column in the summary_monthly_temp data frame tell us about temperatures in NYC throughout the year?\n\n\n\n\n\n\n\n\nLC 3.6 Block 1 Day 6\n\n\n\nWhat code would be required to get the mean and standard deviation temperature for each day in 2013 for NYC?\n\n\n\n\n\n\n\n\nLC 3.7 Block 1 Day 6\n\n\n\nRecreate by_monthly_origin, but instead of grouping via group_by(origin, month), group variables in a different order group_by(month, origin). What differs in the resulting dataset?\n\n\n\n\n\n\n\n\nLC 3.8 Block 1 Day 6\n\n\n\nHow could we identify how many flights left each of the three airports for each carrier?\n\n\n\n\n\n\n\n\nLC 3.9 Block 1 Day 6\n\n\n\nHow does the filter() operation differ from a group_by() followed by a summarize()?\n\n\n\n\n\n\n\n\nLC 3.10 Block 1 Day 6\n\n\n\nWhat do positive values of the gain variable in flights correspond to? What about negative values? And what about a zero value?\n\n\n\n\n\n\n\n\nLC 3.11 Block 1 Day 6\n\n\n\nCould we create the dep_delay and arr_delay columns by simply subtracting dep_time from sched_dep_time and similarly for arrivals? Try the code out and explain any differences between the result and what actually appears in flights.\n\n\n\n\n\n\n\n\nLC 3.12 Block 1 Day 76\n\n\n\nWhat can we say about the distribution of gain? Describe it in a few sentences using the plot and the gain_summary data frame values.\n\n\n\n\n\n\n\n\nLC 3.13 Block 1 Day 7\n\n\n\nLooking at Figure @ref(fig:reldiagram), when joining flights and weather (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of year, month, day, hour, and origin, and not just hour?\n\n\n\n\n\n\n\n\nLC 3.14 Block 1 Day 7\n\n\n\nWhat surprises you about the top 10 destinations from NYC in 2013?\n\n\n\n\n\n\n\n\nLC 3.15 Block 1 Day 7\n\n\n\nWhat are some advantages of data in normal forms? What are some disadvantages?\n\n\n\n\n\n\n\n\nLC 3.16 Block 1 Day 7\n\n\n\nWhat are some ways to select all three of the dest, air_time, and distance variables from flights? Give the code showing how to do this in at least three different ways.\n\n\n\n\n\n\n\n\nLC 3.17 Block 1 Day 7\n\n\n\nHow could one use starts_with(), ends_with(), and contains() to select columns from the flights data frame? Provide three different examples in total: one for starts_with(), one for ends_with(), and one for contains().\n\n\n\n\n\n\n\n\nLC 3.18 Block 1 Day 7\n\n\n\nWhy might we want to use the select function on a data frame?\n\n\n\n\n\n\n\n\nLC 3.19 Block 1 Day 7\n\n\n\nCreate a new data frame that shows the top 5 airports with the largest arrival delays from NYC in 2013.\n\n\n::: {.callout-note icon=false} ## LC 3.20 Block 1 Day 7 Let’s now put your newly acquired data wrangling skills to the test!\nAn airline industry measure of a passenger airline’s capacity is the available seat miles, which is equal to the number of seats available multiplied by the number of miles or kilometers flown summed over all flights.\nFor example, let’s consider the scenario in Figure 1. Since the airplane has 4 seats and it travels 200 miles, the available seat miles are \\(4 \\times 200 = 800\\).\n\n\n\n\n\nFigure 1: Example of available seat miles for one flight.\n\n\n\n\nExtending this idea, let’s say an airline had 2 flights using a plane with 10 seats that flew 500 miles and 3 flights using a plane with 20 seats that flew 1000 miles, the available seat miles would be \\(2 \\times 10 \\times 500 + 3 \\times 20 \\times 1000 = 70,000\\) seat miles.\nUsing the datasets included in the nycflights13 package, compute the available seat miles for each airline sorted in descending order. After completing all the necessary data wrangling steps, the resulting data frame should have 16 rows (one for each airline) and 2 columns (airline name and available seat miles). Here are some hints:\n\nCrucial: Unless you are very confident in what you are doing, it is worthwhile not starting to code right away. Rather, first sketch out on paper all the necessary data wrangling steps not using exact code, but rather high-level pseudocode that is informal yet detailed enough to articulate what you are doing. This way you won’t confuse what you are trying to do (the algorithm) with how you are going to do it (writing dplyr code).\nTake a close look at all the datasets using the View() function: flights, weather, planes, airports, and airlines to identify which variables are necessary to compute available seat miles.\nFigure @ref(fig:reldiagram) showing how the various datasets can be joined will also be useful.\nConsider the data wrangling verbs in Table @ref(tab:wrangle-summary-table) as your toolbox! ::"
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-4-tidy",
    "href": "LC/Learning-checks.html#chapter-4-tidy",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 4: Tidy",
    "text": "Chapter 4: Tidy\n::: {.callout-note icon=false} ## LC 4.1 Block 1 Day 8 What are common characteristics of “tidy” data frames? ::\n::: {.callout-note icon=false} ## LC 4.2 Block 1 Day 8 What makes “tidy” data frames useful for organizing data? ::\n::: {.callout-note icon=false} ## LC 4.3 Block 1 Day 8 Take a look at the airline_safety data frame included in the fivethirtyeight data package. Run the following:\n\nairline_safety\n\nAfter reading the help file by running ?airline_safety, we see that airline_safety is a data frame containing information on different airline companies’ safety records. This data was originally reported on the data journalism website, FiveThirtyEight.com, in Nate Silver’s article, “Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past?”. Let’s only consider the variables airlines and those relating to fatalities for simplicity:\n\nairline_safety_smaller <- airline_safety %>% \n  select(airline, starts_with(\"fatalities\"))\nairline_safety_smaller\n\n# A tibble: 56 × 3\n   airline               fatalities_85_99 fatalities_00_14\n   <chr>                            <int>            <int>\n 1 Aer Lingus                           0                0\n 2 Aeroflot                           128               88\n 3 Aerolineas Argentinas                0                0\n 4 Aeromexico                          64                0\n 5 Air Canada                           0                0\n 6 Air France                          79              337\n 7 Air India                          329              158\n 8 Air New Zealand                      0                7\n 9 Alaska Airlines                      0               88\n10 Alitalia                            50                0\n# … with 46 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nThis data frame is not in “tidy” format. How would you convert this data frame to be in “tidy” format, in particular so that it has a variable fatalities_years indicating the incident year and a variable count of the fatality counts? ::\n::: {.callout-note icon=false} ## LC 4.4 Block 1 Day 9 Convert the dem_score data frame into a “tidy” data frame and assign the name of dem_score_tidy to the resulting long-formatted data frame. ::\n::: {.callout-note icon=false} ## LC 4.5 Block 1 Day 9 Read in the life expectancy data stored at https://moderndive.com/data/le_mess.csv and convert it to a “tidy” data frame. ::"
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-5-regression",
    "href": "LC/Learning-checks.html#chapter-5-regression",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 5: Regression",
    "text": "Chapter 5: Regression\n\n\n\n\n\n\nLC 5.1 Block 2 Day 1\n\n\n\nConduct a new exploratory data analysis with the same outcome variable \\(y\\) being score but with age as the new explanatory variable \\(x\\). Remember, this involves three things:\n\nLooking at the raw data values.\nComputing summary statistics.\nCreating data visualizations.\n\nWhat can you say about the relationship between age and teaching scores based on this exploration?\n\n\n\n\n\n\n\n\nLC 5.2 Block 2 Day 1\n\n\n\nFit a new simple linear regression using lm(score ~ age, data = evals_ch5) where age is the new explanatory variable \\(x\\). Get information about the “best-fitting” line from the regression table by applying the get_regression_table() function. How do the regression results match up with the results from your earlier exploratory data analysis?\n\n\n\n\n\n\n\n\nLC 5.3 Block 2 Day 1\n\n\n\nGenerate a data frame of the residuals of the model where you used age as the explanatory \\(x\\) variable.\n\n\n\n\n\n\n\n\nLC 5.4 Block 2 Day 2\n\n\n\nConduct a new exploratory data analysis with the same explanatory variable \\(x\\) being continent but with gdpPercap as the new outcome variable \\(y\\). What can you say about the differences in GDP per capita between continents based on this exploration?\n\n\n\n\n\n\n\n\nLC 5.5 Block 2 Day 2\n\n\n\nFit a new linear regression using lm(gdpPercap ~ continent, data = gapminder2007) where gdpPercap is the new outcome variable \\(y\\). Get information about the “best-fitting” line from the regression table by applying the get_regression_table() function. How do the regression results match up with the results from your previous exploratory data analysis?\n\n\n\n\n\n\n\n\nLC 5.6 Block 2 Day 2\n\n\n\nUsing either the sorting functionality of RStudio’s spreadsheet viewer or using the data wrangling tools you learned in Chapter @ref(wrangling), identify the five countries with the five smallest (most negative) residuals? What do these negative residuals say about their life expectancy relative to their continents’ life expectancy?\n\n\n\n\n\n\n\n\nLC 5.7 Block 2 Day 2\n\n\n\nRepeat this process, but identify the five countries with the five largest (most positive) residuals. What do these positive residuals say about their life expectancy relative to their continents’ life expectancy?\n\n\n\n\n\n\n\n\nLC 5.8 Block 2 Day 3\n\n\n\nNote in Figure @fig:three-lines there are 3 points marked with dots and:\n\nThe “best” fitting solid regression line in blue\nAn arbitrarily chosen dotted red line\nAnother arbitrarily chosen dashed green line\n\n\n\n\n\n\nFigure 2: Regression line and two others.\n\n\n\n\nCompute the sum of squared residuals by hand for each line and show that of these three lines, the regression line in blue has the smallest value."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-6-multiple-regression",
    "href": "LC/Learning-checks.html#chapter-6-multiple-regression",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 6: Multiple regression",
    "text": "Chapter 6: Multiple regression\n\n\n\n\n\n\nLC 6.1 Block 2 Day 4\n\n\n\nCompute the observed values, fitted values, and residuals not for the interaction model as we just did, but rather for the parallel slopes model we saved in score_model_parallel_slopes.\n\n\n\n\n\n\n\n\nLC 6.2\n\n\n\nConduct a new exploratory data analysis with the same outcome variable \\(y\\) debt but with credit_rating and age as the new explanatory variables \\(x_1\\) and \\(x_2\\). What can you say about the relationship between a credit card holder’s debt and their credit rating and age?\n\n\n\n\n\n\n\n\nLC 6.3\n\n\n\nConduct a new exploratory data analysis with the same outcome variable \\(y\\) debt but with credit_rating and age as the new explanatory variables \\(x_1\\) and \\(x_2\\). What can you say about the relationship between a credit card holder’s debt and their credit rating and age?\n\n\n\n\n\n\n\n\nLC 6.4\n\n\n\nFit a new simple linear regression using lm(debt ~ credit_rating + age, data = credit_ch6) where credit_rating and age are the new numerical explanatory variables \\(x_1\\) and \\(x_2\\). Get information about the “best-fitting” regression plane from the regression table by applying the get_regression_table() function. How do the regression results match up with the results from your previous exploratory data analysis?"
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-7-sampling",
    "href": "LC/Learning-checks.html#chapter-7-sampling",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 7: Sampling",
    "text": "Chapter 7: Sampling\n\n\n\n\n\n\nLC 7.1 Block 3 Day 1\n\n\n\nWhy was it important to mix the bowl before we sampled the balls?\n\n\n\n\n\n\n\n\nLC 7.2 Block 3 Day 1\n\n\n\nWhy is it that our 33 groups of friends did not all have the same numbers of balls that were red out of 50, and hence different proportions red?\n\n\n\n\n\n\n\n\nLC 7.3 Block 3 Day 1\n\n\n\nWhy couldn’t we study the effects of sampling variation when we used the virtual shovel only once? Why did we need to take more than one virtual sample (in our case 33 virtual samples)?\n\n\n\n\n\n\n\n\nLC 7.4 Block 3 Day 1\n\n\n\nWhy did we not take 1000 “tactile” samples of 50 balls by hand?\n\n\n\n\n\n\n\n\nLC 7.5 Block 3 Day 1\n\n\n\nLooking at Figure @ref(fig:samplingdistribution-virtual-1000), would you say that sampling 50 balls where 30% of them were red is likely or not? What about sampling 50 balls where 10% of them were red?\n\n\n\n\n\n\n\n\nLC 7.6 Block 3 Day 1\n\n\n\nIn Figure 7.9, we used shovels to take 1000 samples each, computed the resulting 1000 proportions of the shovel’s balls that were red, and then visualized the distribution of these 1000 proportions in a histogram. We did this for shovels with 25, 50, and 100 slots in them. As the size of the shovels increased, the histograms got narrower. In other words, as the size of the shovels increased from 25 to 50 to 100, did the 1000 proportions\n\nA. vary less,\nB. vary by the same amount, or\nC. vary more?\n\n\n\n\n\n\n\n\n\nLC 7.7 Block 3 Day 1\n\n\n\nWhat summary statistic did we use to quantify how much the 1000 proportions red varied?\n\nA. The interquartile range\nB. The standard deviation\nC. The range: the largest value minus the smallest.\n\n\n\n\n\n\n\n\n\nLC 7.8 Block 3 Day 2\n\n\n\nIn the case of our bowl activity, what is the population parameter? Do we know its value?\n\n\n\n\n\n\n\n\nLC 7.9 Block 3 Day 2\n\n\n\nWhat would performing a census in our bowl activity correspond to? Why did we not perform a census?\n\n\n\n\n\n\n\n\nLC 7.10 Block 3 Day 2\n\n\n\nWhat purpose do point estimates serve in general? What is the name of the point estimate specific to our bowl activity? What is its mathematical notation?\n\n\n\n\n\n\n\n\nLC 7.11 Block 3 Day 2\n\n\n\nHow did we ensure that our tactile samples using the shovel were random?\n\n\n\n\n\n\n\n\nLC 7.12 Block 3 Day 2\n\n\n\nWhy is it important that sampling be done at random?\n\n\n\n\n\n\n\n\nLC 7.13 Block 3 Day 2\n\n\n\nWhat are we inferring about the bowl based on the samples using the shovel?\n\n\n\n\n\n\n\n\nLC 7.14 Block 3 Day 2\n\n\n\nWhat purpose did the sampling distributions serve?\n\n\n\n\n\n\n\n\nLC 7.15 Block 3 Day 2\n\n\n\nWhat does the standard error of the sample proportion \\(\\widehat{p}\\) quantify?\n\n\n\n\n\n\n\n\nLC 7.16 Block 3 Day 2\n\n\n\nThe table that follows is a version of Table @ref(tab:comparing-n-2) matching sample sizes \\(n\\) to different standard errors of the sample proportion \\(\\widehat{p}\\), but with the rows randomly re-ordered and the sample sizes removed. Fill in the table by matching the correct sample sizes to the correct standard errors.\nStandard errors of \\(\\hat{p}\\) based on n = 25, 50, 100\n\n\n\nSample size\nStandard error of \\(\\hat{p}\\)\n\n\n\n\n\\(n=\\)\n0.94\n\n\n\\(n=\\)\n0.45\n\n\n\\(n=\\)\n0.69\n\n\n\nFor the following four Learning checks, let the estimate be the sample proportion \\(\\widehat{p}\\): the proportion of a shovel’s balls that were red. It estimates the population proportion \\(p\\): the proportion of the bowl’s balls that were red.\n\n\n\n\n\n\n\n\nLC 7.17 Block 3 Day 2\n\n\n\nWhat is the difference between an accurate and a precise estimate?\n\n\n\n\n\n\n\n\nLC 7.18 Block 3 Day 2\n\n\n\nHow do we ensure that an estimate is accurate? How do we ensure that an estimate is precise?\n\n\n\n\n\n\n\n\nLC 7.19 Block 3 Day 2\n\n\n\nIn a real-life situation, we would not take 1000 different samples to infer about a population, but rather only one. Then, what was the purpose of our exercises where we took 1000 different samples?\n\n\n\n\n\n\n\n\nLC 7.20 Block 3 Day 2\n\n\n\nFigure @ref(fig:accuracy-vs-precision) with the targets shows four combinations of “accurate versus precise” estimates. Draw four corresponding sampling distributions of the sample proportion \\(\\widehat{p}\\), like the one in the leftmost plot in Figure @ref(fig:comparing-sampling-distributions-3).\n\n\n\n\n\n\n\n\nLC 7.21 Block 3 Day 3\n\n\n\nThe Royal Air Force wants to study how resistant all their airplanes are to bullets. They study the bullet holes on all the airplanes on the tarmac after an air battle against the Luftwaffe (German Air Force).\n\n\n\n\n\n\n\n\nLC 7.22 Block 3 Day 3\n\n\n\nImagine it is 1993, a time when almost all households had landlines. You want to know the average number of people in each household in your city. You randomly pick out 500 phone numbers from the phone book and conduct a phone survey.\n\n\n\n\n\n\n\n\nLC 7.23 Block 3 Day 3\n\n\n\nYou want to know the prevalence of illegal downloading of TV shows among students at a local college. You get the emails of 100 randomly chosen students and ask them, “How many times did you download a pirated TV show last week?”.\n\n\n\n\n\n\n\n\nLC 7.24 Block 3 Day 3\n\n\n\nA local college administrator wants to know the average income of all graduates in the last 10 years. So they get the records of five randomly chosen graduates, contact them, and obtain their answers."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-8-confidence-intervals",
    "href": "LC/Learning-checks.html#chapter-8-confidence-intervals",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 8: Confidence intervals",
    "text": "Chapter 8: Confidence intervals\n\n\n\n\n\n\nLC 8.1 Block 3 Day 5\n\n\n\nWhat is the chief difference between a bootstrap distribution and a sampling distribution?\n\n\n\n\n\n\n\n\nLC 8.2 Block 3 Day 5\n\n\n\nLooking at the bootstrap distribution for the sample mean in Figure @ref(fig:one-thousand-sample-means), between what two values would you say most values lie?\n\n\n\n\n\n\n\n\nLC 8.3 Block 3 Day 6\n\n\n\nWhat condition about the bootstrap distribution must be met for us to be able to construct confidence intervals using the standard error method?\n\n\n\n\n\n\n\n\nLC 8.4 Block 3 Day 6\n\n\n\nSay we wanted to construct a 68% confidence interval instead of a 95% confidence interval for \\(\\mu\\). Describe what changes are needed to make this happen. Hint: we suggest you look at Appendix @ref(appendix-normal-curve) on the normal distribution.\n\n\n\n\n\n\n\n\nLC 8.5 Block 3 Day 8\n\n\n\nConstruct a 95% confidence interval for the median year of minting of all US pennies. Use the percentile method and, if appropriate, then use the standard-error method."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-9-hypothesis-testing",
    "href": "LC/Learning-checks.html#chapter-9-hypothesis-testing",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 9: Hypothesis testing",
    "text": "Chapter 9: Hypothesis testing\n\n\n\n\n\n\nLC 9.1 Block 4 Day 2\n\n\n\nWhy does the following code produce an error? In other words, what about the response and predictor variables make this not a possible computation with the infer package?\n\nlibrary(moderndive)\nlibrary(infer)\nnull_distribution_mean <- promotions %>%\n  specify(formula = decision ~ gender, success = \"promoted\") %>% \n  hypothesize(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(stat = \"diff in means\", order = c(\"male\", \"female\"))\n\n\n\n\n\n\n\n\n\nLC 9.2 Block 4 Day 2\n\n\n\nWhy are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of promotion proportions for the two genders?\n\n\n\n\n\n\n\n\nLC 9.3 Block 4 Day 2\n\n\n\nUsing the definition of p-value, write in words what the \\(p\\)-value represents for the hypothesis test comparing the promotion rates for males and females.\n\n\n\n\n\n\n\n\nLC 9.4 Block 4 Day 2\n\n\n\nDescribe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between the promotion rate of males and females using this study.\n\n\n\n\n\n\n\n\nLC 9.5 Block 4 Day 3\n\n\n\nWhat is wrong about saying, “The defendant is innocent.” based on the US system of criminal trials?\n\n\n\n\n\n\n\n\nLC 9.6 Block 4 Day 3\n\n\n\nWhat is the purpose of hypothesis testing?\n\n\n\n\n\n\n\n\nLC 9.7 Block 4 Day 3\n\n\n\nWhat are some flaws with hypothesis testing? How could we alleviate them?\n\n\n\n\n\n\n\n\nLC 9.8 Block 4 Day 3\n\n\n\nConsider two \\(\\alpha\\) significance levels of 0.1 and 0.01. Of the two, which would lead to a more liberal hypothesis testing procedure? In other words, one that will, all things being equal, lead to more rejections of the null hypothesis \\(H_0\\).\n\n\n\n\n\n\n\n\nLC 9.9\n\n\n\nConduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same?\n\n\n\n\n\n\n\n\nLC 9.10\n\n\n\nWhat conclusions can you make from viewing the faceted histogram looking at rating versus genre that you couldn’t see when looking at the boxplot?\n\n\n\n\n\n\n\n\nLC 9.11\n\n\n\nDescribe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.\n\n\n\n\n\n\n\n\nLC 9.12\n\n\n\nWhy are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?\n\n\n\n\n\n\n\n\nLC 9.13\n\n\n\nUsing the definition of \\(p\\)-value, write in words what the \\(p\\)-value represents for the hypothesis test comparing the mean rating of romance to action movies.\n\n\n\n\n\n\n\n\nLC 9.14\n\n\n\nWhat is the value of the \\(p\\)-value for the hypothesis test comparing the mean rating of romance to action movies?\n\n\n\n\n\n\n\n\nLC 9.15\n\n\n\nTest your data wrangling knowledge and EDA skills:\n\nUse dplyr and tidyr to create the necessary data frame focused on only action and romance movies (but not both) from the movies data frame in the ggplot2movies package.\nMake a boxplot and a faceted histogram of this population data comparing ratings of action and romance movies from IMDb.\nDiscuss how these plots compare to the similar plots produced for the movies_sample data."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-10-inference-for-regression",
    "href": "LC/Learning-checks.html#chapter-10-inference-for-regression",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 10: Inference for regression",
    "text": "Chapter 10: Inference for regression\n\n\n\n\n\n\nLC 10.1 Block 4 Day 7\n\n\n\nContinuing with our regression using age as the explanatory variable and teaching score as the outcome variable.\n\nUse the get_regression_points() function to get the observed values, fitted values, and residuals for all 463 instructors.\nPerform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern but comment on what you find here.\n\n\n\n\n\n\n\n\n\nLC 10.2 Block 4 Day 8\n\n\n\nRepeat the inference but this time for the correlation coefficient instead of the slope. Note the implementation of stat = \"correlation\" in the calculate() function of the infer package."
  },
  {
    "objectID": "LC/Learning-checks.html#chapter-11-tell-your-story-with-data",
    "href": "LC/Learning-checks.html#chapter-11-tell-your-story-with-data",
    "title": "Learning Checks from Modern Dive",
    "section": "Chapter 11: Tell your story with data",
    "text": "Chapter 11: Tell your story with data\n\n\n\n\n\n\n\nLC 11.1 Block 4 Day 2\n\n\n\nRepeat the regression modeling in Subsection 11.2.3 and the prediction making you just did on the house of condition 5 and size 1900 square feet in Subsection 12.2.4, but using the parallel slopes model you visualized in Figure 11.6. Show that it’s $524,807!\n\n\n\n\n\n\n\n\nLC 11.2\n\n\n\nWhat date between 1994 and 2003 has the fewest number of births in the US? What story could you tell about why this is the case?"
  },
  {
    "objectID": "LC/Learning-checks.html#lc-11.1",
    "href": "LC/Learning-checks.html#lc-11.1",
    "title": "Learning Checks from Modern Dive",
    "section": "LC 11.1",
    "text": "LC 11.1\nRepeat the regression modeling in Subsection 11.2.3 and the prediction making you just did on the house of condition 5 and size 1900 square feet in Subsection 12.2.4, but using the parallel slopes model you visualized in Figure 11.6. Show that it’s $524,807!"
  },
  {
    "objectID": "LC/Learning-checks.html#lc-11.2",
    "href": "LC/Learning-checks.html#lc-11.2",
    "title": "Learning Checks from Modern Dive",
    "section": "LC 11.2",
    "text": "LC 11.2\nWhat date between 1994 and 2003 has the fewest number of births in the US? What story could you tell about why this is the case?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "outline.html",
    "href": "outline.html",
    "title": "Evolving outline for Stats 300",
    "section": "",
    "text": "Textbook: Ismay & Kim Statistical Inference via Data Science (“SIDS” for short)\nSoftware: R, which the textbook is based on and which is used in Math 141/142Z\nSupplemental readings:"
  },
  {
    "objectID": "outline.html#bradley-warners-outline-from-14-apr-2022.",
    "href": "outline.html#bradley-warners-outline-from-14-apr-2022.",
    "title": "Evolving outline for Stats 300",
    "section": "Bradley Warner’s outline from 14 Apr 2022.",
    "text": "Bradley Warner’s outline from 14 Apr 2022.\nFour blocks to the semester, each with a QR.\n\nStatistical graphics, wrangling, importing. SIDS Part I (Chaps. 1, 2, 3, 4)\n\n12 class days (including GR)\n\nRegression. SIDS Part II (Chaps. 5, 6)\n\n8 class days (including GR)\n\nConfidence intervals. SIDS Part III (Chaps. 7, 8)\n\n7 class days (including GR)\n\nHypothesis testing. SIDS Part III (cont.) (Chaps. 9, 10)\n\n11 class days (including GR)\n\n\nTwo end-of-semester days for case-study, more examples."
  },
  {
    "objectID": "outline.html#dtk-comments-on-warners-outline",
    "href": "outline.html#dtk-comments-on-warners-outline",
    "title": "Evolving outline for Stats 300",
    "section": "DTK comments on Warner’s outline",
    "text": "DTK comments on Warner’s outline\n\nSIDS part I\n\nSuggest we soft pedal the histograms in favor of density, similarly violin plots instead of box-and-whiskers.\nFour-five days on relational operations sounds right.\nMake case study about coding and cleaning data, with students transcribing data from archival records (Examples from History Dept). Also, accessing online data such as from World Bank (Political Science wants this), wide to long. 3 days.\n\nSIDS part II\n\nTime frame sounds right.\nAdd a component about prediction and classification. CART, logistic regression\nIntroduce decision theory here: loss function, ROC\n\nand 4. SIDS part III\n\nEighteen days is too long to spend on p-values and CIs. I suggest we budget 6 days.\nBefore doing inference based on sampling variation, let’s have a 6-day unit on covariates, adjustment, study design as a way to deal with unknown covariates (e.g. case control), cross-sectional versus longitudinal\nThen do CIs and p-values, lightly, emphasizing that they have little or nothing to say unless you get the study design right and deal with covariates.\nEven though I’m suggesting adding prediction and classification in Block 2, I think that techniques like cross-validation do not need to be covered.\n\n\nOverall, I think that our emphasis should be that the hard and creative work of learning from data is collecting/wrangling, visualizing, modeling, and dealing with covariates. Once the thought and creativity and hard work has been done, use p-values and CIs as a sanity check, not as a primary form of analysis. Emphasize loss functions and the trade-off between the different types of error when making conclusions."
  },
  {
    "objectID": "fall2022.html",
    "href": "fall2022.html",
    "title": "Fall 2022 Edition",
    "section": "",
    "text": "Explanation This is an annotated schedule of the Fall 2022 edition of Math 300, the first semester when it’s being taught from the Modern Dive textbook. The annotations refer to proposed changes for Spring 2023.\nThis schedule, based on this Teams file, is current as of Sept 9, 2022. This document will be updated to reflect any re-arrangement of the Math 300 Fall 2022 schedule."
  },
  {
    "objectID": "fall2022.html#block-1-data-graphics-and-wrangling",
    "href": "fall2022.html#block-1-data-graphics-and-wrangling",
    "title": "Fall 2022 Edition",
    "section": "Block 1: Data, Graphics, and Wrangling",
    "text": "Block 1: Data, Graphics, and Wrangling\n\nData with R\n\nReading: MD1 Chapter 1\nHomework: LC2 1.1 - 1.7\n\n\nScatterplots\n\nReading: MD §2 - 2.3\n\nHomework: LC 2.1 - 2.8\n\n\nLinegraphs, Histograms, and Facets\n\nReading: MD §2.4 - 2.6\n\nHomework: LC 2.9 -2.21\n\n\nBoxplots and Barcharts\n\nReading: §2.7 - 2.9\n\nHomework: LC 2.22 - 2.37\n\n\nfilter and summarize\n\nReading: MD §3 - 3.3\n\nHomework:\n\nLC 3.1 - 3.4,\nProblem Set 1\n\n\ngroup_by, mutate, and arrange\n\nReading: MD §3.4 - 3.6\n\nHomework LC 3.5 - 3.12\n\n\njoin, select, rename, and top_n\n\nReading: MD §3.7 - 3.9\n\nHomework: LC 3.13 - 3.20\n\n\nImporting Data\n\nReading: MD §4 - 4.2\n\nHomework: LC 4.1 - 4.3\n\n\nCase Study/ Review\n\nReading: 4.3 - 4.5\n\nHomework:\n\nLC 4.4 - 4.5\nProblem Set 2\n\n\nGR 1 (Chapters 1-4)"
  },
  {
    "objectID": "fall2022.html#block-2-regression",
    "href": "fall2022.html#block-2-regression",
    "title": "Fall 2022 Edition",
    "section": "Block 2: Regression",
    "text": "Block 2: Regression\n\nSLR3 - Continuous x\n\nReading: §5 - 5.1\nHomework: LC 5.1 - 5.3\n\n\nSLR - Discrete x\n\nReading: §5.2\nHomework: LC 5.4 - 5.7\n\n\nSLR - Related Topics\n\nReading: §5.3 - 5.4\nHomework: LC 5.8\n\n\nMultiple Regression - Numerical & Discrete\n\nReading: §6 - 6.1\nHomework:\n\nLC 6.1\n\nProblem Set 3\n\n\nMultiple Regression - Two Numerical\n\nReading: §6.2\nHomework: LC 6.2 - 6.3\n\n\nMultiple Regression - Related Topics\n\nReading: §6.3\n\n\nMultiple Regression Conclusion/Review\n\nReading: §6.4\n\nHomework: PS 4\n\nGR 2 (Chapters 5-6) GR 2"
  },
  {
    "objectID": "fall2022.html#block-3-sampling-variability-and-confidence-intervals",
    "href": "fall2022.html#block-3-sampling-variability-and-confidence-intervals",
    "title": "Fall 2022 Edition",
    "section": "Block 3: Sampling variability and confidence intervals",
    "text": "Block 3: Sampling variability and confidence intervals\n\nSampling\n\nReading: §7 - 7.2\nHomework: LC 7.1 - 7.7\n\n\nSampling Framework\n\nReading: §7.3\nHomework: LC 7.8 - 7.20\n\n\nCase Study\n\nReading: §7.4\nHomework: LC 7.21 - 7.24\n\n\nCLT, Normal Distribution\n\nReading: §A.2, 7.5 - 7.6\n\nHomework: LCA.1, LCA.2\n\n\nBootstrap Intro\n\nReading: §8 - 8.2\nHomework:\n\nLC 8.1 - 8.2\n\nProblem Set 5\n\n\nUnderstanding CI\n\nReading: §8.3\nHomework: LC 8.3 - 8.4\n\n\nConstructing CI\n\nReading: §8.4\nHomework: LC 8.5\n\n\nInterpreting CI\n\nReading: §8.5\n\n\nCase Study\n\nReading: §8.6\n\nHomework: Problem Set 6\n\nGR 3 (Chapters 7-8) GR3"
  },
  {
    "objectID": "fall2022.html#block-4-hypothesis-tests",
    "href": "fall2022.html#block-4-hypothesis-tests",
    "title": "Fall 2022 Edition",
    "section": "Block 4: Hypothesis tests",
    "text": "Block 4: Hypothesis tests\n\nPermutation Tests\n\nReading: §9 - 9.1\n\n\nConducting Hypothesis Tests\n\nReading: §9.2 - 9.3\n\nHomework: LC 9.1 - 9.4\n\n\nInterpreting Hypothesis Tests\n\nReading: §9.4\nHomework: LC 9.5 - 9.8\n\n\nCase Study\n\nReading: §9.5\nHomework: LC 9.9 - 9.15\n\n\nMore on Hypothesis Tests\n\nReading: §9.6\n\n\nInterpreting Regression Tables\n\nReading: §10 - 10.2\n\nHomework: Problem Set 7\n\nRegression Assumptions\n\nReading: §10.3\n\nHomework: LC 10.1\n\nRegression Inference via Simulation\n\nReading: §10.4\n\nHomework: LC 10.2\n\nSummary\n\nReading: §10.5\n\nHomework: PS 8\n\nGR 4 (Chapters 9-10) GR 4\nCase Study\n\nReading: §11 - 11.2\n\nHomework: LC 11.1\n\nInference Examples\n\nReading: B (???)"
  },
  {
    "objectID": "LC/Learning-checks.html#lc-10.2",
    "href": "LC/Learning-checks.html#lc-10.2",
    "title": "Learning Checks from Modern Dive",
    "section": "LC 10.2",
    "text": "LC 10.2\nContinuing with our regression using age as the explanatory variable and teaching score as the outcome variable.\n\nUse the get_regression_points() function to get the observed values, fitted values, and residuals for all 463 instructors.\nPerform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern but comment on what you find here."
  },
  {
    "objectID": "LC/Learning-checks.html#lc-10.2-1",
    "href": "LC/Learning-checks.html#lc-10.2-1",
    "title": "Learning Checks from Modern Dive",
    "section": "LC 10.2",
    "text": "LC 10.2\nRepeat the inference but this time for the correlation coefficient instead of the slope. Note the implementation of stat = \"correlation\" in the calculate() function of the infer package."
  },
  {
    "objectID": "objectives-diffs.html",
    "href": "objectives-diffs.html",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "",
    "text": "Objectives for blocks 3 and 4."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 300Z — Proposed revisions to Fall 2022 Stat 300",
    "section": "",
    "text": "Objectives for blocks 3 and 4."
  },
  {
    "objectID": "objectives-diffs.html#lesson-21",
    "href": "objectives-diffs.html#lesson-21",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 21",
    "text": "Lesson 21\n\n\n\n\n\n\n\n\nStat 300 Lesson 21\n\n\n\n1.Given a sampling scenario, discuss issues such as accuracy and precision as they relate to generalization to the population of interest.\n\n\n\n\n\n\n\n\nStat 300Z Lesson 21\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-24",
    "href": "objectives-diffs.html#lesson-24",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 24",
    "text": "Lesson 24\n\n\n\n\n\n\n\n\nStat 300 Lesson 24\n\n\n\n\nExplain how to construct a confidence interval using both the percentile method and the standard error method including assumptions. *DK note: Unless you want to emphasize the normal distribution, this is a technical issue and shouldn’t be prioritized.\nExplain how changing the confidence level impacts the width of a confidence interval.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 24\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-27",
    "href": "objectives-diffs.html#lesson-27",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 27",
    "text": "Lesson 27\n\n\n\n\n\n\n\n\nStat 300 Lesson 27\n\n\n\n\nCalculate, using both percentile and standard error methods, confidence intervals for a difference of two proportions.\nCalculate a normal-based, theory-based, confidence interval for a single proportion or mean.\nCorrectly use all terms and notation to include standard error, margin of error, sampling distribution, and bootstrap distribution.\nCompare and contrast sampling distribution and bootstrap distribution.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 27\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-25",
    "href": "objectives-diffs.html#lesson-25",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 25",
    "text": "Lesson 25\n\n\n\n\n\n\n\n\nStat 300 Lesson 25\n\n\n\n\nConstruct bootstrap percentile and standard error confidence intervals for a single mean or median using the infer package.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 25\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-19",
    "href": "objectives-diffs.html#lesson-19",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 19",
    "text": "Lesson 19\n\n\n\n\n\n\n\n\nStat 300 Lesson 19\n\n\n\n\nExplain the need for randomization in sampling.\nExplain the impact of sample size on the sample distribution and number of replications on the sampling procedure.\nUsing a sampling distribution, make decisions about the population. In other words, understanding the effect of sampling variation on our estimates.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 19\n\n\n\n\nUse and explain the terms accuracy and precision and the technical terms bias and variance.\nREWRITE: Covariates, confounders …\nREWRITE: Sampling variation"
  },
  {
    "objectID": "objectives-diffs.html#lesson-20",
    "href": "objectives-diffs.html#lesson-20",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 20",
    "text": "Lesson 20\n\n\n\n\n\n\n\n\nStat 300 Lesson 20\n\n\n\n\nKnow and correctly use the terminology and notation for the sampling concepts such as population, census, point estimate, biased, etc.\nExplain the impact of sample size on the sample distribution and number of replications on the sampling procedure.\nUse and explain the terms accuracy and precision in the context of sampling.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 20\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-22",
    "href": "objectives-diffs.html#lesson-22",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 22",
    "text": "Lesson 22\n\n\n\n\n\n\n\n\nStat 300 Lesson 22\n\n\n\n\nExplain the central limit theorem.\nFor a normal distribution, use R to find probabilities and percentiles.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 22\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-23",
    "href": "objectives-diffs.html#lesson-23",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 23",
    "text": "Lesson 23\n\n\n\n\n\n\n\n\nStat 300 Lesson 23\n\n\n\n\nExplain the concept of a bootstrap distribution using proper terminology and notation.\nUse R to find the bootstrap distribution of a sample statistic.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 23\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-26",
    "href": "objectives-diffs.html#lesson-26",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 26",
    "text": "Lesson 26\n\n\n\n\n\n\n\n\nStat 300 Lesson 26\n\n\n\n\nCorrectly interpret a confidence interval to include identifying incorrect statements.\nExplain the factors that impact the width of a confidence interval.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 26\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-28",
    "href": "objectives-diffs.html#lesson-28",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 28",
    "text": "Lesson 28\n\n\n\n\n\n\n\n\nStat 300 Lesson 28\n\n\n\nNo items listed.\n\n\n\n\n\n\n\n\nStat 300Z Lesson 28\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-29",
    "href": "objectives-diffs.html#lesson-29",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 29",
    "text": "Lesson 29\n\n\n\n\n\n\n\n\nStat 300 Lesson 29\n\n\n\n\nExplain the permutation test and compare and contrast it with a bootstrap distribution.\nGenerate and interpret visualizations for data with two categorical variables.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 29\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-30",
    "href": "objectives-diffs.html#lesson-30",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 30",
    "text": "Lesson 30\n\n\n\n\n\n\n\n\nStat 300 Lesson 30\n\n\n\n\nCorrectly use terminology and notation of hypothesis testing.\nUsing the infer package, conduct a hypothesis test and interpret the results.\nCompare and contrast confidence intervals and hypothesis tests.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 30\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-31",
    "href": "objectives-diffs.html#lesson-31",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 31",
    "text": "Lesson 31\n\n\n\n\n\n\n\n\nStat 300 Lesson 31\n\n\n\n\nCorrectly use terminology and notation of interpreting hypothesis tests.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 31\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-32",
    "href": "objectives-diffs.html#lesson-32",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 32",
    "text": "Lesson 32\n\n\n\n\n\n\n\n\nStat 300 Lesson 32\n\n\n\n\nConduct and interpret a hypothesis test for the difference of two means.\nCalculate and interpret a confidence interval for the difference of two means.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 32\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-33",
    "href": "objectives-diffs.html#lesson-33",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 33",
    "text": "Lesson 33\n\n\n\n\n\n\n\n\nStat 300 Lesson 33\n\n\n\n\nStandardize a variable.\nFind percentile and probabilities for the t distribution; this includes determining the correct degrees of freedom.\nUse the infer package to conduct a theory-based hypothesis test.\nKnow and verify the assumptions of the two-sample t-test.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 33\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-34",
    "href": "objectives-diffs.html#lesson-34",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 34",
    "text": "Lesson 34\n\n\n\n\n\n\n\n\nStat 300 Lesson 34\n\n\n\n\nBuild and interpret a regression table and use correct terminology.\nWrite the hypotheses from the regression table.\nUse the p-value from a regression table to make a decision about the relationship between the explanatory and response variables.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 34\n\n\n\n\nUse software to build regression and ANOVA tables from linear regression.\nInterpret a regression table in terms of parameters, confidence intervals, and coefficient-wise p-values.\nInterpret an ANOVA table as a whole-model summary.\nUse ANOVA for model selection among nested models."
  },
  {
    "objectID": "objectives-diffs.html#lesson-35",
    "href": "objectives-diffs.html#lesson-35",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 35",
    "text": "Lesson 35\n\n\n\n\n\n\n\n\nStat 300 Lesson 35\n\n\n\n\nExplain and test the assumptions for inference in a linear regression model.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 35\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-36",
    "href": "objectives-diffs.html#lesson-36",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 36",
    "text": "Lesson 36\n\n\n\n\n\n\n\n\nStat 300 Lesson 36\n\n\n\n\nConstruct and interpret bootstrap confidence intervals, both percentile and standard error method, for regression parameters such as slope and correlation coefficient.\nConduct and interpret a permutation test on the regression slope parameter.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 36\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-37",
    "href": "objectives-diffs.html#lesson-37",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 37",
    "text": "Lesson 37\n\n\n\n\n\n\n\n\nStat 300 Lesson 37\n\n\n\n\nUse the output of a regression table to conduct a hypothesis test and build a confidence interval for the slope parameter from a linear regression model.\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 37\n\n\n\n\nOne\nTwo\nThree"
  },
  {
    "objectID": "objectives-diffs.html#lesson-38",
    "href": "objectives-diffs.html#lesson-38",
    "title": "Stat 300 objectives vs Stat 300Z",
    "section": "Lesson 38",
    "text": "Lesson 38\n\n\n\n\n\n\n\n\nStat 300 Lesson 38\n\n\n\n\n\n\n\n\n\n\n\n\nStat 300Z Lesson 38\n\n\n\n\nOne\nTwo\nThree"
  }
]