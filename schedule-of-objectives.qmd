---
title: "Day-by-day Objectives for Math 300R"
author: "Danny Kaplan"
format:
  html:
    theme: cosmo
  pdf:
    documentclass: scrreprt
  docx:
    number-sections: false
---

## Lessons 1-18

As done in Fall 2020. Possible revisions to those lessons is not a topic of this proposal.

## Lesson 19: Decisions with data ([nti](NTI/Math300R-Lesson19.html))

#. Distinguish between the two settings for decision-making: 

    a. **Prediction**: predict an outcome for an individual
    b. **Relationship**: characterize a relationship with an eye toward intervention or a better understanding of how a mechanism works.
    
#. Given a research question, identify whether it corresponds to a prediction setting or a relationship setting.

## Lesson 20: Reality versus gaming ([nti](NTI/Math300R-Lesson20.html)) {#gaming-intro} 

#. Gaming: Understand that gaming is a way of improving our skills and identifying potential opportunities and problems. 

#. Distinguish between a sample, a summary of a sample, and a sample of summaries of samples.

## Lesson 21: DAGs, noise, and simulation ([nti](NTI/Math300R-Lesson21.html))

#. Determine whether a proposed graph is directed and acyclic.

#. Read notation to identify response variable, explanatory variable, covariates, and effect sizes.

#. Characterize the magnitude of random noise.

#. Gaming: Generate data from simulations and use the data to model the relationships.

<!-- noise sources for simulation, normal, two-sided exponential, dicotomizer. Maybe use a pipe for the added noise, e.g. children |> epsilon(0.5) -->

## Lesson 22: Sampling variation ([nti](NTI/Math300R-Lesson22.html))

#. Gaming: Implement on the computer a procedure to generate a sample, calculate a regression model, and produce a summary.

#. Gaming: Iterate the procedure and collect the summaries across iterations. This collection is called the "sampling distribution."

#. Graphically display the distribution of summaries and generate a compact numerical description ("confidence interval") of the sampling distribution.

#. Understand and use scaling of confidence interval length as a function of $n$.

## Lesson 23: Estimate sampling variation from a single sample ([nti](NTI/Math300R-Lesson23.html))

#. Use bootstrapping to estimate sampling variation.

#. Infer sampling variation from a regression table: "standard error" of a model coefficient.

#. Construct and interpret confidence intervals on a model coefficient.

## Lesson 24: Effect size ([nti](NTI/Math300R-Lesson24.html))

#. Estimate an effect size from a regression model of the two variables.

#. Construct a confidence interval on the effect size.

#. Gaming: Evaluate whether confidence interval indicates that estimated effect size is consistent with simulation.

## Lesson 25: Mechanics of prediction ([nti](NTI/Math300R-Lesson25.html))

#. Given a sample from a DAG simulation, construct a predictor function for a specified response variable.

#. Use the predictor function to estimate prediction error on a given DAG sample and summarize with root mean square (RMS) error.

#. Distinguish between in-sample and out-of-sample prediction estimates of prediction error. 

## Lesson 26: Constructing a prediction interval ([nti](NTI/Math300R-Lesson26.html))

#. In evaluating a model function, generate a prediction interval.

#. Interpret prediction bands as a series of intervals, one for each value of the model input.

#. Identify the two components that make up a prediction error, one that scales with $n$ and the other that doesn't.

## Lesson 27: Covariates ([nti](NTI/Math300R-Lesson2y.html))

#. Show that including covariates in a prediction model always reduces in-sample mean square residual, but may not reduce residuals out-of-sample. 

#. Given regression coefficients, calculate model degrees of freedom and residual degrees of freedom.

#. Calculate amount of in-sample mean square error reduction to be expected with a useless (random) covariate. (Residual sum of squares divided by residual degrees of freedom.)

## Lesson 28: Covariates eat variance ([nti](NTI/Math300R-Lesson28.html))

#. Construct F statistic as ratio of incremental increase in model mean square due to model term(s) divided by residual mean square. 

#. Use software to construct ANOVA report and correctly interpret F statistics for prediction model term selection.


## Lesson 29: Confounding ([nti](NTI/Math300R-Lesson29.html))

#. Identify confounding in a DAG

#. Choose whether to include covariate depending on form of DAG


## Lesson 30: Non-causal correlation ([nti](NTI/Math300R-Lesson30.html))

#. Distinguish "common cause" and "collider" forms of DAG.

#. Construct appropriate DAG to match a narrative hypothesis.

## Lesson 31: Experiment and random assignment ([nti](NTI/Math300R-Lesson31.html))

#. Properly use nomenclature of experiment.

#. Correctly re-draw DAG for an ideal experimental intervention.

#. Use blocking to set assignment to treatment or control.

## Lesson 32: Measuring and accumulating risk ([nti](NTI/Math300R-Lesson32.html))

#. Distinguish between absolute and relative risk and identify when a change in risk is being presented as absolute or relative.

#. Calculate and correctly interpret other presentations of differences in risk: population attributable fraction, NTT, odds ratio.

#. Interpret effect size as stated in log odds.

## Lesson 33: Constructing a classifier ([nti](NTI/Math300R-Lesson33.html))

#. Build a classifier from case-control data.

#. Cross-tabulate classifier results versus true state. Evaluate false-positive rate, false-negative rate, accuracy.

#. Calculate different forms of conditional probability: p(A|B) versus p(B|A) and identify which form of conditional probability is useful for prediction of an individual's outcome.

## Lesson 34: Accounting for prevalence ([nti](NTI/Math300R-Lesson34.html))

#. Explain why case-control data may not give an proper measure of "prevalence."

#. Understand sensitivity and specificity as conditional probabilities.

#. Calculate false-positive and false-negative rates for a given prevalence.


## Lesson 35: Hypothesis testing ([nti](NTI/Math300R-Lesson35.html))

#. Understand and use properly hypothesis testing nomenclature: test statistic, sampling distribution under the null, Type-1 and Type-2 error, rejection threshold, p-value

#. Contrast hypothesis testing versus Bayesian framework. 


## Lesson 36: Calculating a p-value ([nti](NTI/Math300R-Lesson36.html))

#. The permutation test

#. Interpret correctly from regression/ANOVA reports

#. Traditional names for hypothesis tests in different "textbook" settings.

#. Distinguish between p-value and effect size, that is, "significance" and "substance."


## Lesson 37: False discovery with hypothesis testing ([nti](NTI/Math300R-Lesson37.html))

#. Identify signs of false discovery in a research paper.

#. Estimate how overall p-value should change when study is replicated.






## Alternative 1

Theme: Classifiers: ROC and loss function

## Alternative 2

Theme: Accumulating risk: Logistic regression
