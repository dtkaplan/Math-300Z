---
title: "Math 300R Lesson `r (lesson <- 30)` Reading Notes"
subtitle: "Confounding"
author: "Prof. Danny Kaplan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
source("../_startup.R")
```

Suppose you are concerned that the chemicals used by lawn-greening companies are a source of cancer or other illness. You propose to find out by collecting and modeling data; sampling many households that have used lawn-greening chemicals for at least a decade and other households that have never used lawn-greening chemicals. You'll record both chemical use and a measure of health outcome: whether anyone in that household has developed cancer in the last five years.

```{r echo=FALSE}
# Same dag mechanism, wealth not shown in the first one
dag_lawn1 <- dag_make(
  .wealth ~ eps(),
  grass ~ binom(.wealth - 0.5, labels=c("organic", "chemicals")),
  cancer ~ binom(-2*(.wealth+2.5) + 0.5*(grass == "chemicals"), labels=c("no", "yes"))
)
dag_lawn2 <- dag_make(
  wealth ~ eps(),
  grass ~ binom(wealth - 0.5, labels = c("organic", "chemicals")),
  cancer ~ binom(-2*(wealth+2.5) + 0.5*(grass == "chemicals"), labels=c("no", "yes"))
)
# set.seed(104); dag_draw(dag_lawn1)

set.seed(120) # important to get the misleading display
Cancer_data <- sample(dag_lawn2, size=1000) 
```

Here are a few rows from the data (which we have simulated for this example):

```{r echo=FALSE}
Cancer_data[330:339,] %>% select(-wealth) %>% knitr::kable()
```

Analyzing such simple data is straightforward, since we are interested in the possible role of grass-greening chemicals in increasing risk of cancer. First, check the overall cancer rate:

```{r}
# overall cancer rate
lm(zero_one(cancer, one="yes") ~ 1, data = Cancer_data) %>% coefficients()
```

In these data, 2.6% of the sampled households had a cancer in the last five years. But how does the grass treatment affect that rate?

```{r}
mod <- lm(zero_one(cancer, one="yes") ~ grass, data = Cancer_data)
coefficients(mod)
```

For households whose lawn treatment is "organic," the risk of cancer is higher by 2.3 percentage points compared to households that treat their grass with chemicals. This is certainly not what we were expecting, but it is what the data show. On the other hand, there is sampling variability to take into account. Let's look at the confidence intervals:

```{r}
confint(mod)
```

The confidence interval on `grassorganic` does not include zero, but it comes pretty close. We are not sure what to conclude: Might the chemical treatment of grass be protective against cancer? This seems implausible. Might we have causality backwards? Hard to imagine that the appropriate DAG is $\text{cancer} \rightarrow \text{chemical treatment}$; causation must be the other way around:

$$\text{cancer} \leftarrow \text{chemical treatment}\ .$$

The statistical thinker knows to consider the possible role of other factors. To form reasonable hypotheses, you need some knowledge of how the system under study works. For instance, green grass is not a necessity, so the households who treat their lawn with chemicals tend to have money to spare. It's also the case that health outcomes are somewhat better for wealthier people. In part this is because of better access to health care. Another factor is that wealthier people can live in less polluted neighborhoods and are less likely to work in dangerous conditions, such as exposure to toxic chemicals. This suggests a DAG hypothesis where "`wealth`" influences how the household's `grass` is treated and `wealth` similarly influences the risk of developing `cancer`. Like this: 

```{r echo=FALSE}
set.seed(102)
dag_draw(dag_lawn2)
```

A description of this structure of causality is, "The effect of grass treatment on cancer is **confounded** by wealth." The Oxford Dictionary has two definitions of "confound."

1. *Cause surprise or confusion in someone, especially by acting against their expectations.* 
2. *Mix up something with something else so that the individual elements become difficult to distinguish.*

It is this second definition that describes the statistical meaning of "confound." 

To be sure, the first definition seems relevant to our story, since the protagonist expected that chemical use would be associated with higher cancer rates and was surprised to find otherwise. But the statistical thinker doesn't throw up her hands when faced with the mixing up of causal factors. Instead, she uses modeling techniques to untangle the influences of the various factors.

Using covariates in models is one such technique. For instance, in generating the simulated data shown above, we used a DAG which associated greater wealth with chemical treatment of grass and also, separately, with better health outcomes. `Wealth` is one of the variables included in the data, even if we didn't show it earlier in the example:

```{r echo=FALSE}
Cancer_data[330:339,] %>%  knitr::kable()
```

Including `wealth` as a covariate in this case untangles the system so that we can see the *direct* link between chemicals and health. 

```{r}
lm(zero_one(cancer, one="yes") ~ grass + wealth, data = Cancer_data) %>%
  confint()
```

Same data, but the opposite conclusion. With `wealth` as a covariate, "organic" lawn treatment  (that is, leaving things be!) reduces the risk of cancer. But the bigger factor in shaping cancer risk is represented by `wealth`.

Keep in mind that this is simulated data. So don't draw any conclusions from the data in this example about the safety of the chemicals used by lawn-greening companies.



## DAGs and covariates

The argument, "reduce spending by reducing spending" is very compelling, common sense even. It's harder to see how reducing spending in one area---the cash payment to people not on the insurance plan---can increase spending overall. I might have been more successful convincing the college budget committee not to eliminate the cash payment if they had understood the language of DAGs. @fig-insurance-two-dags shows two competing DAGs for the situation:

```{r echo=FALSE}
#| label: fig-insurance-two-dags
#| fig-cap: "Two different DAGs relevant to the debate about eliminating the cash payment to employees not on the college's health care plan."
#| layout-ncol: 2
#| fig-cap: 
#|   - "One path from cash to expenditures"
#|   - "Two paths from cash to expenditures"
dagA <- dag_make(`Cash payment` ~ 1, 
                 Enrollment ~ 1,
                 `Expenditures` ~ `Cash payment` + Enrollment)
dagB <- dag_make(`Cash payment` ~ 1, 
                 `Enrollment` ~ `Cash payment`,
                 `Expenditures` ~ `Cash payment` + `Enrollment`)
set.seed(107); dag_draw(dagA); set.seed(107); dag_draw(dagB)
```

The people on the budget committee saw clearly the direct link between the cash payment and total expenditures and likely would not have disputed a direct link between enrollment and expenditures. But they didn't imagine a link between the cash payment and enrollment. I did, because I knew of several colleagues who used their spouse's companies insurance plan, even though it was identical to the college's plan.

The situation with the drug aprotinin is similar. 

```{r echo=FALSE}
#| label: fig-drugs-two-dags
#| fig-cap: "Two different DAGs relevant to the link between aprontinin and mortality."
#| layout-ncol: 2
#| fig-cap: 
#|   - "One path from cash to expenditures"
#|   - "Two paths from cash to expenditures"
dagA <- dag_make(`Health condition` ~ 1, 
                 Aprontinin ~ 1,
                 Mortality ~ `Health condition` + Aprontinin)
dagB <- dag_make(`Health condition` ~ 1, 
                 Aprontinin ~ `Health condition`,
                 Mortality ~ `Health condition` + Aprontinin)
set.seed(107); dag_draw(dagA); set.seed(107); dag_draw(dagB)
```

LOOK AT SOME DAGs to show what happens when you include a covariate: which links you study.













