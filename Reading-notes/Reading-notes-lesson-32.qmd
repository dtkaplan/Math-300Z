---
title: "Math 300R Lesson `r (lesson <- 32)` Reading Notes"
subtitle: "Experiment and random assignment"
author: "Prof. Danny Kaplan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
source("../_startup.R")
```



## From SM2

One of the most important ideas in science is "**experiment**". In a simple, ideal form of an experiment, you cause one explanatory factor to vary, hold all the other conditions constant, and observe the response.  A famous story of such an experiment involves Galileo Galilei (1564-1642) `r index_entry('C','Galileo Galilei')` `r index_entry('C', 'Pisa, Leaning Tower')`  dropping balls of different masses but equal diameter from the Leaning Tower of Pisa.^[The picturesque story of balls dropped from the Tower of Pisa may not be true. Galileo did record experiments done by rolling balls down ramps.] Would a heavy ball fall faster than a light ball, as theorized by Aristotle 2000 years previously?  The quantity that Galileo varied was the weight of the ball, the quantity he observed was how fast the balls fell, the conditions he held constant were the height of the fall and the diameter of the balls.  The experimental method of dropping balls side by side also holds constant the atmospheric conditions: temperature, humidity, wind, air density, etc.

Of course, Galileo had no control over the atmospheric conditions.  By carrying out the experiment in a short period, while atmospheric conditions were steady, he effectively held them constant.

Today, Galileo's experiment seems obvious.  But not at the time.  In the history of science, Galileo's work was a landmark: he put *observation* at the fore, rather than the beliefs passed down from authority.  Aristotle's ancient theory, still considered authoritative in Galileo's time, was that heavier objects fall faster. 

`r index_entry('C', 'experiment! vs observation')` 
`r index_entry('C', 'relationship!partial vs total')` 
`r index_entry('C', 'partial relationship')` 
`r index_entry('C', 'total relationship')` 
`r index_entry('C', 'aprotinin (drug)')` 
`r index_entry('C', 'heart surgery')` 

The ideal of "holding all other conditions constant" is not always so simple as with dropping balls from a tower in steady weather.  Consider an experiment to test the effect of a blood-pressure drug. Take two groups of people, give the people in one group the drug and give nothing to the other group.  Observe how blood pressure changes in the two groups.  The factor being caused to vary is whether or not a person gets the drug. But what is being held constant?  Presumably the researcher took care to make the two groups as similar as possible: similar medical conditions and histories, similar weights, similar ages.  But "similar" is not "constant." 



## DAG interpretation of experiment

Albert Einstein is reputed to have said:

> *A theory is something nobody believes, except the person who made it. An experiment is something everybody believes, except the person who made it.*

A graphical causal network is a kind of theory. As a theory, it's natural for people to be skeptical about results stem from the theory. Experiments are more persuasive. Let's consider what an experiment looks like when represented by a graphical causal networks.

In an experiment, you have some real-world system and a means to intervene physically on at least one of the variables in that system and to read out the response of the system to the intervention. You don't necessarily know much about the actual structure of the real world system. In @fig-experiment-system the real-world system is shown in the rounded box. The intervention is on X and the output is Y.

```{r echo = FALSE}
#| label: fig-experiment-system
#| fig-cap: "An experiment is a system in which there is an intervention and an output."
knitr::include_graphics("www/experiment-system.png")
```


Note that in @fig-experiment-system X is, potentially, affected by other variables in the system.

Ideally, the experiment is set up to eliminate all other effects on X except the intervention as in @fig-experiment-pure. And the intervention is done in a way that none of the variables in the system can have any effect on it, for instance by assigning the intervention using a **computer random-number generator**. The lovely thing about this configuration is that the correct model to capture the effect of `X` on `Y` is simply `Y ~ X`. Whatever different people might believe about the real-world mechanism doesn't matter. The correct model is always `Y ~ X`. This is why Einstein's statement, "An experiment is something everybody believes," is justified.

```{r echo = FALSE}
#| label: fig-experiment-pure
#| fig-cap: "An ideal experiment is one where the *only* influence on X is the intervention. Any effect on X or the intervention of the other variables in the system has been eliminated. The input paths to X from C and D that appear in @fig-experiment-system have been deleted by the experimenter. This is not always possible in practice."
knitr::include_graphics("www/experiment-pure.png")
```


But there is another part to Einstein's statement: "... except the person who made it." Why shouldn't the experimenter believe her own experiment? The experimenter might know that she didn't or couldn't conduct an ideal experiment. She wasn't actually able to eliminate the arrows D $\rightarrow$ X and C $\rightarrow$ X. The other variables in the system might also be influencing X as in @fig-experiment-system. In this situation, the right model may not be Y `~` X. In fact, for the particular system shown in @fig-experiment-system the correct model would be Y `~` X + C + D. But how could the experimenter know this for sure if she didn't know all about the real-world mechanism?

It turns out that for either of the causal systems in [Figures @fig-experiment-system or @fig-experiment-pure] there is always a correct model to show the link between the intervention and output: Output `~` Intervention. Rather than modeling the output by the physical quantity X, model the output by the random numbers generated by the computer that were used to set the intervention. This modeling approach is called **intent to treat**.

Typically, experiments are done using a specially constructed system that is thought to resemble the system on which the intervention will actually be done. Insofar as the experimental system does resemble the real-world system, the experimental results will anticipate the effect of the real-world intervention. But often it's hard to establish that the experimental system is a match to the system on which the real-world intervention will be applied. As such, subjective belief is still a factor in accepting that the experiment will be informative about the real-world systems we work with.
 
--------

It's appropriate to show some humility about models and recognize that they can be no better than the assumptions that go into them.  Useful object lessons are given by the episodes where conclusions from modeling (with careful adjustment for covariates) can be compared to experimental results.  Some examples (from [@freedman-editorial-2008]):

* Does it help to use telephone canvassing to get out the vote? Models suggest it does, but experiments indicate otherwise.
* Is a diet rich in vitamins, fruits, vegetables and low in fat protective against cancer, heart disease or cognitive decline? Models suggest yes, but experiments generally do not.

The divergence between models and experiment suggests that an important covariate has been left out of the models. `r index_entry('C', 'covariate!leaving out')`  `r index_entry('C', 'adjustment!faulty')` 


