---
title: "Math 300R Lesson `r (lesson <- 23)` Reading Notes"
subtitle: "title goes here"
author: "Prof. Danny Kaplan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

### Review 

- Case : a row in a data frame
- Sample: a data frame.
- Summarized sample: lm(model, data=dataframe) %>% summary()

This is as far as we can go with real data. DAG simulation (gaming) let us go further:

- Sample: a draw of $n$ cases from the DAG: sample(DAG, size=50) 
- Trial: a summarized sample: 
    ```r
trial <- function(n=50) {
  lm(tilde, data=sample(DAG, size=n) %>% summary()
}
    ```
- Repeated trials to see **sampling:distribution**: `do(100) * trial()`
- Summarize the repeated trials: e.g. standard deviation of trial-by-trial coefficients
    ```r
    do(100) * trial() %>% summarize(sd = sd(coef_on_x))
    ```
We found that the standard deviation of trial-by-trial coefficient

i. Is smaller if $n$ is bigger.
ii. Specifically, is proportional to $\frac{1}{\sqrt{n}}$.

::: {.callout-note icon=false}
## Formulas for sampling distributions

Statistics textbooks often give formulas for the standard deviation of the sampling distribution. The formulas have been constructed for many of the standard situations. To give you an idea of how this is done, let's go over the very simplest situation.

System: $\epsilon \longrightarrow y$ with tilde `xy~ 1`.

Interpretation: The coefficient on `1`, that is, the "intercept" is an estimate of the mean of $y$.

THIS IS JUST A SKETCH.

When $n=1$, that is, the mean of a sample of size $n=1$, the standard deviation of the sampling distribution is just $sd(y)$. Of course, we can't estimate this from a single sample of size $n=1$ because we need at least $n=2$ to calculate a standard deviation. If we knew the DAG behind the data, we could read $sd(y)$ from the DAG. Let's imagine that we do and use the name $\sigmal$ for the standard deviation from many trials on the DAG. But if we have $n > 1$, we could calculate the SD from the sample. Let's call that $s$, our estimate of sigma.

We also know that the SD of the sampling distribution scales as $\frac{1}{n}$.

Sample size | SD of `Intercept` coefficient
------------|------------------------------
$n=1$       | $\sigma$ as stipulated
$n=2$       | $\sigma/\sqrt{2}$ estimated by $s/\sqrt{2}$
$n=3$       | $\sigma/\sqrt{3}$ estimated by $s/\sqrt{3}$
$\vdots$    | $\vdots$
$n$         | $\sigma/\sqrt{n}$ estimated by $s/\sqrt{n}$

GIVE FORMULAS for `y ~ 1`, `y ~ yesno`, `y ~ x`

The challenge faced by the traditional statistics student is to look up the correct formula for the situation at hand. But the computer can figure out the right formula directly from the tilde model. 
:::

## Bootstrapping



## Regression table


## Is sampling variation the issue?

> From the 2018 StatPREP newsletter

In 1996 my department chair handed me the first statistics textbook I had ever seen. That single gesture constituted my college's faculty development program for teaching statistics. One of the earliest examples in the book was about the importance of random sampling. It included a picture of President Truman holding up the Chicago Tribune's infamous "Dewey Defeats Truman" headline. It's a good story, but hardly timely, having taken place 48 years earlier. Few of my students knew who Truman was and none of them knew anything about Dewey.

Our students have grown up in an era of "scientific" polling. Being scientific, the results are reported with a margin of error, often ±3 percentage points, to help us know when conclusions are warranted and when not. Many of our statistics courses feature units on constructing a margin of error on a sample proportion, often with explicit reference to political polls. But, like Dewey defeating Truman, the story is no longer timely. The "error" in the "margin of error" is now only a small part of the unreliability of polls. Why?

In an unprecedented opening up of the process of polling, The New York Times is letting us observe, live, their polling for the 2018 mid-term elections. You'll find a description of the project in a September 2018 column and the live action here. It's worth watching.

For those of you reading this after the polling ends, I'll describe the action. As I write this, 2,070,469 telephone calls have been made. In each Congressional district, the results from the past calls are laid out in a long line of circles, filled red or blue depending on the the recipient's response. But only 1 or 2% of the dots are filled. The large majority are empty: no response. Each new call generates a wiggling box at the head of the line of dots. It wiggles until the end of the call. Almost always, the box turns into an unfilled circle.

The poll I'm watching now, New Jersey 3rd district, is in its early stage. 4250 calls producing 62 responses. The margin of error? There's a simple but meaningful statement laid right on top of the grayed-out tally so far: "Don’t take this poll seriously until we reach at least 250 people. We’re at 62."

The calls are made based on a random selection from the phone numbers known to be in the district. But the random selection hardly generates a random sample when the response rate is 2%. To get something that resembles the population, pollsters weight their results. The New York Times is weighting "by age, party registration, gender, likelihood of voting, race, education and region, mainly using data from voting records files compiled by L2, a nonpartisan voter file vendor." And then there's the "likely voter" model, an informed guess about what fraction of people in each weighting strata will actually vote. There's a detailed explanation in this article on the site, where the faulty results from the 2016 presidential election are attributed to a failure to weight by education level.

Seeing the polling process in such detail reveals our misconceptions about what's important in statistics. The so-called "margin of error" is not an adequate indicator of the reliability of the poll. Instead, we need to be thinking about the factors used in weighting and the extent to which they capture the current configuration of political schisms. Polls are now about big, multivariable data (the "voting records compiled by L2") and building models of turnout based on previous elections.

