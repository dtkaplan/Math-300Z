---
title: "Math 300R Lesson `r (lesson <- 21)` Reading Notes"
subtitle: "title goes here"
author: "Prof. Danny Kaplan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
  pdf_document:
    toc: yes
---

```{r include=FALSE}
source("../_startup.R")
```


The theme of this second half of the course is one word: "inference." To illustrate how inference is distinct from the data science methods---wrangling, visualization, modeling---you have been learning, consider @fig-hadley-r4ds-diagram, copied from a well-regarded data-science text.

```{r echo=FALSE, out.width="60%"}
#| label: fig-hadley-r4ds-diagram
#| fig.cap: "Schematic diagram illustrating a path for data exploration. From Wickham & Grolemund, [*R for Data Science*](https://r4ds.had.co.nz/explore-intro.html)"
knitr::include_graphics("www/data-science-explore.png")
```
You've been to all the stepping stones on this path (with "transform" meaning "wrangling"), except the one on the far right: "Communicate." I'd prefer if "communicate" were replaced with "inform." One of the main uses of data science is to extract from data information that is useful for decision-making. The best information is that which reflects the true state of the world. 

**Statistical inference** is the body of concepts and techniques that help us be careful and responsible that our statistical results do actually reflect the true state of the world insofar as the data can tell us about it.

Example: Imagine a salesperson bargaining with a customer. Successful salespeople want to have some idea about how much money the customer would be willing to spend. They try to predict this based on observations they can make about the customer. These might include the kind of car the customer drives, how the customer is dressed, age of the customer, etc. You might think that the prediction takes the form of a **quantity**: the amount of money. But it's better if the prediction is in the form of a **range**. After all, the relationship between willingness to pay and the observed customer attributes is weak and uncertain. It's not good if the prediction suggests more precision than is actually warranted.

Example: Nutritionists are interested in helping people to make diet choices that will increase health. Often they do this by collecting data on what people eat and their health outcomes. A regression model might indicate, for instance, that "organic" food is associated with a reduction in risk of an illness by, say, 20%. Skeptics could point out that "correlation is not causation," and that other factors, say family income, account for the association. To inform the consumers decision about spending on food, it's helpful if the data modeling is structured in a way that can provide confidence that the link between food and health is causal. 

Since inference involves the relationship between the resulted gleaned from models and the state of the world, it's helpful to have situations where the state of the world is well known. We are going to provide such situations in a simple, sure way: by simulation.

To emphasize that the simulation is only for developing an understanding of inference, and **not for depicting the real world**, we'll use the word "gaming" to refer to using such simulations. The full process of gaming has four stages.

::: {.callout-note icon=false}
## The Four Stages 
i. building the deck: Instructors provide a simulation of a mechanism that generates rows of a data frame.
ii. the deal: Some of these rows will be dealt to you, constituting the data you have to work with. [real-world]
iii. the play: Build models and extract results. [real-world]
iv. the reveal: Compare your results from (iii) either to the mechanism given in (i) or to more data generated by the simulation.
:::
    

WE'RE GOING TO USE SIMPLE NAMES like X, Y, A, B, C just to remind you that this is a simulation. Real-world data will usually have descriptive variable names, like `height`, `age`, `score`.

## Signal and noise {#sec-signal-and-noise}

A useful distinction is made in statistics---as it is in engineering---between **signal** and **noise**. For instance, it is usually assumed that response variables consist of a part that stems deterministically from the rest of the system ("signal") and a random part ("noise").

An important task in statistical modeling is to estimate the **size** of the noise. We'll need to develop some statistical techniques to do this with real world data, but we can illustrate the ideas with DAG games.  

Consider the mechanism represented by `dag01`:

```{r}
dag01
dag_draw(dag01)
```

`dag01` has two variables, `x` and `y`. The tilde expression `x ~ eps()` means that `x` is generated entirely as random noise; that's what the `eps()` function does.  In contrast, the tilde expression `y ~ 1.5 * x + 4 + eps()` means that variable `y` will be composed of a part that depends on `x` and another part that is random noise. 

- "depends on `x`": `1.5*x + 4`
- "random noise": `eps()`

In contrast, the `dag00` system involves two variables that are not connected in any way.

```{r}
dag00
dag_draw(dag00)
```

::: {.callout-tip}
## `eps()` is a process
The idea of randomness is central to statistics. In simulating data from a DAG, we use a variety of **random number generators**. One of the most often used generators appears in the tilde expressions as `eps()`.

From the notation, you can see that `eps()` is an R function. By default, it is used without an input, just the bare `()` with nothing inside. So what could the output be? 

A random number generator, like `eps()`, produces its output as if from nothing. (There's a lot of sophisticated mathematics behind this "nothing" but that doesn't concern us here.) Each time `eps()` is used, it makes a new set of random numbers that are not connected to any previous output created by `eps()`. It's best to think about random number generators like `eps()` as a process, for instance, rolls of dice or spins of a lottery wheel.

By default, the "size" of the random noise produced by `eps()` is 1. Some DAGs, such as `dag01`, explicitly specify the size of the noise. For instance, `eps(2)` means the noise will have size 2, `eps(0.17)` means the noise will have size 0.17.
:::

